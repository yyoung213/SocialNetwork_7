기업명,주요업무,자격요건,우대사항
빗썸,"• 데이터 파이프라인 구축 및 운영 : 다양한 소스로 부터 데이터를 수집, 변환, 적재 하는 대용량 데이터 파이프라인 설계 및 구현• 데이터 웨어하우스 구축 플랫폼 운영 : 클라우드 환경 (AWS, GCP 등)에서 DW를 구축 하고 안적적인 데이터 플랫폼 운영을 위한 모니터링 자동화 시스템 구축• 데이터 추출 및 BI 구성 지원 : 데이터 분석과 및 비지니스 팀의 요청에 따라 필요한 데이터를 추출하고 제공• 데이터 품질 관리 : 데이터 품질 확보및 무결성 유지를 위한 검증 및 테스트 프로세스 구축.","• 프로그래밍/스크립팅 언어 중 1개 이상에 능숙한 분 (예: Python, Scala, Java)• SQL에 매우 능숙하며, 복잡한 데이터 추출 및 쿼리 최적화 경험을 보유하신 분• 데이터베이스(RDBMS, NoSQL) 설계 및 운영 경험을 보유하신 분• 대용량 데이터 처리 시스템 구축 및 운영 경험을 보유하신 분 (예: Hadoop, Spark)• 데이터 파이프라인 구축 경험을 보유하신 분 (ETL/ELT).","• 클라우드 환경(AWS, GCP)에서 데이터 인프라 및 서비스(예: Redshift, BigQuery, EMR)를 운영해 본 경험이 있으신 분• 데이터 스트리밍 플랫폼(예: Kafka, Kinesis, Pulsar)을 활용한 실시간 데이터 처리 경험을 보유하신 분• 데이터 웨어하우스(DW) 설계 및 데이터 모델링(Dimensional Modeling 등)에 대한 깊이 있는 이해를 갖추신 분• 데이터 품질 관리(Data Quality) 및 데이터 거버넌스(Data Governance) 구축 경험이 있으신 분."
클래스유,"• AI 프로덕트의 클라이언트 개발 및 최적화• 데이터 온톨로지 엔진 개발• AGI 생성 플랫폼 구축• LLM파인튜닝 및 최적화• 시스템 아키텍처 설계 및 구현• 실험설계(A/B Testing, 인과추론) 및 통계분석• NPL.","[누구나 지원할 수 있습니다!]필요한 것은 단 하나 *공학적 사고를 하는가*• ""구조적으로 보면 이 문제는... 잠깐 멈춰서 내 접근 방식이 최선인가?"" 이런 식으로 생각해본 분• ""근본 원인을 분석해보면... 내 접근에 한계가... 편향이 있을 수 있다"" 자기성찰을 하는 분• ""현상 vs 본질을 구분하면서도 내 관점의 한계는 뭘까? 다른 각도로 생각해 보면 어떨까?"" 다층적 사고를 하는 분• ""이상한데... 뭔가 놓친게 있는 거 같은데"" 직감적으로도 문제를 감지하는 분• ""잠깐 멈춰서... 내가 확신하는게 맞나? 한번 더 체크해보자"" 의식적·무의식적 성찰이 자연스러운 분• ""이 원인들의 속성은 뭐지? 각 원인들 간에 상관관계가 있나요?"" 모호한 개념을 구체적인 속성들로 분해하고 각 요소 간의 관계를 체계적으로 매핑해본 경험이 있는 분※경력이나 학력, 기술 스택에 제한을 두지 않습니다.","기술적 경험이나 특정 스킬보다는 문제를 바라보는 사고방식을 더 중요하게 생각합니다특별히 가산점을 많이 부여하지 않습니다.* 해당 분야 경력 5년 이상 시 연봉 1억 5천만원부터[AI/Prompt Engineering]• LLM 파인퓨팅 및 RAG 시스템 구축 경험• 머신러닝 모델 프로덕션 배포 경험• 언어적 개념의 정의와 인문학적 사고력• 프롬프트 엔지니어링을 통한 실제 비즈니스 문제 해결 사례[Development (Backend/Frontend)]• 대용량 트래픽 처리 시스템 설계 경험• 클라우드 인프라(AWS/GCP/Azure) 설계 및 운영 경험[Product Manager]• 0-＞1 신제품 런칭 또는 피봇 성공 경험• 데이터 기반 의사결정 경험[Data Science/Analytics]• 실제 비즈니스 임팩트를 창출한 데이터 분석 프로젝트 경험• 대용량 데이터 파이프라인 구축 및 운영 경험• 실험 설계(A/B Testing, 인과추론) 및 통계적 분석 경험[UX/UI Design]• 사용자 중심 디자인을 통한 비즈니스 지표 개선 경험• 디자인 시스템 구축 경험[Marketing/Growth]• 데이터 드리븐 마케팅 및 그로스 해킹 경험• 브랜드 마케팅 캠페인 기획 경험※기술은 함께 배우면 됩니다. 공학적 사고가 더 중요해요!"
마이리얼트립,"[함께 일하게 될 팀]• 데이터 플랫폼팀은 마이리얼트립에서 서비스 되는 모든 데이터를 개발 및 관리 하는 팀입니다.• 마리트의 비지니스에서 필요로 하는 DB데이터, Log데이터, 외부수집데이터등을 통합/관리합니다.이렇게 개발 수집된 데이터는 검색/추천, 다양한 의사결정, Planning, 회계/정산, 업무 자동화, A/B Test 등 다양한 곳에 사용됩니다.이를 관리하기 위한 다양한 DW 운영 기술들을 경험해 볼 수 있으며, 다양한 소스를 통합관리하는 데이터 파이프라인, 대용량 데이터 처리를 위한 빅데이터 기술, 실시간 데이터 처리등의 기술을 습득할 수 있습니다. [Data Engineer가 하는 일]• 정보계 데이터 저장소 및 파이프라인 개발/운영• 다양한 데이터의 Batch 및 streaming 처리• DW/Mart 설계 및 개발• 대용량 데이터 처리 아키텍쳐 개발 및 운영• 대용량 데이터 분석 후 관련 서비스 개발/운영• MLOps를 통한 성능 최적화 작업.","• 클라우드 환경에서의 대규모 데이터 처리를 위한 데이터 파이프라인 설계 및 구현 경험• 주도적인 BI/DW 구축 경험• 탁월한 수준의 SQL• Airflow, luigi 같은 ETL 도구의 경험• Java or Python 등 하나의 언어를 자유롭게 다룰수 있는 분• 실시간 Streaming 데이터 처리 경험.",• 분산 환경 대용량 데이터 처리 환경 구축 경험• AI를 활용한 생산성 향상 경험• 광고 데이터 파이프라인 구축 경험• debezium(CDC) 개발 및 운영 경험.
씨제이올리브영(CJ올리브영),"[유닛 소개]코어플랫폼유닛 - ①카탈로그서비스 / ②회원서비스 / ③인벤토리서비스 ""고효율 플랫폼""의 핵심 엔진을 개발하고 최적화합니다.올리브영 코어플랫폼유닛은 이커머스 옴니채널 비즈니스의 핵심 자산인 상품, 회원, 프로모션, 물류/재고 데이터를 통합 관리하며, 플랫폼의 효율성과 확장성을 책임지는 중요한 역할을 수행합니다. 깊이 있는 기술적 전문성과 풍부한 경험을 바탕으로, 안정적이고 성능 뛰어난 Back-End 시스템을 구축하고 운영하며, 미래 성장을 위한 혁신적인 기술 도입을 주도할 숙련된 Back-End 엔지니어를 찾습니다. 핵심 비즈니스 로직을 효율적으로 설계하고 구현하여 올리브영의 지속적인 성장에 기여할 전문가를 기다립니다.• 핵심 비즈니스 로직 (상품 관리, 회원 관리, 프로모션, 캠페인, 재고 관리 등) 개발 및 운영• Java 또는 Kotlin 기반의 Spring Framework를 활용한 애플리케이션 개발• JPA, Hibernate 등 ORM을 이용한 효율적인 데이터 모델링 및 관리• 대규모 트래픽 및 데이터 처리를 위한 시스템 설계 및 최적화• 시스템의 안정성, 확장성, 성능 향상을 위한 지속적인 기술 검토 및 개선.","• 4년 이상의 Application 개발 경력 보유• Java 또는 Kotlin 중에 숙련된 개발 경험 보유• Spring Framework 기반의 Application 개발 경험• JPA, Hibernate 등 ORM 사용과 도메인 모델링 경험.",• 새로운 기술을 익히고 도메인 지식을 쌓는 것을 좋아하시는 분• e-commerce 분야에서 개발경험이 있으신 분• 틀에서 벗어난 사고를 하고 기존 지식에 도전하기 좋아하시는 분• 어떤 문제든 끝까지 파고들어 해결하시는 분.
업스테이지,"• AI 모델 개발을 위한 데이터 수집, 분석, 가공, 평가, 관리 전반의 프로젝트 운영 • 최신 AI 모델 개발 흐름을 바탕으로 한 창의적인 벤치마크 설계 및 학습 데이터 구축• AI 모델을 활용한 텍스트 및 이미지 데이터 증강부터 Human Feedback Loop까지 신규 데이터셋 구축을 위한 유기적인 데이터 제작 파이프라인 설계와 실행• 고품질 데이터셋 구축을 위한 내외부 협업 및 커뮤니케이션[근무 형태]• 정규직.","• HuggingFace 및 데이터 전처리/후처리 라이브러리(OpenCV, KoNLPy, NLTK, SpaCy 등)를 활용한 데이터 처리 경험이 있으신 분• Python 프로그래밍에 능숙하신 분• 다양한 팀과의 협업에서 원활한 커뮤니케이션 및 협력할 수 있는 능력이 있으신 분.",• AI 기술을 활용한 실제 제품 개발 경험이 있으신 분• AI 모델링 경험이 있는 분• 파운데이션 모델 API를 활용한 서비스 개발 또는 프로젝트 수행 경험이 있으신 분• 문제 해결을 위한 정량적 및 정성적 평가를 설계하고 실제로 적용해본 경험이 있으신 분.
마이리얼트립,"• 마이팩 데이터 분석데이터 분석을 통해 수요를 미리 읽고 ‘언제, 어떤 상품을 내놓을지’ 결정하는데 도움을 줍니다.상세 ＞ 구매 전환 퍼널을 데이터로 살피며 병목을 없애고, 기획전·상시 상품의 성과를 실험으로 검증하며 마이팩 버티컬의 성장을 도모 합니다.• 교통·통신 데이터 분석Rail Europe 구간권(P2P) 연동을 시작으로 일본 JR 패스·해외 렌터카 등 다양한 이동 수단을 순차적으로 통합하려 합니다.데이터 분석가는 고객 여정 데이터를 면밀히 분석해 최적의 교통 옵션을 추천하고, 항공·숙소·투어와 매끄럽게 이어지는 원스톱 여행 준비 경험을 제공하도록 합니다.분석을 통해 교통·통신관련 고객의 여행을 진정으로 돕고, 팀과 서비스가 함께 성장할 수 있도록 합니다.• End-to-End 문제 해결 & 데이터 문화 확산문제 정의 ＞ 데이터 모델링 ＞ 실험 설계 ＞ 제품 반영까지 주도적 오너십을 가지고, 반복 작업은 Generative AI·Workflow Automation으로 효율화 합니다.전사 구성원이 데이터를 ‘읽고·쓰고·행동’할 수 있도록 교육 및 가이드를 제공하여 함께 성장하는 문화를 만듭니다.","• 데이터 조작 및 분석 능력• SQL을 통해 데이터베이스에서 원하는 데이터를 추출할 수 있는 분• Python/R 로 데이터를 가공·전처리하고, 시각화까지 일관되게 수행할 수 있는 분2. 기본적인 통계 및 분석 역량• 기초 통계학·실험 설계(Design of Experiments)를 이해하고 있는 분• A/B 테스트, 퍼널 분석 등을 실제 서비스에 적용해 본 경험이 있는 분3. 데이터 기반의 변화 추진 능력 • 데이터를 기반으로 서비스나 업무 프로세스에 실질적인 변화를 만들어낼 수 있는 분• 개발자, 디자이너, PM, 비즈니스 담당자 등 다양한 직군과 원활하게 협업할 수 있는 분.","• 문제를 스스로 정의하고 끝까지 해결하려는 오너십을 지닌 분• 난관이 와도 쉽게 포기하지 않고 집요하게 파고드는 분• 익숙하지 않은 영역도 과감히 도전하며 자기 성장을 추구하는 분• AI·자동화 도구(Generative AI, AutoML, Prompt Engineering 등)를 활용해 반복적인 분석·리포트·Batch 작업을 자동화하고 팀 생산성을 향상시킨 경험, LLM·RAG 기반 분석/서비스 프로토타입을 신속히 구축하거나 운영에 적용한 사례• AI 기술을 팀원에게 전파하고 분석 워크플로를 ‘지능형’으로 고도화한 경험을 공유할 수 있는 분."
씨제이올리브영(CJ올리브영),"• AI/ML/자동화 시스템 개발 및 최적화• 수요예측, 발주 고도화 등 비즈니스 요구에 맞춘 AI / 머신러닝 / 자동화 시스템 개발 및 성능 최적화• 모델 배포, 모니터링, 성능 개선 등 MLops 전체 운영 라이프사이클 설계 및 운영 관리• 데이터 과학자 및 분석가와 협업하여 모델의 실무 적용성을 높이고, 데이터 인프라와의 원활한 연계 지원2. 물류 특화 데이터베이스 및 분석 환경 구축• 물류 도메인에 특화된 데이터레이크 설계 및 구축• 대용량 데이터를 효율적으로 저장, 조회, 분석할 수 있는 인프라 환경 구축3. 데이터 파이프라인 구축 및 관리• API 연동, DB 연동 등 다양한 데이터 수집 방식을 적용하여 자동화된 데이터 파이프라인 구축• 데이터 수집부터 정제, 적재, 변환까지의 전 과정을 체계적으로 관리.","[Education] • 컴퓨터등 관련 학사 이상[Experience]• 유관경력 5~15년 보유• 레거시 시스템과 클라우드 환경(AWS, GCP) 간 데이터 연동 및 ETL 파이프라인 설계, 구축, 운영 경험• 실시간 데이터 처리 환경(Kafka 등) 구축 및 운영 경험• Airflow 등 워크플로우 툴을 활용한 ETL 자동화 및 모니터링 체계 운영 경험• 데이터 품질 관리, 메타데이터 관리, 접근 권한 제어 등 데이터 거버넌스 체계 설계 경험• ML/DL 모델 성능 개선, 재학습 자동화, 모니터링 등 MLOps 전 주기 운영 관리 경험• 데이터 플랫폼 및 ML 시스템과 연동되는 서비스 API 설계, 개발, 운영 경험[Skill]• Python, SQL, Java 등 개발 역량• 데이터 수집부터 정제, 전처리등 데이터파이프라인 전반에 대한 역량• Spark, AWS Redshift, GCP BigQuery 등 클라우드 DB 구축 관리 역량• Airflow 등 워크플로우 툴을 활용한 ETL 자동화 및 모니터링 체계 구축 및 운영 역량• 컨테이너 기반 환경(Docker, Kubernetes 등)에서 ML 시스템 배포, 관리, 운영 역량.","• 컴퓨터등 관련 석사 이상• Tensorflow, Pytorch, Scikit-learn등을 이용한 ML/DL 개발, 운영 경험 우대• 물류 또는 공급망 관리(SCM) 분야 실무 시스템 개발 경험 우대• 수요예측등 머신러닝, 자동화 프로젝트 리딩 경험 우대."
에스투더블유(S2W),"데이터 팀은 S2W의 제품 개발·운영에 필요한 모든 데이터를 수집·분석하고, 관련 소프트웨어들의 효율성과 가용성을 높이는 역할을 담당합니다. 그 중 웹 데이터 수집 및 분석 영역에서는 다음과 같은 업무를 수행합니다.• Surface Web, Deep/Dark Web 수집기 운영• 봇탐지/차단 우회 기술 개발/적용• 수집데이터 저장/관리• 수집 모듈을 위한 API 개발 및 운영• 웹 수집/분석/데이터 파이프라인을 위한 컨테이너 환경 관리• 웹 수집/분석/데이터 파이프라인을 위한 core library 개발/관리.","• 컴퓨터공학 전공 혹은 그에 준하는 전공 및 지식 보유• 2년 이상의 Python 또는 Java 개발 경험 (한 개 이상 원활한 프로그래밍 가능)• Docker, Kubernetes 활용 경험• DB를 활용한 애플리케이션 또는 파이프라인 설계/구축 경험• Object Oriented Programming (OOP)에 대한 이해 (Java, C++ 등의 프로그래밍 언어 경험)• HTTP에 대한 기초 지식.","• Playwright, Selenium을 이용한 웹 수집 경험• Deep/Darkweb 수집 경험• 봇 탐지/차단 기술 분석, 우회 기술 개발 경험 (e.g., Captcha, Cloudflare)• linux 환경에서의 개발 경험• NoSQL DB를 활용한 개발 경험• 비동기 프로그래밍 경험• AI를 활용한 업무 자동화 경험."
도터,• 의료 데이터 라벨링 및 품질 관리• 특허 및 기술 보고서 작성 보조• Git/GitHub 기반 소스 코드 관리 및 협업.,"• 인공지능, 데이터사이언스, 컴퓨터공학 등 관련 전공 학사 (신입 ~ 3년 경력, 졸업 예정자 포함)• Python 프로그래밍 및 PyTorch, TensorFlow 등의 딥러닝 프레임워크 활용 능력• OpenCV, Pillow, Scikit-Image 등의 영상 처리/분석 라이브러리 활용 능력• 기술 문서 작성 역량 (README, 연구 노트, 기술 보고서 등).",• 의료 영상 또는 의료 데이터 프로젝트 경험• 인공지능 관련 대회 수상 또는 공개 리더보드 성과• 인공지능 모델 서빙/배포 경험• 영어 기술 문서 독해 및 작성 능력.
피에프씨테크놀로지스,"- 안정적이고 확장 가능한 데이터 파이프라인을 설계, 개발 및 운영해요.- 비즈니스 요구사항에 맞는 데이터 마트를 구축하고 고도화해요.- 사내 다양한 부서의 데이터 추출 및 분석을 지원해요.- 데이터 처리 과정에서 발생하는 이슈를 트래킹하고 해결하며, 서비스 안정성을 확보해요.- 반복적인 데이터 관련 업무를 자동화하거나 시스템을 개선해요.","- 경력 상관없이, SQL을 활용한 데이터 처리 및 분석 역량이 있으신 분- Python 등 하나 이상의 프로그래밍 언어에 대한 이해도가 있으신 분- 데이터 엔지니어링 및 데이터 모델링에 대한 기본적인 지식을 지니신 분- 동료와 함께 문제를 해결해나가는 적극적인 커뮤니케이션 역량이 있으신 분.","- 안정적인 서비스 운영에 대한 책임감이 강하신 분- 동료와의 협업과 소통을 중요하게 생각하시는 분- 주어진 문제를 능동적으로 해결하고, 선제적으로 시스템을 개선하려는 의지가 있으신 분- PFCT와 함께 데이터 전문가로 성장하고 싶으신 분- 클라우드 환경(AWS, GCP 등)에서의 데이터 처리 경험이 있으신 분- Airflow, Spark 등 데이터 관련 프레임워크 사용 경험이 있으신 분- 대용량 데이터 처리 및 분산 시스템에 대한 이해도가 있으신 분- 핀테크 또는 금융 도메인에 대한 높은 관심을 지니신 분- 새로운 기술을 배우고 적용하는 데 흥미가 있으신 분."
에이블리코퍼레이션,• 방대한 데이터를 빠르고 효율적으로 활용하기 위해 데이터 플랫폼을 개선하고 관리해요.• 에이블리 서비스에서 발생하는 데이터 처리를 위해 파이프라인을 설계하고 개발해요.• 데이터 플랫폼 설계부터 개발 및 운영까지 모든 과정에 참여해요.,"• 에이블리 조직문화에 공감하여, One Team으로 GRIT하게 일하며 Impact를 만들어갈 의지가 있는 분을 찾아요.• 데이터 엔지니어 관련 업무 경력이 2년 이상이거나, 그에 준하는 역량을 갖고 계신 분을 찾아요.• Kafka를 활용한 실시간 데이터 처리를 경험해 보신 분을 찾아요.• Spark를 활용한 분산 처리 경험이 있는 분을 찾아요.• 데이터 플랫폼 설계부터 운영까지 A to Z를 주도적으로 개발해본 경험이 있는 분을 찾아요.","• 데이터 엔지니어링 관련 오픈소스 기여 경험이 있는 분이면 더 좋아요.• CDC, Airflow, Flink, Iceberg, ScyllaDB 등의 기술에 대한 경험이 있는 분이면 더 좋아요.• K8s 활용 경험이 있는 분이면 더 좋아요.[이런 기술을 활용해요]• Language : Python, Java, Scala• Processing : Spark, Flink, Kafka, Airflow• Storage & Analysis : BigQuery, Athena, S3• Visualization : Redash• Discovery : Datahub• Infra : EKS, EMR."
게임듀오,"데이터 정제/가공/분석 및 자동화-유저 행동 Raw 데이터 등 모바일 게임에서 발생하는 데이터를 정제, 가공 및 분석합니다. 이를 토대로 리포트와 대시보드를 작성하여 실제 Action Plan으로 이어질 수 있도록 기여합니다.-나아가, 반복적인 분석 리포트 출력을 자동화하고 주요 지표를 시스템화하여 전사의 효율적인 데이터 활용을 돕습니다.핵심 지표/로그 설계 및 실험 분석-게임 운영 및 분석에 필요한 핵심 지표와 로그 데이터를 설계하고 관리합니다. 이를 통해 목표 달성을 지원하고, 가설 검증을 위한 다양한 실험(A/B 테스트 등)을 계획하고 진행합니다.데이터 기반 의사 결정-경영진, PD, 기획자, 개발자, 마케터 등 다양한 직군의 동료들과 함께 주요 의사 결정 과정에 참여합니다. 데이터 기반(Data Informed) 문제 해결방식을 제시하여 보다 효과적인 의사 결정을 지원합니다.ML/DL 기술 활용-데이터 분석 결과와 예측 모델을 개발하여 게임 운영에 안정적으로 반영합니다. ML/DL 기술을 활용하여 유저 경험을 개선하는 데 기여합니다.사내 데이터 문화 개선-전사적인 데이터 리터러시 향상을 위한 활동에 기여합니다. 정기 데이터 세미나(분기 1-2회)를 기획/진행하거나, 데이터 인사이트 아티클을 작성 및 공유하며 데이터 기반 문화를 함께 만들어갑니다.","Python, SQL을 활용하여 데이터를 원하는 형태로 핸들링이 가능하신 분BI Tool(Looker Studio, Tableau, Superset 등)을 활용하여 대시보드 제작 경험이 있으신 분게임 데이터 분석에서 발생가능한 복잡한 이슈를 Deep dive 하여 해결할 수 있는 역량을 보유하신 분A/B 테스트, 수학/통계에 대한 이해를 바탕으로 목표에 맞는 실험 설계와 가설 검증이 가능하신 분다양한 팀원들과 주도적으로 협업하며 자기주도적이고 진취적이신 분GCP, AWS 등 클라우드 환경에서 데이터 활용 경험을 보유한 분.","게임을 좋아하시는 분게임 로그를 정의하고 분석한 경험이 있는 분ARPU, LTV, Funnel, Retention, CPI 등을 활용한 게임 데이터 분석 기법에 높은 이해도를 가지신 분BigQuery와 Airflow를 다양하게 다뤄본 경험을 보유한 분인과추론(Causal Inference) 방법론에 대한 이해 및 실제 비즈니스 문제 적용 경험이 있는 분생성형 AI 등 최신 AI 기술을 코드 작성, 리포팅, 분석 업무에 접목하여 생산성을 크게 향상시킨 경험이 있는 분."
하이퍼커넥트,"[Content Understanding 업무 소개]AI Lab의 contents understadning 업무에서는 영상이나 이미지, 음성 및 자연어로 구성된 비정형 데이터를 입력으로 받아 비즈니스에 유용한 정보를 추출하는 데 집중하며, 모더레이션을 통한 신뢰와 안전(Trust & Safety) 업무에 기여하는 것을 주 목표로 합니다. 하이퍼커넥트 및 Match Group 브랜드에서 생성되는 컨텐츠를 이해하는 데 기여하며 글로벌 신뢰와 안전 기준을 충족하기 위해 Match Group과 협력하여 다양한 과제를 수행합니다.• 모바일 및 웹 환경에서 짧은 레이턴시와 낮은 전력 소비를 유지하면서도 높은 정확도를 달성할 수 있는 경량 모델 설계 및 최적화 기법• noise와 imbalance가 심한 데이터에서 레이블 품질을 추적 및 관리하고, 최소한의 라벨링으로 성능을 확보하기 위한 액티브 러닝, core-set selection, semi-/self-supervised 학습 방법• multi-task 또는 multi-label 분류를 제한된 파라미터 budget 내에서 최적화하고, 텍스트, 이미지, 영상 등 multi-modal 정보를 통합하는 모델링 기법• 도메인 간 분포 차이를 극복하는 도메인 적응, 서비스 확장성을 위한 meta-learning 기법• 국제 AI 기준을 맞추기 위한 Fairness 및 Privacy 보장을 위한 학습 방법• 사용자 행동 로그와 콘텐츠 분석 정보를 활용하여 스팸, 가짜 계정 등 이상 행위를 실시간으로 탐지하거나 사전 예측하는 스트리밍 기반 모델링• ML 프로덕션 프로세스를 혁신하기 위한 LLM 활용 방법.","• AI/ML 도메인 전반에 대한 이해와 적어도 한 개 이상의 특정 도메인에 대한 깊이 있는 지식을 갖춘 분• AI 기술의 제품화에 관심이 많으신 분• AI를 통한 문제 해결 역량 및 이를 위한 프로젝트 관리 역량을 갖춘 분• Tensorflow, PyTorch, CatBoost, JAX 등 오픈소스 프레임워크 기반 개발역량을 포함한 파이썬 개발역량이 충분하신 분• 강한 오너쉽을 발휘해 프로젝트의 A-Z를 책임지고 완수하실 수 있는 분• 여러 직군의 이해관계자와 협업할 수 있는 강력한 커뮤니케이션 능력을 갖추신 분• ML 시스템의 소프트웨어 개발 구조와 내용을 이해하고 기능을 기획할 수 있는 엔지니어링 역량이 있는 분• 데이터의 통계적 특성과 패턴을 발견하고 이를 AI 문제 해결에 반영하실 수 있는 분• A/B 테스트에 대한 이해를 갖추고 SQL 기반의 데이터 분석 역량을 갖춘 분• 학위나 국적은 무관하되 한국어로 원활한 의사소통이 가능한 분.","• 기계학습 관련 탑티어 학회 및 저널(NeurIPS, ICLR, ICML, CVPR, ICCV/ECCV, KDD, …) 게재 실적 혹은 AI 관련 대회 수상 실적이 있으신 분• AI/ML 도메인 전반에 대한 방대한 지식을 자랑할 수 있으신 분• 실제 서비스에 AI 기술을 통합하고 주요 지표를 유의미하게 향상시켜 본 경험이 있으신 분• PO/PM 혹은 그에 준하는 경험이 있으신 분• 영어로 원활한 의사소통이 가능하신 분• 인과관계 분석(DID, RCT, Causal Inference 등), 다변량 테스트, Sequential Testing 등에 대한 이해가 깊으신 분."
씨제이올리브영(CJ올리브영),"• 신규 데이터 발굴 및 수집• 오라클 / 빅쿼리 등 물류관련 다양한 내부 시스템 및 외부 연동 시스템으로부터 유의미한 데이터를 발굴, 수집, 정제• 기존 수기관리 데이터 (엑셀 등) DB화 및 분석 자산 전환2. 물류 인사이트 분석 및 발굴• 물류 운영 전반(입고, 출고, 배송, 반품 등)에 대한 데이터를 분석하여 프로세스 개선 및 비용 절감등을 위한 인사이트 도출• 정기적 분석 결과 리포팅을 통한 데이터 기반 전략적 의사결정 지원3. 지표 고도화 및 분석 시각화• 기존 지표 체계를 재정의하거나 정밀도를 높여, 보다 정확하고 신뢰도 높은 지표 생성 및 고도화• Tableau 등 시각화 도구를 활용한 직관적 대쉬 보드 구성 및 분석 결과 시각화.","[Education]• 컴퓨터 / 산업공학 / 통계등 관련 학사 이상 [Experience]• 유관경력 5~15년 보유• 레거시, 클라우드플랫폼 등 다양한 물류 관련 내부 데이터베이스 및 외부 시스템과의 연동/분석 경험• 비정형 / 수기 관리 데이터(엑셀, CSV 등) DB화 및 데이터 품질 개선 경험• 기존 KPI 및 운영 지표를 분석 목적에 맞게 재설계및 고도화 경험• Tableau, 오픈소스 등 다양한 데이터 시각화 도구를 활용한 대시보드 구축 경험• 분석 결과에 대한 커뮤니케이션 경험• [Skill]• SQL, Python, R, Tableau 등 데이터 분석 및 자동화 도구 활용 역량• 데이터 수집부터 정제, 전처리등 데이터파이프라인 전반에 대한 역량• 다양한 통계 / 데이터 모델링 기법 및 문제 해결 역량.","• 컴퓨터 / 산업공학 / 통계등 관련 석사 이상• 오라클, GCP (BigQuery), AWS (Redshift) 등 레거시 및 클라우드 경험 우대• 물류 또는 공급망 관리(SCM) 분야 실무 경험 우대• 입고, 출고, 배송, 반품 등 물류 운영 전반에 대한 데이터 분석 및 운영 프로세스 개선 프로젝트 수행 경험 우대• 분석 프로젝트 리딩 경험 우대."
누아,• 여행사 업무 자동화를 위한 AI 에이전트 설계 및 구현• 비정형 데이터 구조화를 통한 업무 자동화 툴 개발• 항공권 유통 솔루션 기반 지능형 에이전트 개발.,• 논리적 사고와 문제해결 능력• 주어진 문제를 성실하고 꾸준하게 해결해내는 분 • 4년제 대학교 졸업자 또는 졸업 예정자• 전공 무관.,"• Python, Java 등 프로그래밍 언어에 대한 이해• 대규모 데이터 처리 및 분석 경험• AI 및 머신러닝 관련 프로젝트 경험."
왓챠,"• 데이터 인프라 구축 및 운영- AWS 클라우드 환경에서 확장 가능하고 비용 효율적인 데이터 인프라 설계 및 구축 - Kubernetes를 활용한 컨테이너 기반 데이터 애플리케이션 운영 환경 구성- Terraform을 활용한 IaC 중심의 데이터 플랫폼 인프라 관리- 장애 대응 및 성능 최적화를 통한 서비스 안정성 향상• 데이터 파이프라인 구축 및 자동화- Airflow, Argo Workflows, Kafka 등을 활용한 실시간 및 배치 데이터 파이프라인 구축- dbt를 활용한 데이터 변환 및 모델링 파이프라인 구축- CI/CD 파이프라인을 통한 데이터 파이프라인 배포 자동화- 코드 기반 워크플로우 관리 및 변경 이력 추적- 반복적인 데이터 처리 작업 자동화• 데이터 웨어하우스 및 스토리지 최적화- BigQuery, S3 등을 활용한 데이터 저장소 설계 및 운영- 대용량 데이터 처리 성능 최적화 및 비용 효율화- 비즈니스 요구사항에 맞는 데이터 모델 설계• 플랫폼 엔지니어링- 사내 개발팀 및 데이터 분석가를 위한 셀프 서비스 데이터 플랫폼 구축- 로그 파이프라인 구축 및 데이터 카탈로그 관리- 대용량 데이터 처리를 위한 분산 시스템 설계 및 운영- 개발 도구 및 오픈소스 도입을 통한 운영 편의성 향상.","• 경력: 데이터 엔지니어링 또는 DevOps 실무 경험 4년 이상• 클라우드: AWS 또는 GCP 주요 서비스 활용 경험• 컨테이너: Docker 및 Kubernetes 환경에서의 애플리케이션 배포 및 운영 경험• SQL: 복잡한 쿼리 작성 및 데이터베이스 성능 최적화 경험• 데이터 처리: Spark, Airflow, Kafka 등 데이터 처리 및 워크플로우 도구 활용 경험• 모니터링: Datadog, Prometheus, Grafana 등을 활용한 시스템 모니터링 경험.","• Terraform, AWS CDK 등 IaC 도구를 활용한 데이터 인프라 관리 경험• Argo Workflows를 활용한 Kubernetes 네이티브 워크플로우 구축 경험• Kafka, Kinesis, Pub/Sub 등 실시간 스트리밍 데이터 파이프라인 구축 경험• Debezium을 활용한 CDC(Change Data Capture) 파이프라인 구축 경험• Apache Flink를 활용한 실시간 스트림 처리 경험• BigQuery, Redshift 등 클라우드 데이터 웨어하우스 최적화 경험• dbt 등 데이터 변환 및 품질 관리 도구 활용 경험• GitOps 기반 데이터 파이프라인 배포 및 관리 경험• 대규모 데이터 처리를 위한 인프라 설계 및 최적화 경험• Kubernetes 환경에서의 복잡한 데이터 워크로드 운영 경험• MLOps 파이프라인 구축 및 ML 모델 서빙 인프라 운영 경험• 오픈소스 프로젝트 기여 또는 사내 데이터 도구 개발 경험."
빅웨이브로보틱스,"※ 본 채용은 AI Engineer 1명을 모집하는 공고이며, 아래 두 직무 요건 중 어느 하나 이상을 충족하시는 분을 채용할 예정입니다.[Machine Learning Engineer] - 담당업무 1) 모델 개발 및 학습 파이프라인 구축 2) 정형 및 비정형 데이터를 활용한 예측/분류/탐지 모델 설계 및 최적화[AI Application Engineer] - 담당업무 1) AI 모델을 엣지 디바이스에서 활용 할 수 있도록 응용 프로그램 개발 및 API 연동 2) AI 서비스를 위한 레거시 시스템과의 인터페이스.","[Machine Learning Engineer] - 자격요건 1) MLflow, SageMaker, Kubeflow 등 MLOps 환경 경험이 있으신 분 2) Roboflow, CVAT 등의 라벨링/데이터셋 관리 툴 경험이 있으신 분 3) 머신러닝/딥러닝 프레임워크(TensorFlow, PyTorch 등) 활용 경험이 있으신 분[AI Application Engineer] - 자격요건 1) FastAPI 또는 Flask 기반의 REST API 서비스 개발 경험이 있으신 분 2) 임베디드 또는 NPU 등의 하드웨어에 대한 지식이 있으신 분 3) MQTT, Redis 등을 활용한 데이터 인터페이스 경험이 있으신 분.",[Machine Learning Engineer] - 우대사항 1) 로봇 도메인에 대한 경험 있으신 분 2) YOLO 등 딥러닝 기반 Vision 모델 경험이 있으신 분[AI Application Engineer] - 우대사항 1) AI모델 SoC(System-on-Chip) 최적화 경험이 있으신 분 2) Kubernetes 기반 서비스 개발 경험 있으신 분.
업스테이지,"• AI 제품 개발을 위한 데이터 수집, 분석, 가공, 평가, 관리 전반에 대한 작업 수행• 데이터 수집부터 분석, 가공, 평가, 관리까지 전 과정을 지원하는 툴 및 파이프라인 개발• 고품질 데이터셋 구축을 위한 내외부 협업 및 커뮤니케이션• 프롬프트 설계 및 평가 프로세스 운영 등 AI 제품의 성능 개선을 위한 실험 및 분석 수행.","• 기본적인 AI 기술에 대한 이해를 보유하신 분• 텍스트 및 이미지 전처리/후처리 라이브러리(OpenCV, KoNLPy, NLTK, SpaCy 등)를 활용한 데이터 처리 경험이 있으신 분• Python 프로그래밍에 능숙하신 분• 다양한 팀과의 협업에서 원활한 커뮤니케이션 및 협력할 수 있는 능력이 있으신 분.","• AI 기술을 활용한 실제 제품 개발 경험이 있으신 분• AI 모델 학습을 위한 데이터 구축 가이드라인 작성 경험이 있는 분• AI 모델링 경험이 있는 분• 문제 해결을 위한 정량적 및 정성적 평가를 설계하고 실제로 적용해본 경험이 있으신 분• 기초적인 컴퓨터공학 지식 (Data Structure & Algorithm, Computer Network, Database, OS 등)을 보유하신 분."
기어세컨드,"반복적인 업무의 효율화를 넘어, 실제 접목 가능한 AI 솔루션을 시도하려고 합니다.빠르게 만들어보고 부딪히며, 우리만의 워크플로우를 바꿔갈 분을 찾고 있어요.• AI 솔루션 기획 및 프로토타입 개발 - 다양한 AI 도구를 활용해 사내 니즈에 맞춘 솔루션을 설계하고 초기 버전을 제작합니다.• 자동화 및 시스템 연동 작업 지원 - 사내 워크플로우를 분석해 필요한 자동화를 제안하고, 웹/서버/데이터 환경과의 통합을 구현합니다.• 기술 문제 해결 및 협업 피드백 반영 - 유관 부서와 긴밀히 협력하여 솔루션의 품질을 높이고, 실시간 피드백을 반영해 개선합니다.","• 컴퓨터 공학, 데이터 사이언스, 소프트웨어 엔지니어링 등 관련 지식을 보유하신 분• Python, JavaScript 등으로 간단한 자동화 및 툴 제작 경험이 있으신 분• AI 모델이나 API를 활용한 실제 솔루션 개발에 관심이 있으신 분• SaaS, 내외부 API, 웹 기반 시스템과의 연동 작업에 익숙하신 분• 빠르게 시제품을 만들고 실험하며 개선하는 과정을 즐기시는 분.","• GPT, Claude, Gemini 등 LLM 기반 기술을 직접 사용해 본 경험이 있으신 분• RAG 또는 에이전트형 시스템 아키텍처에 관심 있거나 적용해 본 경험이 있으신 분• AWS, GCP, Azure 등 클라우드 환경에서 시스템을 구성해 본 경험이 있으신 분• 오픈소스 프로젝트 기여 또는 팀 기반 개발 협업 경험이 있으신 분."
우아한형제들(배달의민족),"A. 데이터 인프라 구축 - Cloud-native 컨테이너 오케스트레이션 환경 구축 및 운영 - 분산 쿼리 엔진 및 실시간 OLAP 엔진 구축 및 최적화 - 모던 테이블 포맷 기반 데이터 레이크 아키텍처 설계 및 운영 - 클라우드 매니지드 웨어하우스 마이그레이션 및 운영 - 온프레미스 K8s 기반 머신러닝 운영 플랫폼 구축 (GPU 클러스터 등)B. 데이터 플랫폼 개발 - 워크플로우 오케스트레이션 및 데이터 변환 도구 개발 및 운영 - 데이터 카탈로그 시스템 및 디스커버리 서비스 (데이터 리니지, 메타 정보 탐색 등) 개발 및 운영 - 오픈소스 분석 도구 기반 자체 분석 환경 구축 (커스터마이징 및 기능 확장)C. 데이터 수집 및 스트리밍 - 자체 구축 로그 수집 시스템 개발 및 운영 - 스트리밍 데이터 커넥터 기반 데이터 파이프라인 구축 및 관리 - 실시간 데이터 처리 파이프라인 설계 및 운영 (Flink 기반 스트림 처리).",• 위 업무내용(A~C) 중 1개 이상 역할을 3년 이상 수행한 경험이 있는 분• Kubernetes 클러스터에서 애플리케이션 배포 및 운영 경험이 있는 분• 분산 데이터 처리 기술 활용 경험이 있는 분• Java/Python 중 1개 이상의 언어 및 SQL 숙련자 (복잡한 쿼리 작성 및 최적화 경험).,"데이터 인프라 관련 - Kubernetes 플랫폼 엔지니어링 경험 (클러스터 운영, 성능 최적화, 트러블슈팅)을 보유한 분 - 분산 쿼리 엔진 및 실시간 OLAP 엔진 운영 및 최적화 경험을 보유한 분 - 모던 데이터 레이크 포맷 및 클라우드 매니지드 웨어하우스 활용 경험을 보유한 분플랫폼 개발 관련 - 데이터 카탈로그 및 메타데이터 관리 시스템 구축 경험을 보유한 분 - 워크플로우 오케스트레이션 도구(Airflow) 개발 및 운영 경험을 보유한 분 (Provider/Plugin 개발 및 커스터마이징 포함)기술 전환 및 마이그레이션 - 레거시 분산 처리 프레임워크에서 현대적 쿼리 엔진으로의 전환 경험을 보유한 분 - 전통적 데이터 웨어하우스에서 클라우드 네이티브 솔루션으로의 마이그레이션 경험을 보유한 분기타 - GitOps 기반 배포 자동화 도구 활용 경험을 보유한 분 - 메트릭 기반 모니터링 및 알림 시스템 구축 경험을 보유한 분 - 팀 내 업무 자동화를 위한 도구 개발이 가능한 분[주요기술]• 주요 기술 : Java, Scala, Spark, Python, Flink, Airflow, SpringFramework, NoSQL(Redis, Elasticsearch, MongoDB 등), Kafka, AWS Services, SQL• 업무 도구 : GitLab, Jira, Confluence, Jenkins• 코드 리뷰 : GitLab MR로 온라인 코드 리뷰 진행• 빌드, 배포 : Jenkins, GitLab CI, AWS CodeDeploy• 테스트 : GitLab CI로 유닛 테스트 및 통합 테스트."
블루개러지(Blue Garage),"""Backen Engineer"" 포지션은 새로운 형태의 엔터테인먼트를 글로벌 팬들에게 선보이기 위한 기술적 운영의 토대를 책임집니다. Creative·클라이언트·R&D와 긴밀히 협업하며 고성능 아키텍쳐를 설계·개발하고, 견고한 데이터 인프라를 구축하며, 다양한 AI 모델을 서버 환경에 배포하고 서빙합니다. 다수의 서비스를 섬세하게 연동해 end-to-end 지연을 최소화하고, 모니터링·로깅·알림 체계를 통해 신뢰도 높은 시스템을 운영합니다.• 리얼타임 AI 서비스를 위한 백엔드 시스템 아키텍처 설계 및 개발• 어플리케이션 및 AI 서비스를 위한 데이터 인프라(데이터베이스, OpenSearch 등) 설계 및 운영• 저지연, 고성능 API(gRPC, WebSocket, REST) 설계 및 개발• 다수의 서비스를 실시간으로 연동하고 end-to-end 지연을 최소화하는 백엔드 로직 구축 및 운영• 다양한 AI 모델을 서버 환경에 배포하고 안정적으로 서빙• 서비스 모니터링, 로깅, 알림 시스템 구축 및 성능 최적화.","• Python 등 하나 이상의 백엔드 언어에 능숙하고, 3년 이상의 백엔드 시스템 개발 경험• 비동기 프로그래밍, 멀티스레딩, 로드밸런싱 기법에 대한 이해• RESTful API 설계 원칙에 대한 깊은 이해와 고성능 API 개발 경험• AI 모델의 추론 파이프라인 구축 경험• 실시간 데이터 처리 및 스트리밍 시스템에 대한 이해• 사용자 세션이나 대화 로그 관리를 위한 데이터베이스 설계 경험 및 Redis 등의 캐시 사용 경험• R&D 엔지니어, 클라이언트 엔지니어 등과 긴밀히 협력하여 요구사항을 구현할 수 있는 분.","• DevOps 관련 경험(Docker 등 컨테이너, Kubernetes 등의 오케스트레이션 도구 사용 경험 및 AWS/GCP 등 클라우드 환경에서의 서비스 운영 경험)• MLOps 관련 경험(GPU 인스턴스 운영, 모델 CI/CD, 모델 모니터링, A/B 테스트 등 머신러닝 모델의 프로덕션 운영에 대한 이해)• 백엔드 최적화를 통해 유의미한 성과를 내본 경험• 스타트업 환경 경험이나 처음부터 아키텍처 설계 및 구현을 주도해본 경험• Terraform, Ansible 등 IaC 도구 사용 경험• LLM, TTS 등 생성형 AI 모델을 활용한 서비스 개발 또는 운영 경험• 글로벌 서비스 개발 또는 운영 경험."
에이머슬리,"• 백엔드 API 개발 및 유지보수 (REST/gRPC 서비스 설계 및 구현)• 데이터 파이프라인 설계 및 운영 (ETL, 실시간 스트리밍 처리)• 대규모 제조 시계열 데이터 수집/저장/분석 인프라 구축• 마이크로서비스 아키텍처 설계 및 서비스 간 통신 구현• 컨테이너 및 클라우드 기반 서비스 배포/운영 (Kubernetes, Docker 등)• 서비스 성능 최적화 (쿼리 튜닝, 캐싱 전략, 시스템 병목 해소 등).","• 백엔드 개발 실무 경험 (언어 무관: Python, Java, Node.js, Go 등)• RESTful API 설계 및 구현 경험• RDBMS 실무 경험 (PostgreSQL, Oracle, MySQL 등)• Docker 기본 사용 능력• Git 버전 관리 경험.","# 우대 역량• Python 실무 경험 (미경험 시 빠른 학습 가능)• 비동기 프로그래밍 경험 (async/await, reactive 등)• NoSQL 사용 경험 (MongoDB, DynamoDB, Redis 등)• 메시지 큐 활용 경험 (Kafka, RabbitMQ 등)• Kubernetes 또는 클라우드(AWS/GCP/Azure) 운영 경험• MSA, DDD, CQRS 등 아키텍처 패턴 적용 경험• gRPC, GraphQL 등 다양한 API 프로토콜 경험 # 태도 요건• 시간이 걸려도 끈기와 인내로 문제를 끝까지 풀어내는 분 복잡한 문제도 쉽게 포기하지 않고, 세심한 관찰과 집중력으로 근본적인 해결을 찾으시는 분• 최신 기술보다 문제의 본질을 올바르게 해결하는 것을 우선하시는 분 유행보다는 문제의 구조와 원인을 정확히 이해하고, 가장 단단한 방법으로 접근하시는 분• 주어진 일 안에서도 주도적으로 의미와 재미를 찾으시는 분 맡은 일의 주체가 되어 스스로 동기를 부여하고, 개선과 성장을 즐기시는 분• Iteration(반복)에 거부감이 없는 분 자신의 결과를 다시 뒤집고 새롭게 시도해야 하는 상황을 자연스럽게 받아들이며, 과정 속에서 배우고 더 나은 방향으로 나아가는 유연함과 포용력을 지닌 분# 주요 기술 스택 (참고)• Backend: Python, FastAPI• Database: PostgreSQL, MongoDB, Redis• Infra: Kubernetes, Docker, Kafka• Auth: Keycloak, OAuth 2.0# 성장 기회• 반도체 제조 AI 서비스의 전체 시스템 구조를 함께 설계하며 성장합니다.• AI 모델, 데이터 파이프라인, 인프라를 아우르는 End-to-End 개발 경험을 쌓을 수 있습니다.• 복잡한 산업 환경 속에서 현실에서 작동하는 AI 시스템을 만드는 경험을 얻게 됩니다."
베이글코드(Bagelcode),• 이런 일을 함께하고 싶습니다.- 대규모 트래픽을 안정적으로 서빙하기 위한 확장성있는 고가용성의 데이터 서비스 플랫폼 설계 및 개발- 다양한 데이터 프로덕트 및 데이터 서비스의 성능 개선을 위한 최적화- 머신러닝을 활용하여 라이브 서비스 중인 프로덕트들에 실시간으로 피드백을 주는 데이터 서비스 개발.,"• 이런 역량을 가지신 분을 찾습니다.- Python / Scala / Go 중 1개 이상의 언어에 능숙하신 분- 알고리즘, 데이터구조, OS, 데이터베이스 등 기본적인 전산 지식에 대한 이해를 갖추신 분- 컨테이너 기반의 서비스 배포에 익숙하신 분- 클라우드 환경에서의 개발 및 운영 경험이 있으신 분.","• 이런 역량을 가지신 분을 우대합니다.- 대규모 시스템 아키텍처에 대한 설계 및 개발 경험이 있으신 분- Hadoop, Spark, Kafka, Hive 등 분산 시스템 설계 및 구축 경험이 있으신 분- 백엔드 및 서버 엔지니어로 3년 이상의 개발 경력이 있으신 분- 쿠버네티스와 같은 컨테이너 오케스트레이션 시스템에서 서비스 운영 경험이 있으신 분- AWS 등의 클라우드 환경에서 Terrraform 등의 IaC를 이용한 인프라 설계 및 운용 경험이 있으신 분- DB / SQL query 최적화 경험이 있으신 분."
게임듀오,"데이터 파이프라인 구축 및 관리• 다양한 소스(클라이언트 로그, MMP, 운영 DB 등)에서 발생하는 모든 데이터를 클라우드 기반 데이터 웨어하우스(DW)에 효율적으로 수집하고 유지 관리합니다.데이터 모델링 및 품질 관리• 분석 목적에 맞는 데이터 마트(DM)를 설계하고 구현합니다.• 데이터 정합성 및 품질 관리를 위한 데이터 거버넌스 체계를 구축하여 신뢰성 있는 데이터를 제공합니다.데이터 플랫폼 개발• 데이터 활용 환경 개선을 위해 자체 클라이언트 로그 수집 및 A/B 테스트 플랫폼을 개발하고 고도화합니다.인프라 운영• GCP 등 클라우드 환경에서 데이터 관련 인프라를 안정적으로 관리하고 최적화합니다.","데이터/백엔드 등 관련 업무 경력 포함 2년 이상이신 분클라우드 환경에서 데이터 엔지니어링 실무 경험이 있는 분Python 등 스크립트 언어를 활용하여 ETL/ELT 파이프라인을 구축하고 관리할 수 있는 분효율적인 DW/DM 모델링(dimensional modeling 등)에 대한 이해와 실무 경험이 있는 분복잡한 SQL 조인, 윈도우 함수 등을 자유롭게 사용하여 데이터를 가공하고, 쿼리 실행 계획 분석 및 최적화 경험을 보유한 분데이터 분석가, 기획자 등 다양한 팀원들과 명확하게 소통하고 협업하여 비즈니스 요구사항을 데이터로 구현할 수 있는 분주도적으로 문제를 정의하거나 찾고 해결해나가는 과정을 즐기시는 분.","Airflow, dbt 등 워크플로우 자동화 및 데이터 변환 도구 사용 경험을 통해 생산성을 높일 수 있는 분CDC(Change Data Capture)나 Kafka와 같은 기술을 활용하여 실시간 데이터를 처리한 경험이 있는 분빠른 데이터 기술 생태계 변화속에서 새로운 기술 및 지식 습득이 빠르고 성장을 즐기는 분."
버킷플레이스(오늘의집),"• 오늘의집 서비스 전반에 대한 품질 관리 참여(요구사항 분석, 테스트 케이스 작성 및 실행) • 테스트 자동화 스크립트 개발 (UI, API) 및 지속적 개선• 테스트 자동화 프레임워크 유지보수 및 운영 (Github Action, Jenkins 등).","• QA 분야에서 3년 이상의 실무 경험이 있는 분• (필수) Appium, Playwright, Selenium 등 테스트 자동화 도구 경험이 있는 분 (Android, iOS, Web)• 모바일 앱/웹 서비스에 대한 높은 이해도를 갖춘 분• 유연한 커뮤니케이션 능력과 자기주도적인 QA 업무 경험이 있는 분• Postman 등 API 테스트 도구 활용 경험이 있는 분• Github Action, Jenkins 등 CI/CD 테스트 자동화 환경 구축 및 운영 경험이 있는 분• Python, Java, JavaScript 등 프로그래밍 능력을 보유한 분• 테스트와 관련한 다양한 방법론 및 기술에 대한 습득력을 갖춘 분.","• 컴퓨터공학 전공 혹은 그에 준하는 소프트웨어공학 기반 지식을 보유한 분• 애자일 스프린트, MVP 단위 개발 프로세스에서의 QA 경험이 있는 분• JIRA, Slack, Confluence 등의 협업툴 사용 경험이 있는 분• ISTQB, CSTS 등 테스트 관련 자격증 보유한 분• AI를 활용해 QA 업무를 개선한 경험이 있는 분• 성능 테스트 경험 (JMeter, Ngrinder, K6 등) 보유한 분• 테스트 자동화 프레임워크 설계 및 도입 경험이 있는 분."
컬리,"커머스, 물류, 고객 행동 로그 등 마켓컬리 전반의 데이터를 집계 및 가공하여 데이터 마트 개발/운영대시보드 및 슬랙 알림 등 다양한 데이터 프로덕트 개발 및 운영데이터 카탈로그 구축 및 유지보수, 표준화 등 데이터 거버넌스 업무 수행.","관련 경력 5년 이상 보유하신 분GCP 등 클라우드 기반 인프라 환경 경험이 있으신 분SQL 및 Python을 활용한 데이터 처리 및 서비스 개발 경험이 있으신 분Airflow 등 워크플로우 관리 도구의 개발 및 운영 경험이 있으신 분데이터 마트 구축 및 운영 경험이 있으며, 분석 목적에 맞춘 데이터 모델링이 가능하신 분.","Tableau, Looker 등의 BI 도구를 활용한 데이터 시각화 경험이 있으신 분Git을 활용한 버전 관리 및 협업 경험, Airflow 기반 데이터 파이프라인 구축 경험이 있으신 분자동화된 데이터 품질 검사(Quality Check) 경험을 보유한 분."
파이프트리(paiptree Inc.),"담당 업무 I Main Responsibilities• 농업 환경 및 생체 데이터 분석을 통해 문제의 원인과 개선 포인트를 규명• 정형/비정형 데이터(영상, 사운드 등)에서 새로운 분석 관점 발굴• 지속 가능한 서비스 개선을 위한 데이터 파이프라인 설계 및 유지• 조직 내 다양한 팀과 협력하여 데이터 인사이트 기반 의사결정 지원.","핵심 역량| Core Competencies• 현상의 이면을 파악하고 원인을 밝혀내려는 탐구적 성향• 통계적 사고와 분석을 통해 복잡한 데이터를 단순하고 명확하게 설명할 수 있는 능력• 새로운 분석 기법이나 도구를 학습• 적용하여 데이터 기반 문제 해결에 앞장서는 태도• 데이터를 단순 나열하는 것을 넘어, 그래서 왜 이런 현상이 발생했는가""를 설명하고 제안할 수 있는 능력• 다양한 직군과 협업하며 인사이트를 공유할 수 있는 커뮤니케이션 역량.","우대 사항 I Preferred Qualifications• 머신러닝/딥러닝 모델 개발 및 서비스 적용 경험• 클라우드 기반 데이터 분석 경험 (AWS, GCP, Azure 등)• 데이터 파이프라인 구축/최적화 경험• 스타트업 환경에서 주도적으로 문제를 정의하고 해결한 경험• 외국어 커뮤니케이션 능력 (영어 등)."
로이드케이,ㆍ대용량/실시간 데이터 수집/처리 및 모니터링 시스템 설계/운영ㆍ키워드/벡터 검색 시스템 구축 및 최적화 성능 튜닝ㆍ이상 탐지/예측 분석 및 트렌트 분석 시스템 구축ㆍ데이터 파이프라인 구축 및 자동화.,"ㆍPython/Shell Script 기반 데이터 파이프라인 자동화 경험ㆍLinux 및 클라우드 환경(AWS, GCP, Azure 등) 활용 경험ㆍ문제 해결 능력 및 원활한 커뮤니케이션 역량 보유.","ㆍ컴퓨터 공학, 시스템 공학 등 관련 전공ㆍ기술 컨설팅, 고객사 대응 또는 프로젝트 리딩 경험ㆍ대용량/실시간 데이터 수집 파이프라인 설계 및 운영 경험ㆍJava/Python 기반 검색 서비스 개발 및 운영 경험."
화해글로벌,"• DB, 로그, Third party 등 다양한 소스데이터로부터 배치 및 실시간 데이터 입수 개발• RAW 데이터를 정제 및 가공하여 조회 및 분석이 가능한 파생 데이터 제공• 데이터 운영 효율화 및 자동화를 고려한 데이터 모델링• Workflow 배치 파이프라인을 개발 및 운영하여 신뢰성 높은 데이터 처리 및 제공• 데이터 사이언티스트, 분석 엔지니어, DevOps 와 긴밀한 협업.","• 데이터 엔지니어 경험이 3년 이상이신 분• 다양한 데이터 소스로부터 수집 경험이 있으신 분(DB, 로그, third party)• 데이터 처리 및 가공을 위해 SQL 작성 능력이 있으신 분• 워크로드와 비즈니스를 고려한 데이터 모델링이 가능하신 분• Airflow 또는 유사한 워크플로우 오케스트레이션 도구(Luigi, Oozie 등) 사용 및 운영 경험이 있으신 분• Python, Java, Scala 중에서 1개 이상 개발 경험이 있으신 분• 기술은 목적이 아닌 수단으로, 문제 해결을 최우선으로 생각하시는 분• 다양한 직군의 동료들과 원할하게 소통할 수 있도록 유연한 사고를 가지신 분.","• public cloud platform 기반의 데이터 엔지니어링 경험이 있으신 분(AWS, GCP)• 코드 기반 인프라 관리(IaC) 경험이 있으신 분 (Terraform, CloudFormation 등)• Kubernetes 기반 데이터 인프라 구성 및 운영 경험이 있으신 분• 데이터 플랫폼 구축 및 설계 경험이 있으신 분• 실시간 데이터 처리 어플리케이션 개발 경험이 있으신 분(spark, flink, storm 등)• 데이터 처리 및 플랫폼 운영 현황 모니터링·시각화 경험이 있으신 분 (Prometheus, Grafana, Elasticsearch, Kibana 등)• 워크로드에 최적화 된 NoSQL 도입 및 운영 경험이 있으신 분(DynamoDB, MongoDB, HBase, cassandra 등)• 신뢰성, 유연성, 확장성 중심의 데이터 아키텍쳐 설계 경험이 있으신 분• 새로운 기술을 학습하고 업무에 적용한 경험이 있는 분."
넛지헬스케어(캐시워크),"• SQL을 사용한 데이터 추출 및 전처리를 통한 지표관리• 주요 지표(KPI) 설계 및 대시보드 개발·관리• Funnel 분석, Cohort 분석, AARRR 분석을 통한 인사이트 도출• 서비스 개선을 위한 가설 수립 및 검증.","• 석사이상의 학위취득자 必• SQL (Bigquery), Python 등을 이용해 데이터 추출/가공/분석을 능숙하게 하실 수 있는 분• Data-Driven 커뮤니케이션이 가능하신 분• Funnel, AARRR, Cohort Analysis 등 데이터 분석 방법에 대한 지식과 경험이 있으신 분.","• GCP(BigQuery), Google Analytics 사용 경험이 있으신 분• 데이터 기반으로 서비스 품질 향상 및 마케팅 성과에 기여한 경험이 있으신 분• 데이터에 기반한 가설을 세워 A/B Test를 설계하고 진행해보신 분• 머신러닝 또는 예측 분석 경험이 있으신 분• 대용량 데이터 처리 경험이 있으신 분."
엘리스,"• 새로운 머신러닝 및 딥러닝 알고리즘을 연구 및 개발합니다. • Open Source 기반의 SOTA 모델을 플랫폼에 적용하고 성능을 높입니다. • 자체 플랫폼 데이터를 기반으로 knowledge tracing, code generation, copy detection 등의 알고리즘을 개발 및 플랫폼에 적용합니다. • LLM 및 SLM 기반의 특정한 지식이나 태스크에 최적화된 dialogue systems를 개발합니다. • AI와 사람 간의 자연스러운 통합을 위한 HCI 연구를 수행합니다. • MLOps 및 AutoML을 활용하여 production 환경에서 AI 모델의 성능 최적화 및 서비스에 효과적으로 통합하는 작업을 수행합니다.","• AI 및 머신러닝 분야에서의 학사 이상 학위 또는 이에 준하는 경험• 전문 지식 및 실무를 토대로 한 머신러닝 및 딥러닝 알고리즘 개발 능력• 데이터 분석 및 처리에 대한 전문 지식• NLP, 컴퓨터 비전, 음성 인식 등의 다양한 AI 기술에 대한 경험• 대규모 언어모델 및 대화 시스템, 코드 데이터셋에 대한 경험• 해외 논문 독해 및 비즈니스 레벨 영어 회화 능력• AI 도구를 활용해 업무 효율성을 높이고 성과를 최적화할 수 있는 역량 보유.","• AI 분야 논문 출판 경험• 엘리스가 보유한 AI 챗봇과 같은 프로젝트 경험• LLM의 개발 경험• TTS, STT, 지식 트레이닝, Safe AI, 음성 인식/평가 등 다양한 AI 연구 또는 개발 경험• 교육 분야에 대한 열정과 관심을 가진 분."
캐롯아이,"• 상권 및 부동산 데이터 처리• 데이터 수집.정제.가공을 포함한 데이터 파이프라인을 개발• 고객 산업 현장에서 AI 서비스를 안정적으로 제공할 수 있도록 배포와 운영을 책임• 신규 런칭되는 어플리케이션 및 B2B 시스템에 데이터 제공• 데이터 수집, 정제, 가공, 시각화 등 데이터 파이프라인 전 과정 설계 및 구현• 효율적인 데이터 처리 및 품질 관리 체계 구축• 인공지능 모델 개발 및 분석팀과의 협업.","• 관련 경력 1년 이상• Git, Docker, Airflow, CI/CD 등 개발 및 운영 도구 활용 경험이 있는 분• Python, SQL을 이용한 대용량 데이터 처리 및 분석 실무• 데이터 파이프라인 설계 및 ETL 개발 경험이 있는 분 * 우리는 이런 분을 찾고 있습니다데이터가 세상을 바꾼다고 믿는 분, 데이터 수집부터 정제·가공·시각화까지 엔드투엔드 파이프라인을 직접 구축하며회사의 데이터 인프라를 처음부터 함께 만들어갈 열정 있는 엔지니어를 기다리고 있습니다.초기 프로세스 구축 단계이기 때문에, 데이터 아키텍처 설계부터 운영 자동화까지 폭넓은 경험을 쌓을 수 있는 절호의 기회입니다.","• AI/ML 기반 서비스 기획 및 구축 경험이 있는 분• Python, TensorFlow, PyTorch 등 머신러닝 프레임워크 사용 경험을 보유한 분• Apache Spark (PySpark) 기반 분산 데이터 처리 실무 경험이 있으신 분• 초기 단계의 핵심 멤버로 참여하여 성장할 수 있습니다.• 다양한 산업 데이터와 실제 서비스 환경에서 경험을 쌓을 수 있습니다.• 유연한 업무 문화와 함께, 개인의 커리어 성장을 적극적으로 지원합니다."
케이티밀리의서재,"이 포지션은 AI서비스본부 데이터거버넌스팀 소속이에요.밀리의서재 데이터거버넌스팀은 데이터를 효율적으로 수집·관리하고, 이를 분석 가능한 형태로 가공해 조직의 의사결정을 지원하는 핵심 조직이에요.우리는 다양한 데이터 활용 요구를 이해하고 비즈니스 로직을 반영해 데이터 마트를 설계·구축하며, 데이터 기반 의사결정을 실질적으로 지원할 Data Analytics Engineer를 찾고 있어요.• 고객 행동 로그와 다양한 데이터를 기반으로 비즈니스 요구사항을 반영한 데이터 마트를 설계·구축해요.• BigQuery 기반 데이터 웨어하우스를 설계하고, 분석에 최적화된 구조로 발전시켜요.• AWS와 GCP(BigQuery) 환경에서 데이터 파이프라인을 설계·운영해요.• 데이터를 표준화하고 메타데이터 관리 체계를 구축해요.• 데이터 품질을 모니터링하고 자동화된 검증 체계를 운영해요.• 데이터 분석 및 활용을 위한 데이터 거버넌스 체계를 수립·운영해요.• 분석가와 데이터 사용자들과 협업해, 주요 성과 분석을 지원할 데이터 마트와 파이프라인을 개선·운영해요.• 정제된 데이터를 기반으로 BI/대시보드 구축을 지원해요.• 조직 내 데이터 활용도를 높이기 위한 문서화·가이드를 제공해요.• 분석가·비즈니스 담당자와 협력해 데이터 활용 니즈를 모델링에 반영해요.","• 3년 이상 7년 미만의 데이터를 활용하여 비즈니스 문제를 해결한 경험이 있는 분을 찾아요. • AWS와 BigQuery 환경에 익숙해야 해요.• SQL을 능숙하게 다룰 수 있어야 하고, 최적화된 쿼리를 작성할 수 있어야 해요.• Python을 활용해 데이터를 처리해본 경험이 필요해요.• Airflow 같은 워크플로우 관리 도구를 사용해본 경험이 필요해요.• 데이터 웨어하우스와 데이터 마트를 설계해본 경험이 있어야 해요.• 메타데이터 관리 정책이나 도구를 수립하고 운영해본 경험이 있어야 해요.• 데이터 품질을 관리하고 검증해본 경험이 필요해요.• 비즈니스 요구사항을 반영해 데이터 아키텍처를 설계한 경험이 있어야 해요.• 도메인별 데이터 마트를 설계·구성해 분석 환경을 최적화한 경험이 필요해요.• GitHub, GitLab 등 버전 관리 시스템을 통한 협업 경험이 필요해요.","• 콘텐츠·미디어·출판 업계 경험이 있다면 좋아요.• 구독형 서비스나 CRM/마케팅 데이터를 다뤄본 경험이 있으면 좋아요.• 데이터 분석을 통해 실제 비즈니스 KPI 개선에 기여한 경험이 있으면 좋아요.• 메타데이터 자동 수집 시스템을 개발해본 경험이 있다면 좋아요.• 다양한 직무의 구성원들과 원활하게 소통할 수 있어야 해요.• SQL을 능숙하게 다룰 수 있어야 하고, 가독성과 재사용성을 고려한 정돈된 쿼리를 작성할 수 있어야 해요.• Looker Studio, Superset 같은 BI/시각화 도구를 사용해보거나 운영해본 경험이 있으면 좋아요."
트웰브랩스(TwelveLabs),"About the RoleSoftware Engineer, Data Acquisition은 트웰브랩스의 멀티모달 AI 모델 학습을 위한 데이터 수집과 확보를 중심으로 하는 역할입니다.이 포지션은 영상, 오디오, 이미지, 텍스트 등 다양한 형태의 데이터를 획득·정리·가공하는 과정을 지원하고, 이를 위한 데이터 파이프라인과 툴을 개발합니다.데이터 라이프사이클 전반을 이해하고, 특히 데이터를 효과적으로 확보하고 준비하는 과정에서 엔지니어링 역량을 발휘할 수 있는 분을 찾습니다.In this Role, You Will• LLM/VLM 학습을 위한 대규모 멀티모달 데이터셋(영상, 이미지, 오디오)의 수집, 전처리, 정제, 필터링, 라벨링을 지원하는 데이터 파이프라인을 구축하고 운영합니다.• 실제 임팩트를 만들어내는 데이터 수집 라이브러리와 서비스를 구현하고 개선합니다.• 다양한 팀과 협업하여 프로젝트의 목표와 우선순위를 이해하고, 기획·개발·운영 단계 전반에 걸쳐 적극적으로 참여합니다.","You may be a good fit if you have• Python에 능숙하며, 간단한 스크립트 작성부터 데이터 처리/백엔드 서비스 개발까지 경험이 있으신 분• 웹 크롤링, API 연동, 데이터 수집 자동화 등 데이터 수집 관련 경험이 있으신 분• SQL을 사용하여 데이터 질의, 가공, 분석을 해본 경험이 있으신 분• Git 등 버전 관리 툴과 기본적인 CI/CD 흐름에 익숙하신 분• 2~3년 수준의 소프트웨어 엔지니어링 혹은 데이터 엔지니어링 실무 경험이 있으신 분.","Preferred Qualifications• 오픈소스/공개 데이터셋을 활용하거나 가공하여 프로젝트에 적용한 경험• 분산 데이터 처리 시스템(예: Spark, Dask, Ray) 혹은 워크플로 엔진(Airflow, Prefect 등) 경험• 클라우드 환경(AWS/GCP/Azure) 에서 데이터 처리·저장 관련 서비스(S3, BigQuery 등) 사용 경험• ML 학습용 데이터의 수집, 전처리, QA, 라벨링 과정에 참여한 경험."
한국딥러닝,"• AI 모델 학습용 데이터 생성 - 단순한 텍스트 데이터뿐 아니라 이미지, 문서 등 다양한 형태의 데이터를 생성 및 증강합니다. - 데이터 생성 규칙을 정의하고 체계화하여 일관된 품질을 유지합니다.• 데이터 품질 검수 (Q/A) - 생성된 데이터가 모델 학습에 적합한지 검수 및 피드백합니다. - 품질 기준을 수립하고, 지속적인 데이터 개선 프로세스를 운영합니다.• 데이터 처리 및 시스템화 - 데이터 생성 및 검수 과정을 자동화하고 모듈화하여 재사용성을 높입니다. - 간단한 스크립트 또는 툴을 개발 및 유지보수합니다.","• Python, SQL 등 데이터 처리 언어 활용 경험이 있는 분• 데이터 처리 및 관리에 대한 기본적인 이해를 보유하신 분• 새로운 도구나 프로세스 학습에 적극적인 태도를 가진 분• 꼼꼼하고 체계적으로 데이터 품질을 유지할 수 있는 분.",• AI 모델 학습 데이터 제작 또는 ML 프로젝트 경험이 있는 분• 자동화 스크립트 작성 또는 데이터 파이프라인 구축 경험이 있는 분• 세부적인 품질 관리 및 QA 프로세스 경험이 있는 분.
현대오토에버,• 스마트팩토리 전반의 데이터 파이프라인 개발 및 운영• Airflow를 활용한 파이프라인 자동화 업무• 비즈니스 요구사항에 따른 데이터 정제 및 클렌징• 신뢰성 있고 확장 가능한 데이터 서비스 설계 및 개발.,"• 엔터프라이즈 하둡 에코시스템에 대한 이해 및 실무 경험이 있으신 분• Hadoop, Hive, Spark 기반 데이터 처리 시스템 구축 및 운영 경험이 있으신 분• 대용량 데이터 처리에 효율적인 아키텍처 구성과 구조에 대해 이해가 깊으신 분• 데이터 마트, 데이터 웨어하우스에 대한 개념 및 언어(SQL, NoSQL)에 대한 경험이 있으신 분• Java, Scala, Python 중 하나 이상의 언어에 능숙하신 분.","• 프로젝트의 PL(Project Leader)로 프로젝트를 이끌며 진행한 경험• 생산 및 제조영역 환경에서의 개발 경험(제조 설비, 장비 데이터 수집)• 온프레미스/클라우드 기반의 데이터 플랫폼 개발 및 운영 경험• DevOps 기반 자동화 경험 (CI/CD)."
콜로세움코퍼레이션,"- 풀필먼트 물류 서비스 성과 평가 및 운영 효율화를 위한 핵심 지표 정의 및 개발 - 물류 서비스의 입고, 출고, 재고, 반품 등 운영 데이터를 기반으로 리포트와 BI 대시보드 서빙 - 데이터 서비스 이용자와의 인터뷰를 통한 요구사항 도출 및 분석 - 물류 운영팀, IT팀, 마케팅팀, 경영진과 협업하여 데이터 기반 문제 해결.","• 직무 역량 - 최소 2년 이상의 데이터 분석 또는 관련 업무 경험 - 물류 도메인에 대한 서비스 이해도 - DW/DM에서 SQL을 활용한 데이터 추출/분석 역량 - Tableau, Redash, Looker Studio, Lightdash 등의 시각화 도구 활용 경험 - 복잡한 물류 서비스 데이터에서 인사이트를 탐색하고 명확히 전달할 수 있는 커뮤니케이션 역량■ 공통 역량 - 문제를 발견했을 때 스스로 또는 필요한 협력을 통해 해결을 주도하시는 분 - 바쁘고 현실적인 제약 속에서 느리더라도 꾸준히 더 나은 방법을 모색하며 개선을 이어가시는 분 - 새로운 기술과 도메인 지식을 학습하며 지속적으로 성장하시는 분 - 다양한 직군과 원활히 협업하실 수 있는 분.","- BI 대시보드 서빙을 위한 데이터 처리 최적화 경험 - 데이터 파이프라인 및 dbt, Airflow 등 데이터 엔지니어와의 협업 경험 - 지표 고도화나 데이터 퀄리티 개선을 위한 서비스/데이터 측면의 개선점 도출 경험 - Self-BI를 위한 데이터플랫폼 환경 구축에 대한 이해도 보유."
코인원(coinone),"• 코인원 데이터 레이크 및 데이터 웨어하우스 데이터 모델링• 클라우드 기반 배치 및 실시간 파이프라인 환경 설계와 구현 및 운영• 분석 환경과 제품, 서비스를 위한 데이터 어플리케이션 구현 및 운영.","• 3년 이상의 데이터 엔지니어 경험이 있는 분• 데이터베이스 상 엔티티 및 관계를 능숙하게 파악하고 적절한 SQL로 표현하실 수 있는 분• 하나 이상의 프로그래밍 언어를 능숙하게 다룰 수 있는 분• 데이터웨어하우스(Redshift, BigQuery, Hadoop 등)를 운영한 경험이 있는 분• 퍼블릭 클라우드 환경(AWS, GCP)에서 데이터 엔지니어링 경험이 있는 분.","• 언어나 프레임워크에 구애받지 않고 요구사항에 적합한 아키텍쳐를 함께 고민할 수 있는 분• dbt, LookML 등의 데이터 모델링 경험이 있는 분• Airflow, Kafka를 사용한 데이터 파이프라인 구축, 운영 경험이 있는 분• 대용량 데이터 및 분산 처리에 대한 이해와 경험, 설계 경험이 있는 분."
소크라에이아이,"• 데이터 파이프라인 및 시스템 설계 및 개발: Socra AI에서는 데이터를 기반으로 한 의사결정, 비즈니스 인사이트 추출 및 머신러닝 모델의 효율적인 학습을 위해 고도화된 데이터 파이프라인과 시스템의 설계 및 개발을 진행합니다. Data Engineer로서 Socra AI의 다양한 서비스에서 필요로 하는 데이터를 신뢰성 있게 처리하고 서빙할 수 있도록 ETL 및 ELT 작업, 데이터 모델링, 데이터 웨어하우스 관리 등의 업무를 담당하게 됩니다.• 데이터 분석 및 ML 모델 서빙을 위한 데이터 시스템 개발: Data Engineer는 데이터 분석가 및 ML 엔지니어와 긴밀히 협력하여 분석 및 모델 학습에 필요한 데이터를 제공합니다. 이를 위해 실시간 데이터 처리 시스템과 배치 처리 시스템을 개발 및 최적화하며, 데이터 품질과 가용성을 보장합니다.• 데이터 기반 의사결정 지원을 위한 인사이트 제공: 데이터 엔지니어링 팀은 회사 내 다양한 부서와 협력하여 데이터를 통한 인사이트 제공을 목표로 합니다. 이를 위해 데이터 모델링, 데이터 분석 툴 개발 및 유지보수 등을 담당하며, 데이터 기반의 의사결정 과정을 지원합니다.","• 컴퓨터 과학(자료구조, 알고리즘, 운영체제, 데이터베이스 등)에 대한 깊은 이해와 탄탄한 기본 지식을 보유하신 분• 하나 이상의 프로그래밍 언어에 능숙하신 분 (Python / Java 등)• AWS, GCP 와 같은 클라우드 환경에서 데이터 플랫폼을 구축해 본 경험이 있으신 분.","• Marketing, PM, Data Scientist, DevOps 등 다양한 유관 부서와 협업한 경험이 있으신 분• ELT 기반 환경에서 DW / DM 구축 경험이 있으신 분• 배치, 스트리밍 처리를 위한 데이터 파이프라인을 구성해 본 경험이 있으신 분• Kubernetes 등 컨테이너 오케스트레이션 시스템을 활용한 운영 경험이 있으신 분• Terraform 과 같은 IaC(Infrastructure as Code)를 이용하여 인프라를 구축 및 운영해 본 경험이 있으신 분."
리디(RIDI),"리디의 다양한 제품에서 쌓인 데이터를 Feature Store로 관리하고, 다양한 직관과 가설을 통해 추천 시스템 모델을 학습합니다.학습된 모델을 다양한 이해관계자와 함께 A/B 테스트하고, 결과를 기반으로 지속적인 개선합니다.ML 모델을 배치 및 실시간 환경에 맞게 Triton Inference Server 등에 배포합니다.모델 학습 데이터셋 관리 및 ML 엔지니어와 협업을 통한 학습을 효율화합니다.대규모 로그 및 이벤트 스트림 수집·처리 합니다.데이터 레이크 및 데이터 마트 설계·운영 합니다.데이터 품질 모니터링 및 파이프라인 자동화, 워크플로우 관리(Airflow 등)를 합니다.","5년 이상의 소프트웨어(데이터 파이프라인, ML 서빙 시스템 등) 설계 및 운영 경험이 있으신 분ML 모델을 서비스에 배포하기 위해 여러 직군과 협업할 수 있는 커뮤니케이션 역량이 있으신 분Python 기반 데이터/ML 도구(PySpark, Pandas, Airflow, PyTorch 등) 숙련되신 분모델 학습용 데이터셋 설계 및 피처 엔지니어링 경험이 있으신 분분산 처리 및 데이터 아키텍처에 대한 이해가 있으신 분알고리즘, 데이터 구조, OS, 데이터베이스 등 기본 전산 지식이 있으신 분.","대용량/실시간 데이터 분산 처리 시스템 설계 및 운영 경험이 있으신 분AWS/GCP 등 클라우드 환경에서 대규모 데이터 인프라 설계 경험이 있으신 분Hadoop MR, Hive, Spark 등 분산 처리 기술 관련 개발 경험이 있으신 분데이터 파이프라인/ETL 시스템 설계 및 운영 경험이 있으신 분대용량 로그/이벤트 기반 추천·검색 시스템 구축 경험이 있으신 분데이터 품질 관리 및 모니터링 시스템 구축 경험이 있으신 분데이터 팀 리딩 또는 프로젝트 오너십 경험이 있으신 분."
모요,"# 합류하면 이런 업무를 해요• 북극성 지표(North Star Metric, NSM)를 바탕으로 각 스쿼드가 OKR을 잘 설계할 수 있도록 도와요.• 목표 달성을 위한 지표와 가설을 설정하고, 다양한 A/B 테스트를 설계 및 분석하여 실행 가능한 항목을 제안해요.• 팀에 인사이트를 줄 수 있는 대시보드를 만들고 관리해요.• 비즈니스에 필요한 데이터를 분석하고 발견한 인사이트를 동료들에게 공유해요.• 마케팅 성과 분석 지표(ROAS, CTR, CVR…)를 설계하고 매체별로 분석해요.",# 모요와 함께 해요＜이런 분을 찾고 있어요＞• 3년 이상의 프로덕트 데이터 분석 업무 경험이 있는 분• 데이터를 전처리하고 시각화하는데 필요한 SQL 역량을 갖춘 분• 데이터를 기반으로 다양한 가설을 세우고 분석해 본 분• 주어진 분석을 하기보다 주도적으로 데이터를 보고 인사이트를 도출할 수 있는 분• 실험 결과를 비롯한 데이터 인사이트를 동료들에게 설명해 본 분.,"＜이런 분이면 더 좋아요＞• 클라우드 환경에서 데이터 분석을 해본 분(AWS, GCP…)• 프로덕트 조직에서 A/B 테스트 경험이 있는 분• 분석툴을 활용한 업무 경험이 있는 분 (Amplitude, Mixpanel)• 대시보드 툴을 활용해 본 분 (Redash, Tableau, QuickSight…)• 팀 전체가 데이터를 더 잘 볼 수 방법에 대해 고민하는 분."
엔라이즈(NRISE),"＜ Data Analyst로 합류하게 된다면, 아래의 경험을 함께할 수 있어요 ＞• 제품의 성장을 위한 지표를 설정하고 다양한 데이터를 분석하여 목표를 달성하기 위한 가설을 세웁니다. 가설을 검증할 A/B 테스트를 설계하고 결과를 분석하여 인사이트를 찾아냅니다.• 위피 한국은 국내 데이팅앱 시장에서 확고한 입지를 다지고 있으며, 위피 재팬은 일본 시장에서 의미 있는 시작을 만들어가고 있습니다. 또한 콰트는 홈트레이닝 앱으로 다양한 도전을 통해 성과를 쌓아가고 있습니다. 다양한 도메인과 성장 단계에 있는 서비스들의 데이터를 한 회사 안에서 경험하며 다룰 수 있습니다.＜ 엔라이즈의 Data Analyst가 담당할 업무에요 ＞• 데이터 분석가로서 같은 목표를 가진 스쿼드에 소속되어 동료들과 협업합니다.• 데이터를 분석해 제품 성장을 위한 가설을 세우고, 이를 평가할 지표를 설정합니다.• 제품 분석에 필요한 유저 행동 로그를 설계하고, 이를 다른 데이터와 엮어 유저의 행동을 이해합니다.• 원활한 데이터 분석 환경을 위해 데이터를 수집·정제하고, 분석용 데이터 마트를 구축합니다.","＜ 엔라이즈는 이런 분을 찾고 있어요 ＞• SQL과 Python을 사용해서 데이터를 자유자재로 다룰 수 있는 분• 데이터에서 발견한 인사이트를 논리적으로 설명할 수 있는 분• 다양한 직군의 동료들과 원활하게 소통하며, 데이터 관점을 쉽게 풀어 설명할 수 있는 분.","＜ 이런 분이라면 더 환영해요 ＞• 새로운 기술을 학습하는 데 있어 허들이 낮고, 학습 속도가 빠르신 분• Machine Learning을 이용하여 제품을 개선 또는 운영한 경험이 있는 분• Airflow, Python, Redash, Quicksight 사용 경험이 있는 분."
커브컴퍼니,"• 의료용 AI 에이전트 모델 학습 파이프라인 개발 및 운영• Docker, Kubernetes 기반 멀티테넌트 SaaS 인프라 구축• CI/CD 파이프라인을 통한 배포 자동화 및 모니터링 시스템 구축• 의료 데이터 보안 규정에 맞는 데이터 처리 파이프라인 개발.","• 컴퓨터공학, 데이터사이언스 또는 관련 분야 전공 (신입 지원 가능)• 머신러닝 기초 지식 및 실습 경험• Git 사용 경험• 새로운 기술 학습에 대한 열정과 적극성.","• Docker, Kubernetes 사용 경험• 클라우드 플랫폼(AWS, GCP, Azure) 사용 경험• MLOps 관련 프로젝트 또는 스터디 경험• AI 에이전트 또는 생성형 AI 모델 활용 프로젝트 경험."
판테라,"• Proteomics 데이터(DIA, DDA, TMT 등) 기반 Deep Learning 모델 설계 및 학습• Bio/Omics 데이터를 사용한 representation model 학습 및 예측 모델 개발• Transcriptome-proteomics 간 다중 공선성 분석 및 multi-omics 통합 AI 모델 개발• Biological interpretation 가능한 모델 구조 설계• 대규모 실험 데이터 기반 데이터 전처리 및 파이프라인 구축.","• 컴퓨터공학, 생명정보학, 통계학, 생물학 등 관련 전공• Bio/Omics 데이터 기반 ML/DL 모델 개발 경험• PyTorch 또는 TensorFlow 등 딥러닝 프레임워크 사용 능력• 데이터 분석, 정규화, feature engineering 등 전처리 파이프라인 구축 능력• 논문/코드 기반 모델을 재현하거나 실험에 맞게 커스터마이징하는 역량.","• Proteomics 데이터 분석 경험 (DIA/DDA/TMT 등)• Multi-omics 통합 분석, 전사체-단백체 연계 예측 경험• Self-supervised / contrastive learning 기반 representation learning 경험• Biological context-aware modeling 경험• 논문 작성, 학회 발표, 오픈소스 기여 등 연구 커뮤니케이션 경험."
데이터라이즈,"• 500곳이 넘는 고객사의 3억 건이 넘는 주문 데이터를 비롯한 모든 커머스 데이터와 일 5천만 건 이상의 고객 행동 로그를 비즈니스 요구사항에 맞춰 준실시간부터 일 주기로 수집하고, 계속 늘어가는 고객사에 대응할 수 있는 EtLT 데이터 파이프라인을 설계, 개발, 운영합니다.• 데이터라이즈 서비스 및 전사 구성원이 사용하는 데이터 인프라 및 데이터 레이크, 클라우드 기반의 여러 기반 인프라를 설계, 개발, 운영하고, 다양한 데이터 사용자들의 요구사항을 처리하고 새로운 가치를 제공할 수 있도록 지속적으로 인프라를 발전시킵니다.• 비즈니스 요구사항에 맞춰 수억 건의 데이터를 분산 처리할 수 있는 어플리케이션 및 서빙 시스템을 설계, 개발, 운영하고 복잡한 데이터를 질서있게 안정적으로 생성하는 방법들을 적용합니다.• 글로벌 서비스를 위한 데이터 엔지니어링 방법론을 설계하고, 필요한 모든 곳에 적용합니다.","• 데이터 엔지니어링 및 플랫폼 개발/운영 경력이 있으신 분• 분산 처리 이론과 기술 (Spark 등) 에 대한 이해를 가지신 분• 한 개 이상의 프로그래밍 언어 (Python 등) 에 능숙하신 분• 클라우드 환경에서의 데이터 엔지니어링에 익숙하신 분• 데이터 엔지니어링을 통해 비즈니스 문제를 해결한 경험이 있거나, 해결하고자 하는 열의가 있으신 분• 데이터 분석가, 사이언티스트 혹은 타 팀과의 커뮤니케이션이 원활하신 분.","• 대용량 및 실시간 데이터 분산 처리에 대한 개발 경험 혹은 깊은 이해를 가지신 분• 사용하는 기술의 원리를 깊게 파악하고, 실무에 적용해보신 분• 비즈니스 도메인 지식을 재빠르게 학습하고, 다양한 동료들과의 협업을 통해 문제를 해결하실 수 있는 분• 정의되지 않은 과제를 정의하고 스스로 해결하는 것을 즐기시는 분• 스타트업의 불합리함과 모호함을 뚫고 번창하실 의지가 있는 분• 여러 국가와 타임존을 아우르는 데이터 엔지니어링 경험이 있으신 분."
한솔피엔에스,• 그룹 데이터 플랫폼 데이터 수집·처리 파이프라인 구축 및 운영• 데이터파이프라인 개발 및 운영• DataLake 구조 설계 및 파티셔닝 전략 수립• 메타데이터 및 데이터 변환 관리* 그룹 데이터 플랫폼 데이터 거버넌스 정책 수립 및 운영• 거버넌스 모델 설계 및 운영• 데이터 품질 검증 및 오류 관리 프로세스 실행*그룹사 데이터 분석 및 활용 지원• Athena/QuickSight 기반 데이터셋 제공 및 최적화• 계열사별 분석 요구사항 반영 및 활용 환경 제공.,"• AWS 데이터 플랫폼 기반 데이터 엔지니어링, 플랫폼 구축·운영 경험• AWS 데이터 서비스 활용 기술 보유(S3, Glue, Datazone, Lake Formation, Redshift, DMS 등)• SQL 및 Python 기반 데이터 처리 능력• ETL/ELT, CDC, 데이터 파이프라인 설계 및 운영 경험• 데이터 모델링 및 파티셔닝 전략 수립 경험• BI 도구(QuickSight, Tableau, Power BI 등) 활용 경험.","• AWS Bedrock기반 AI챗봇 구축 경험• 데이터 거버넌스/메타데이터 관리 경험• 대규모 데이터 레이크/데이터 웨어하우스 구축 경험• MLOps 또는 데이터 사이언스 환경 연계 경험 (SageMaker, EMR 등)• laC(Infrastructure as Code, Terraform/CloudFormation) 활용 경험• AWS자격증 Data Analytics - Specialty, Solutions Architect• 제조/스마트팩토리 도메인 경험• 그룹사 데이터 플랫폼 구축 및 운영 경험."
펑타이그레이터차이나(PTKOREA),"• AWS Kubernetes 환경에서 데이터 플랫폼 구축 및 운영• 데이터 분석, 활용 및 플랫폼 구축, 데이터 리니지 관리• 데이터 플랫폼 전체 아키텍처 설계, 배포, 모니터링, 문제 해결 및 운영 정책 수립• 비용과 성능을 고려한 효율적인 데이터 플랫폼 기술 검토 및 도입.","• 학사 이상이신 분• Kubernetes, Airflow, Trino, Flink, Spark, Python, Parquet, Iceberg, Vertica 등의 활용 역량을 보유하신 분• 유관 경력 3년 이상 혹은 그에 준하는 데이터 엔지니어 업무 경험이 있으신 분.","• Kubernetes에 익숙하신 분• 데이터 파이프라인 개발 경험이 있으신 분• Spark, Flink 개발 및 튜닝 경험이 있으신 분• 이해관계자들과 원활하고 적극적인 커뮤니케이션이 가능하신 분• 데이터 엔지니어링 전반에 걸친 다양한 업무 경험이 있으신분."
위버스컴퍼니(WEVERSE COMPANY),"• 데이터 기반 의사결정을 지원하기 위해, 다양한 데이터 소스로부터 데이터를 수집, 가공, 적재하는 배치 및 실시간 ETL 파이프라인을 설계하고 구축합니다.• LLM과 데이터 디스커버리(Data Discovery) 기술을 활용하여, 전사적인 데이터 민주화를 가속화하는 플랫폼을 개발하고 고도화합니다.• 대용량 트래픽에 대응 가능한 로그 수집 파이프라인을 구축하고 운영합니다.• 안정적이고 효율적인 데이터 분석 환경을 위한 인프라를 구성하고 개선합니다.• Kubernetes(k8s) 기반의 데이터 플랫폼을 안정적으로 운영하고 고도화합니다.","• 업계 경력 7년이상, 데이터 엔지니어로서 3년 이상의 실무 경험을 보유하신 분• Kotlin, Java 등 JVM 언어 또는 Python 중 하나 이상에 능숙하신 분• Spark, Hadoop, Flink 등 대용량 분산 처리 프레임워크 사용 경험이 풍부하신 분• GCP(BigQuery, Dataproc), AWS 등 클라우드 환경에서 데이터 파이프라인을 구축하고 운영해 보신 분[필요역량] • 주도적으로 문제를 정의하고 해결해 나가는 도전 정신과 책임감• 새로운 기술에 대한 지적 호기심과 빠른 학습 능력• 다양한 부서의 동료들과 원활하게 소통하고 협업하는 능력• 비즈니스와 기술을 아우르는 폭넓은 시야와 문제 해결 능력[과제 및 테스트] • 실무 면접 시 시스템 설계 과제 진행 후 기술 면접 진행• 이력서와 함께 지원자 본인이 참여했던 프로젝트에 대한 포트폴리오도 포함하여 지원 (포트폴리오 제출시 가산점 부여).",• Spring Boot 등 Kotlin/Java 기반 백엔드 개발 경험이 있으신 분• Kubernetes 환경에서 애플리케이션 또는 플랫폼 운영 경험이 풍부하신 분• MLOps 환경을 구축하거나 AI 서비스 파이프라인을 설계하고 운영해 보신 분.
빗썸,"• MySQL(Aurora 등) 기반 RDB의 고가용성 아키텍처를 설계 및 운영하며, 24/7 안정적인 서비스를 위한 모니터링, 백업/복구, 장애 대응을 주도합니다.• 백엔드 개발자들이 최적의 쿼리를 작성할 수 있도록 SQL 쿼리 리뷰 및 튜닝, 인덱스 전략 수립, 테이블 스키마 설계를 선제적으로 지원하고 가이드합니다.• 단순 쿼리 튜닝을 넘어, 락(Lock) 경합, 시스템 파라미터 튜닝 등 DB 시스템 전반의 성능 병목을 분석하고 근본적인 해결책을 제시합니다.• 반복적인 DB 운영(스키마 변경, 데이터 마이그레이션, 백업 검증 등)을 자동화하는 스크립트(Python, Shell) 및 도구를 개발하여 운영 효율성을 극대화합니다.• 블록체인 트랜잭션 등 대용량 데이터 분석을 위한 새로운 데이터베이스(Data Warehouse, NoSQL 등) 도입을 리서치하고 PoC를 수행하며, 향후 데이터 아키텍처의 확장을 준비합니다.","• MySQL(Aurora, RDS 등) 기반 RDBMS의 고가용성 환경을 주도적으로 설계, 구축, 운영해 본 경험을 보유하신 분• 대용량 데이터 환경에서의 SQL 쿼리 최적화 및 인덱스 전략 수립 역량을 보유하신 분• 장애 대응, 락(Lock) 분석, 성능 병목 트러블슈팅에 대한 깊은 이해를 보유하신 분• Python, Shell 등 스크립트 언어를 활용한 DB 운영 자동화 개발 경험을 보유하신 분.","• 핀테크 또는 거래소 환경에서 미션 크리티컬 트랜잭션 DB를 다뤄본 경험을 보유하신 분• 대용량 데이터 분석을 위한 데이터 웨어하우스 및 OLAP DB 운영 경험을 보유하신 분• ETL/ELT 파이프라인 구축 등 데이터 엔지니어링 관련 업무 경험 또는 높은 관심을 보유하신 분• IaC(Terraform), 클라우드(AWS/GCP), Kubernetes 환경에서의 DB 운영 경험을 보유하신 분• 개발팀의 요구사항을 깊이 이해하고, 선제적으로 스키마 설계와 쿼리 개선을 제안하는 적극적인 협업 태도를 보유하신 분• 데이터 전반에 대한 강한 오너십을 가지고, 안정성과 확장성을 주도적으로 고민하는 자세를 보유하신 분[근무조건]• 고용형태 : 수습평가 후 정규직 전환• 근무장소 : 서울 강남구 테헤란로 124 삼원타워 (주)빗썸 본사• 급여 : 회사 내규에 따름 (인터뷰 후 결정)."
샐러드랩,"• 데이터 품질 관리(DQ) 프로세스를 적용하여 데이터의 정확성과 일관성을 확보합니다.• 데이터 인프라의 성능 개선 및 비용 최적화를 위한 기술 검토 및 도입을 주도합니다.• 데이터 기반의 개인화 마케팅 캠페인 및 CRM 활동을 위한 데이터 활용 환경을 지원합니다.• 고객 식별 및 통합(ID Resolution)을 통해 통합 고객 프로파일을 구축하고 관리합니다.• 실시간 및 배치 데이터 처리 아키텍처를 구현하고 최적화하여 데이터 적시성을 확보합니다.• 다양한 소스 시스템(CRM, 웹/앱 로그, 이커머스 등)으로부터 데이터를 수집, 변환, 적재(ETL/ELT)하는 데이터 파이프라인을 설계하고 구축합니다.","• 데이터 엔지니어링 또는 관련 경력 3년 이상의 경험 및 역량을 보유하신 분.• Python, SQL을 이용한 대용량 데이터 처리 및 분석 실무 경험을 보유하신 분.• 대용량 데이터 환경에서의 ETL/ELT 파이프라인 설계 및 개발 경험을 보유하신 분.• 데이터 모델링 및 스키마 설계에 대한 기본적인 이해를 보유하신 분.","• AWS 데이터 서비스 실무 경험(Glue, S3, Redshift, Athena, Kinesis 등)• 실시간 스트리밍 데이터 처리 기술 경험(Kafka, Kinesis, Flink 등)• CDP(Customer Data Platform) 구축 또는 운영 경험• 개발 및 IT 관련 전공자 또는 이에 준하는 지식을 보유하신 분."
누아,"• 항공·여행 산업에서 발생하는 비정형 텍스트 데이터(공지사항, 이메일, 채팅 등)의 수집 및 정형화 체계 구축• 정형화된 데이터를 기반으로 한 업무 자동화용 데이터 처리 파이프라인 설계 및 구현• 도메인 특화 LLM 기반 챗봇 학습을 위한 고품질 학습 데이터 생산 파이프라인 개발• 챗봇 응답 정확도 향상을 위한 데이터 전처리 및 후처리 로직 설계• 자동화 시스템의 일관성 및 성능 향상을 위한 데이터 품질 진단 및 지속적 개선.","• 주어진 문제를 논리적으로 분석하고, 현실적인 해결 방향을 스스로 도출할 수 있는 능력• 상대방의 말과 의도를 정확히 읽어내고 자신의 생각을 조리 있게 설명할 수 있는 능력• 하나 이상의 프로그래밍 언어를 익숙하게 다룰 수 있는 능력• 어떤 일이든 끝까지 책임지고 완수하려는 자세• 알고리즘과 자료구조에 대한 기본적인 이해.",• 항공·여행 산업에 대한 관심 또는 관련 경험• 자료구조의 내부 동작 원리를 이해하고 직접 구현해본 경험• 자신이 작성한 코드의 메모리 사용량이나 실행시간을 측정하고 최적화해본 경험• 복잡한 문제나 방대한 코드베이스를 이해하기 위해 문서나 코드를 집요하게 분석해본 경험.
더블유컨셉코리아(W컨셉),"[검색데이터개발팀 소개]고객의 구매 경험 향상과 비즈니스 성과 극대화를 위해 빅데이터 및 추천, 빅데이터를 활용한 신규 서비스를 개발하는 팀이에요.이커머스 데이터 플랫폼 및 데이터 기반 신규 서비스를 개발하고 있어요.데이터와 실험을 중심으로 한 의사결정을 중시하며, 끊임없는 개선과 학습을 통해 더 나은 서비스를 개발해요.서로의 아이디어를 자유롭게 제안하고 빠르게 검증하는 열린 개발 문화를 지향하고 있어요!새로운 기술을 적극적으로 도입하고 실험하는데 주저하지 않으며, 개인의 성장과 팀의 성과가 함께 확장되는 경험을 하실 수 있어요.[주요업무]• 다양한 소스(DB, API, Streaming 등)로부터의 데이터 수집·정제·적재(ETL/ELT) 파이프라인 설계 및 개발• AWS/GCP 기반 데이터 레이크/웨어하우스(Data Lake / DWH) 구축 및 운영• Spark, Kafka, Kinesis, PubSub 등의 분산 처리 및 ETL 기술을 활용한 대규모 데이터 처리 워크플로우 개발• 데이터 엔지니어링 및 플랫폼 관련 성능 및 운영 방식 최적화.","• 데이터 엔지니어 경험 3년 이상• 대용량 데이터 파이프라인 설계, 구축, 운영 경험이 있으신 분• AWS, GCP 환경에서 데이터 처리 및 분석 경험이 있으신 분• Spark, ELK, Kafka 등의 기술에 대한 이해도 및 활용 경험이 있으신 분• Python 혹은 Java 등 하나 이상의 언어를 습득하신 분.","• 대규모 데이터 분산 처리 개념에 대한 이해를 바탕으로 로직 설계 및 구현 경험이 있으신 분• AWS, GCP 등 클라우드 기반 데이터 인프라 구축 및 운영 경험이 있으신 분• 데이터 엔지니어링을 통해 비즈니스 문제를 해결한 경험이 있으신 분• 대규모 트래픽 환경에서 성능 최적화 및 안정적인 서비스 운영 경험이 있으신 분• 비지니스와 프러덕에 대한 이해를 바탕으로 최신 기술의 활용을 주도적으로 제안할 수 있는 분• 원활한 커뮤니케이션 능력을 보유하신 분."
미소(miso),"[미소에서 하게 될 업무는요]• 비즈니스 성장을 위한 대시보드 구축 및 데이터 분석을 수행합니다. - 비즈니스 의사결정을 위한 대시보드 구축 - 데이터 가공, A/B 테스팅, 가설 검증, EDA 등 데이터 분석 - 매출 증대를 위한 사업 전략 및 데이터 분석• 공급과 수요 관리를 위해 알고리즘을 개선하고 가격 전략을 수립합니다. - 파트너 모집의 효율 증대를 위한 대시보드 구축 및 전략 제시 - 매칭 알고리즘 개발 및 프로세스 개선 - 파트너 활동을 장려하기 위한 추천 알고리즘 개발 - 수요와 공급 균형을 위한 가격 전략• 전략적 문제 해결 및 연구를 위한 지원을 제공합니다. - 문제 정의 및 해결 방안 도출 - ad-hoc 데이터 분석 지원 - Qualitative Research 수행.","[이런 분과 함께하고 싶습니다]• 데이터 주도적 업무 수행 및 결과 도출, 문제 해결이 가능하신 분• 복잡한 데이터를 단순하고 직관적인 형태로 표시하고 결과를 명확, 간결한 방식으로 제시할 수 있으신 분• 스스로 문제를 정의하고 해결책을 도출하며 결과에 따른 다음 액션까지 연결시킬 능력이 있으신 분• 개인이 아닌 팀 플레이에서의 시너지를 중시하고 협업을 지향하시는 분• 원활하고 프로페셔널 한 커뮤니케이션이 가능하신 분• 성과 지향적이신 분.","[이런 분을 우대합니다]• 데이터 시각화 도구(예: Tableau, PowerBI 등) 사용 경험이 있는 자• 학술적 또는 취미 프로젝트에서 실제 데이터 처리 및 분석 경험이 있으신 분• 기계 학습 및 인공 지능에 대한 기본적인 이해를 가지고 있는 자• 영어 회화 유창하신 분."
이노션,"• 글로벌 디지털 마케팅 데이터를 위한 파이프라인 설계·구축·운영 (BigQuery, Cloud Functions, Cloud Run 등 클라우드 기반 환경 활용)• 광고 플랫폼·웹 로그 등 다양한 소스 데이터 수집 및 적재 자동화 (Python을 통한 Google Ads, Meta, GA4 연동)• 글로벌 캠페인 성과 분석을 위한 데이터 마트 설계·구축·운영• 데이터 품질 관리 및 최적화 (무결성 검증, 이상 탐지, 비용 효율화 쿼리 구조 설계).","• 전문학사 이상• SQL 및 Python 기반 데이터 처리 경험• 클라우드 환경에서 데이터 구축 및 운영 경험• 대용량 데이터 최적화 및 파이프라인 운영 경험• 최종합격 후, 지정 입사일에 입사 가능하신 분• 해외 출장에 결격 사유가 없는 분 (남성의 경우, 회사가 지정한 입사일까지 병역을 마쳤거나 면제되신 분).","• Google Ads, Meta, GA4 등 광고/마케팅 데이터 경험 보유자• 빅쿼리(BigQuery) 또는 다른 데이터 웨어하우스 활용 경험• 데이터 파이프라인(ETL/ELT) 구축 또는 자동화 프로젝트 경험• IAM(권한 관리) 및 보안 설정 이해."
모두싸인,"• 계약 및 문서 중심의 지능형 Agent를 설계 및 구현합니다. (LLM + Tool + Memory 기반)• 계약서 내 정보 추출, 의미 분석, 요약, 리스크 탐지 등 고차원의 AI 기능을 설계합니다.• Retrieval-Augmented Generation (RAG) 및 Hybrid Search 시스템을 개발하고 최적화합니다.• 다양한 LLM(OpenAI, Claude, Gemini, Llama 등)의 성능을 비교하고 비용과 품질을 최적화합니다.• LLM inference pipeline을 구성하고 prompt engineering 전략을 수립합니다.• 문서/계약 데이터 embedding, vector search, metadata 관리 파이프라인을 구축합니다.• 내부 제품군(Form, eSign, Cabinet, Review 등)에 AI 기능을 내재화하고, API를 연동합니다.• AI 품질 평가 체계(AI evals, hallucination test, grounding metric 등)를 설계하고 개선합니다.","• AI/ML 전공자 또는 그에 준하는 연구·산업 경력을 3년 이상 보유한 분• 대규모 언어모델(LLM), NLP, 정보 검색(IR), 또는 지식 기반 시스템 관련 프로젝트 경험이 있는 분• Python 기반 ML/NLP stack(PyTorch, Transformers, LangChain, LlamaIndex 등) 사용에 능숙한 분• RAG 또는 Agent 시스템의 설계/구현 경험이 있는 분• Vector DB(Qdrant, Weaviate, ElasticSearch Vector 등)와 Embedding pipeline 설계 경험이 있는 분• LLM API(OpenAI, Anthropic, Gemini 등) 활용 및 성능 최적화 경험이 있는 분• SaaS 환경 혹은 대규모 데이터 파이프라인 상에서 AI 기능을 서비스화한 경험이 있는 분.","• AI/ML, 컴퓨터 공학 등 관련 전공 분야 석사 이상의 학위를 보유하신 분• 문서 처리/계약 관리(CLMS, e-signature) 관련 NLP 또는 Information Extraction 경험이 있는 분• OCR, Table Understanding, Layout-aware Document Parsing 경험이 있는 분• Multi-agent orchestration, Planning-based Agent 설계 경험이 있는 분• Prompt evaluation, reinforcement learning from feedback (RLAIF 등) 경험을 가지신 분• LLM latency/cost optimization을 위한 caching, batching, parallelization 설계 경험을 가지신 분• AWS Bedrock, SageMaker, Vertex AI 등 클라우드 AI 플랫폼 활용 경험이 있는 분• 논문 구현, 오픈소스 기여, 연구 중심 PoC를 Product로 전환 경험이 있는 분."
현대오토에버,"• AWS/Azure/GCP/HMG Cloud 등 클라우드 인프라 설계·구축 및 운영• 컨테이너(Kubernetes, ECS), 벡터 DB, RAG 파이프라인, k8s 기반 LLM 배포 인프라 설계• CI/CD 파이프라인 설계 및 운영 (GitLab Runner, ArgoCD 등)• Tomcat, Netty, Nginx 등의 미들웨어 자동 배포• APM, Zabbix, ESM 등을 활용한 모니터링 및 장애 감지• 장애 1선 대응을 위한 장애 분석, 롤백, 패치 적용• 모의해킹, HMG 보안원칙에 따른 보안 스캔·정책 적용 및 규정 준수 관리.","• AWS/Azure/GCP/HMG Cloud 등 클라우드 인프라 설계·구축 및 운영의 숙련• 컨테이너·오케스트레이션(Docker, Kubernetes, ECS 등) 운영 경험• CI/CD 툴 전문성 (GitLab Runner, ArgoCD, Docker, Kubernates 등)• 클라우드 플랫폼(AWS/Azure/GCP) 운영 능력• Java/Python/Bash 등 스크립팅 및 자동화 역량• Spring boot 활용 역량.","• 풀스택 DevOps 역량: 코드부터 모델 배포까지 자동화 및 통합 운영 가능• 장애 대응 및 트러블슈팅: 신속한 장애 탐지 및 예방 활동 경험• 협업 주도력: 개발자, 기획자 등과 협업하여 빠른 릴리즈 주도를 경험• 문제해결 능력: 롤백, 모니터링, 성능 이슈 대응에 능숙한 즉각 대응 역량."
힐링페이퍼(강남언니),"• Streaming data pipeline 구축, stream 처리 작업 개발 및 운영• Data 적재 작업 개발, 정합성 관리 및 운영• Data Platform 개선 및 운영• Data Warehouse 및 Data Mart 모델링• A/B testing 플랫폼의 데이터 수집, 정합성 관리.","• 3년 이상 Data Engineering을 경험하신 분• 머신러닝 엔지니어, 데이터 분석가와의 협업 경험을 보유하신 분• 데이터 수집/저장/처리의 데이터 파이프라인 설계 및 운영 경험을 보유하신 분• Data Warehouse, Data Mart의 데이터 모델링 경험을 보유하신 분• 뛰어난 SQL 사용 능력을 갖추신 분.","• aws cloud에 대한 이해와 경험이 있으신 분• Debezium, Kafka, Flink 등을 활용한 CDC pipeline 구축, 운영 경험이 있으신 분• dbt 이용한 데이터 처리 경험이 있으신 분• Spark 등 빅데이터 처리에 대한 경험이 있으신 분• Airbyte, Snowflake, Airflow 등의 구축 및 운영 경험이 있으신 분• MLOps pipeline 구축에 경험 또는 관심이 있으신 분."
모요,# 합류하면 이런 업무를 해요• 전사 데이터 마트를 설계하고 구축하여 팀이 필요한 데이터에 쉽게 접근할 수 있도록 해요.• Airflow 기반 데이터 파이프라인을 운영하고 안정성을 개선해요.• BigQuery 환경을 최적화하고 효율적인 데이터 아키텍처를 설계해요.• 데이터 품질을 모니터링하고 거버넌스 체계를 구축 및 운영해요.• 비즈니스에 필요한 데이터를 분석하고 발견한 인사이트를 동료들에게 공유해요.• 팀에 인사이트를 줄 수 있는 대시보드를 만들고 관리해요.,"# 모요와 함께 해요＜이런 분을 찾고 있어요＞• 3년 이상의 프로덕트 데이터 분석 업무 경험이 있는 분• SQL/Python을 활용한 데이터 전처리, 시각화, 파이프라인 구축이 가능한 분• 데이터를 기반으로 가설을 세우고 주도적으로 인사이트를 도출할 수 있는 분• Airflow를 활용한 데이터 파이프라인 운영 및 트러블슈팅 경험이 있는 분• 전사 데이터 마트 설계 및 구축 경험이 있는 분• GCP(BigQuery) 환경에서 데이터 아키텍처를 이해하고 운영할 수 있는 분.","＜이런 분이면 더 좋아요＞• 클라우드 환경에서 데이터 분석을 해본 분(AWS, GCP…)• 프로덕트 조직에서 A/B 테스트 및 분석 툴(Amplitude, Mixpanel) 활용 경험이 있는 분• 대시보드 툴(Looker, Tableau) 구축 및 운영 경험이 있는 분• 데이터 모델링 및 파이프라인 자동화 경험이 있는 분 (dbt, Airflow 활용)• 데이터 거버넌스 체계 구축 및 운영 경험이 있는 분• 팀 전체가 데이터를 더 잘 볼 수 방법에 대해 고민하는 분."
카카오모빌리티(kakaomobility),• 모빌리티 및 물류 서비스의 비즈니스 목표를 달성 또는 문제 해결을 위한 다양한 OR/RL/ML 프로젝트 수행• 머신러닝 모델의 개발-서빙-모니터링 파이프라인 설계 및 구축• ML/DL 학습 및 추론 워크플로우 자동화를 위한 MLOps 파이프라인 개발.,"• 관련 경력 5년 이상• Python, Java, Kotlin, Kubernetes, GCP, Airflow, CI/CD 등 개발 환경에 익숙한 분• MLOps 파이프라인 개발 및 운영 경험이 있는 분• 데이터 파이프라인 설계 및 ETL 개발 경험이 있는 분.","• 물류, 배차, 모빌리티, 라이드헤일링 등 도메인 관련 경험이 있는 분• 대규모 트레이닝/서빙 환경에서 리소스 및 성능 최적화 경험이 있는 분."
두나무(업비트/증권플러스),• 대용량 및 준-실시간 데이터 가공을 위한 쿼리 엔진 등 컴퓨팅 플랫폼구축 및 운영• 실시간 서비스 지원을 위한 메세징 큐 등 실시간 플랫폼 구축 및 운영• 웨어하우스 가공 및 적재를 위한 워크플로우 등 웨어하우스 플랫폼 구축 및 운영• 전사 데이터 플랫폼 구축을 통한 비즈니스 기여 및 데이터 생산성 개선.,"• 만 4년 이상의 데이터 엔지니어링 경력을 보유하신 분• AWS 클라우드와 Kubernetes 환경에서 데이터 플랫폼을 구축 및 운영해본 경험이 있으신 분• Kubernetes 환경에서 데이터 가공을 위한 컴퓨팅 엔진 및 스토리지 (Spark, Trino, Starrocks, Kafka, KSQL 등) 를 운영해 본 경험이 있으신 분• Kubernetes 환경에서 데이터 분석 및 가공을 위한 시스템을 (Redash, Superset, Jupyter, Airflow, Dolphin Scheduler 등) 를 구축해본 경험이 있으신 분.","• 국내외의 가상자산 또는 금융 컴플라이언스 요건을 준수하며 데이터 플랫폼을 구축하고 내부 사용자에게 제공한 경험이 있으신 분• 데이터 인프라 제공을 넘어 고객의 생산성 및 비즈니스 기여를 위해 다양한 조직과 소통을 수행하고 주도적인 시스템 개선점을 찾아내실 수 있는 분• 문제 해결을 위해 오픈소스 코드를 직접 분석하거나 수정해 본 경험이 있으신 분• 서비스 모니터링 환경을 직접 구축하고 주도적으로 모니터링 하면서 장애를 대비한 경험이 있으신 분[지원서 작성 방법]• 이력서에는 실제 경험한 프로젝트를 필수로 기재해 주셔야 하며, 본인의 역할과 기여 내용을 구체적으로 작성해주시기 바랍니다.• 프로젝트명이나 결과만 나열하기보다는, 아래 항목을 참고하여 경험의 전반적인 맥락을 전달해 주세요. (예시: 프로젝트 개요, 목적, 팀 구성, 주요 업무, 문제 해결 과정, 기여 성과/결과 등)• Github, GitLab, Bitbucket 등의 개인 프로젝트나 포트폴리오가 있다면 함께 첨부해 주세요. 실무 경험과 역량을 이해하는 데 도움이 됩니다.[유의사항]• 이력서 및 포트폴리오는 필수로 제출하셔야 하며 양식은 자유입니다.• 재직 이력은 빠짐없이 정확하게 작성해 주시고, 휴직 이력이 있다면 기간과 사유를 구체적으로 기재해 주세요.• 채용 과정에서 전/현직 직장의 영업 비밀이 침해되지 않도록 유의해 주세요.• 주민번호, 현재 연봉, 희망 연봉 등 민감한 정보는 삭제하거나 마스킹 후 제출해 주세요.[공통 지원자격]• 해외 여행에 결격 사유가 없으신 분[채용절차]서류전형 ＞ 1차면접 ＞ 2차면접 ＞ 처우협의 ＞ 최종합격 • 1차면접 합격 시 실무진과의 커피챗이 진행될 수 있습니다.• 전형은 상황 및 일정에 따라 변경될 수 있습니다.• 지원서 내용 중 허위사실이 있는 경우에는 지원이 취소될 수 있습니다.• 국가 유공자 및 장애인 등 취업 보호 대상자는 관계 법령에 따라 우대합니다.• 최종 전형 전, 인성검사를 진행합니다• 본 포지션에 합격하시는 경우, 3개월의 수습 기간을 적용합니다.[채용정보]• 채용인원 : 0명• 고용형태 : 정규직• 채용유형 : 경력직• 근무지역 : 서울시 서초구 강남대로 369, DF Tower• 공고기간 : 상시채용 (채용 완료 시 조기에 마감될 수 있습니다.)."
빅밸류,• 데이터 파이프라인 설계/구축/운영• DL/DW/DM 구축/운영• AI 및 자동화 기술을 활용한 업무 효율화• 최신 데이터 처리기술 연구 및 도입• 데이터 처리 및 제어 SW 개발.,"• 경력: 무관• 공간 데이터, 빅데이터, 인공지능 기술 전반에 대해 관심이 있는 분• 해외 출장에 결격사유가 없는 분※ 전문연구요원 지원 가능.","• 데이터 파이프라인 구축 경험자• 컴퓨터공학, 산업공학, 데이터사이언스, 소프트웨어 아키텍처, 데이터 아키텍처 석사 이상 전공자• 통계학 및 데이터 분석 관련 지식 보유자• 다양한 직군의 이해관계자들과 효과적으로 소통하고 협업할 수 있는 커뮤니케이션 능력이 있는 분기술 스택• Postgresql, Airflow, Grafana, Python, DSL."
페이타랩(패스오더),"• 마케팅 또는 프로덕트 성과 측정을 위해 데이터 추출·가공·시각화까지 이어지는 데이터 파이프라인을 설계 및 구축해요.• KPI 및 연관 지표들을 명확히 정의하고, 전사적인 지표 관리 체계를 확립해요.• 사용자 행동 데이터 분석을 통해 심층적인 인사이트를 도출하고, 이를 바탕으로 패스오더 퍼널 전환율을 개선해요.• 데이터 분석 결과를 기반으로 도출한 솔루션의 기대효과를 예측하고, A/B 테스트와 후속 성과 측정을 통해 실제 비즈니스 임팩트를 측정해요.• 구성원이 데이터를 기반으로 심층적인 인사이트를 도출하고 의사 결정할 수 있도록 Data-Driven 환경을 만들어요.","• 비즈니스 목적에 맞는 데이터 파이프라인(ELT/ETL)을 설계 및 구축한 경험이 있는 분• SQL과 Python을 활용해 대용량 데이터를 추출• 정제• 가공• 분석할 수 있는 분• 모바일 서비스의 고객 행동 분석(Retention, Cohort, 세그먼트)과 마케팅 효율 지표(CAC, ROAS, ROI) 분석에 대한 이해가 있는 분• 문제정의 ＞ 가설수립 ＞ 실험설계(A/B 테스트) ＞ 성과측정 ＞ 개선으로 이어지는 실험 사이클을 직접 수행한 경험이 있는 분.","• 2년 이상의 마케팅/프로덕트 데이터 분석 혹은 데이터 엔지니어링 실무 경력이 있는 분• 빠르게 성장하는 IT 스타트업 환경, 특히 O2O·모바일 앱·식음료 도메인에서 근무한 경험이 있 분• BigQuery 등 클라우드 기반의 대용량 분석 환경에서 데이터 마트를 설계한 경험이 있는 분• 머신러닝 모델 학습 및 서빙을 위해 데이터 파이프라인을 구축 및 자동화한 경험이 있는 분• AI 툴을 활용해 리서치, 코드 생성, 리포팅 자동화 등 업무를 효율화한 경험이 있는 분• 조직 내 Data-Driven 문화 확산 및 데이터 리터러시 증대에 기여한 경험이 있는 분."
이노션,"• Web/App 내 사용자 행동 데이터 수집 환경 구축 및 운영 (Google Analytics 4, GTM, Pixel, Twitter, Floodlight, etc)• 개발자 가이드 문서 제작 (Confluence)• 데이터 분석 및 운영을 위한 데이터 마트 설계·구축·운영.","• 전문학사 이상• 총 경력 1년차 이상 필수• Web/App 내 Google Analytics 4 구축 및 운영 경험을 보유하신 분• 최종합격 후, 지정 입사일에 입사 가능하신 분• 해외 출장에 결격 사유가 없는 분 (남성의 경우, 회사가 지정한 입사일까지 병역을 마쳤거나 면제되신 분).","• 개발 언어 활용 역량 • Javascript, HTML, CSS • SQL (BigQuery 활용자 우대)• 마케팅 및 유저 행동 데이터에 대한 이해도• Web&App 개발/운영 경험 보유 혹은 앱 개발 언어(Kotlin, Swift) 활용 능력."
콘센트릭스서비스코리아CATALYST,"• 웹 데이터 크롤링 시스템 설계 및 개발• 반(反)봇 방어 우회 로직(IP 로테이션, 캡차 회피 등) 구현 및 운영• 크롤링 데이터의 수집 정제 적재 파이프라인(Data Pipeline) 구축 및 자동화• 크롤링 성능 모니터링 및 장애 대응• 수집된 데이터 품질 검증 및 유지.","• Python 기반 크롤링/스크래핑 개발 경험 1년 이상 (BeautifulSoup, Selenium, Requests 등)• SQL 활용 가능 (데이터 적재 및 검증 쿼리 작성 수준)• 클라우드 환경(AWS, GCP등) 구축 또는 운영 경험.","• 대규모 크롤링 시스템 운영 경험자 (분산 크롤링, 큐 기반 작업 관리 등)• IP 로테이션, User-Agent 관리, 프록시 서버 운영 등 차단 우회 경험자• FastAPI 또는 Flask 기반의 크롤링 API 서버 개발 경험• Airflow등 워크플로우 오케스트레이션 도구 활용 경험• 데이터 파이프라인/ETL 구축 및 운영 경험• Docker, Kubernetes 등 컨테이너 환경에서의 배포 경험*장애인 우대 채용하고 있는 포지션입니다. 지원서에 관련 내용 기재해 주시면 적극 반영할 예정입니다.또한 관련 규정에 따라 입사시 별도의 수당이 지급되오니 이 점도 참고 부탁드립니다."
오케스트로,"• RAG 구현을 위한 데이터 수집, 전처리, 임베딩 파이프라인 설계 및 개발• Vector DB(Milvus, Pinecone, FAISS 등) 스키마 설계, 구축 및 운영• LangChain, LlamaIndex 등 RAG 프레임워크를 활용한 데이터 증강 시스템 개발• 대용량 데이터 처리를 위한 분산 처리 시스템(Spark, Ray 등) 운영 및 최적화• 데이터 품질 관리 및 파이프라인 모니터링 시스템 구축.",• 3년 이상의 데이터 엔지니어링 또는 백엔드 개발 경험• Python을 이용한 데이터 처리 및 ETL 파이프라인 개발 능력• SQL 및 NoSQL 데이터베이스에 대한 깊은 이해• 대용량 데이터 처리 프레임워크(e.g. Spark) 사용 경험.,"• RAG 또는 검색 시스템(Elasticsearch 등) 관련 프로젝트 개발 경험• Vector DB 구축 및 운영 경험• Airflow, Kafka 등 데이터 파이프라인 관련 도구 사용 경험• 자연어 처리(NLP) 및 텍스트 데이터 마이닝에 대한 이해."
닥터스바이오텍,"• 데이터 파이프라인 구축: 의료 데이터 수집부터 처리, 적재까지 안정적이고 확장 가능한 ETL/ELT 파이프라인 설계 및 구현• 데이터 웨어하우스 설계: 분석 및 AI 모델 학습에 최적화된 데이터 웨어하우스 아키텍처 구축 및 운영• 데이터 인프라 최적화: 실시간/배치 데이터 처리 시스템의 성능 최적화 및 비용 효율화• 데이터 품질 관리: 의료 데이터 특성을 고려한 데이터 정합성 검증 및 품질 모니터링 시스템 구축• 크로스 팀 협업: 데이터 분석가, ML 엔지니어, 백엔드 개발자와 긴밀히 협업하여 데이터 요구사항 해결.","• Python을 활용한 데이터 처리 파이프라인 개발 경험 3년 이상• SQL 최적화 및 데이터 모델링 실무 경험• Airflow, Prefect 등 오케스트레이션 도구를 활용한 파이프라인 자동화 경험• AWS, GCP, Azure 중 최소 1개 이상 클라우드 환경에서의 데이터 엔지니어링 경험• Docker 기반 컨테이너화 및 배포 경험• Git 기반 협업 워크플로우 숙련도해외 여행에 결격사유가 없는 분 (해외 컨퍼런스 및 출장 가능).","기술 스택• Spark, Flink 등 분산 처리 프레임워크 운영 경험• BigQuery, Redshift, Snowflake 등 클라우드 DW 실무 경험• Kafka, Kinesis 등을 활용한 실시간 스트리밍 파이프라인 구축 경험• dbt, Great Expectations 등 데이터 품질 관리 도구 활용 경험• Terraform, CDK 등 IaC 도구를 활용한 인프라 자동화 경험도메인 경험• 의료 데이터 표준(HL7, FHIR 등) 처리 경험• HIPAA, 개인정보보호법 등 의료 데이터 규제 준수 경험• MLOps 파이프라인 구축 및 모델 서빙 인프라 운영 경험소프트 스킬• 초기 스타트업 환경에서의 빠른 의사결정과 실행 경험• 기술 부채를 고려한 실용적인 솔루션 설계 능력• 비기술 팀원들과의 원활한 커뮤니케이션 능력."
아이아이컴바인드,"• 데이터 파이프라인 및 인프라 구축 • 커머스 특화 ETL/ELT 파이프라인 설계 및 개발 (고객 행동, 상품 정보, 주문 데이터) • AWS Glue, EMR, Step Functions를 활용한 배치 및 실시간 데이터 처리 파이프라인 구축 • S3 기반 Data Lakehouse 아키텍처 설계 및 데이터 거버넌스 체계 구축 • Apache Airflow를 이용한 데이터 워크플로우 오케스트레이션 및 모니터링2. 실시간 데이터 스트리밍 및 분석 시스템 • Confluent Kafka와 AWS Kinesis를 활용한 실시간 데이터 스트리밍 아키텍처 설계 • Apache Spark Streaming, Kafka Connect를 이용한 실시간 데이터 처리 파이프라인 구축 • 실시간 고객 행동 분석 및 개인화 추천을 위한 이벤트 기반 아키텍처 구현 • ECS/EKS 컨테이너 환경에서의 데이터 처리 워크로드 운영 및 최적화3. 데이터 레이크하우스 및 분석 플랫폼 구축 • Databricks를 활용한 통합 데이터 레이크하우스 플랫폼 구축 및 운영 • Delta Lake 기반의 ACID 트랜잭션 및 데이터 버저닝 시스템 구현 • Amazon Redshift, Athena를 이용한 분석용 데이터 웨어하우스 설계 및 성능 최적화 • dbt를 활용한 데이터 변환 모델링 및 데이터 리니지 관리 • 셀프서비스 분석 환경 구축 및 BI 도구 연동 지원.","• 소프트웨어 엔지니어 경력 5년 이상 (그 중 데이터 엔지니어 실무 경험 3년 이상)• Python, SQL을 이용한 대용량 데이터 처리 및 분석 실무 경험 3년 이상• Apache Spark (PySpark) 기반 분산 데이터 처리 실무 경험이 있으신 분• AWS 데이터 서비스 실무 경험이 있으신 분 (Glue, EMR, S3, Redshift, Athena 중 3개 이상)• ETL/ELT 파이프라인 설계부터 운영까지 End-to-End 경험이 있으신 분• 컨테이너 환경에서의 데이터 워크로드 운영 경험이 있으신 분.","• Databricks 플랫폼 활용 경험 및 Unity Catalog, Delta Lake 구현 경험이 있으신 분• Confluent Kafka 또는 Apache Kafka 기반 실시간 스트리밍 파이프라인 구축 경험이 있으신 분• Apache Iceberg, Delta Lake 등 오픈 테이블 포맷 활용 경험이 있으신 분• dbt, Airflow, Prefect 등 모던 데이터 스택 도구 활용 경험이 있으신 분• DataOps, MLOps 파이프라인 구축 및 CI/CD 환경 구성 경험이 있으신 분• 시계열 데이터 분석 및 수요 예측 모델링 경험이 있으신 분 (ARIMA, Prophet, LSTM 등)• Amazon Forecast, SageMaker 등 AWS ML 서비스 활용 경험이 있으신 분• 커머스/리테일 도메인에서의 데이터 분석 시스템 및 셀프서비스 분석 환경 구축 경험이 있으신 분• 글로벌 재고 관리 또는 공급망 최적화 프로젝트 경험이 있으신 분."
뤼튼테크놀로지스,"• 24/7 무중단 운영을 목표로 데이터 플랫폼(Data Lake/Warehouse, Kubernetes Cluster 등)의 안정성과 확장성을 책임집니다.• 데이터 플랫폼의 상태를 정확히 진단하기 위한 Observability(Monitoring, Logging, Tracing) 시스템을 구축하고, 핵심 지표(SLI/SLO)를 정의하여 관리합니다.• 플랫폼 운영의 효율성과 안정성을 높이기 위해 반복적인 업무를 자동화하고, 내부 운영 도구를 개발합니다.• Airflow 기반의 데이터 파이프라인(DAG)을 개발하고, EKS 환경에서 안정적으로 운영 및 최적화합니다.• 데이터 분석가, 사이언티스트 등 유관부서와 협업하여 비즈니스 문제 해결을 위한 데이터 애플리케이션을 개발하고 지원합니다.","• Python을 이용한 프로그래밍에 능숙하며, 데이터 처리 및 애플리케이션 개발 경험이 있으신 분• Kubernetes (특히 EKS) 환경에서 실제 데이터 워크로드를 운영하고 관리해 본 경험이 있으신 분• Airflow를 사용하여 복잡한 DAG를 설계, 개발하고 운영해 본 경험이 있으신 분• SQL을 능숙하게 작성하고 데이터 모델링에 대한 이해가 있으신 분• 다양한 데이터 엔지니어링 영역(인프라, ETL, 데이터 모델링 등)에 대한 폭넓은 경험과 이해를 갖추신 분.","• BigQuery, Snowflake 등 클라우드 기반 DW 환경에서 대규모 트래픽을 안정적으로 운영해 본 경험이 있으신 • SRE(Site Reliability Engineering) 원칙에 대한 깊은 이해와 실제 서비스 적용 경험이 있으신 분• Prometheus, Grafana, Datadog 등을 활용하여 관측 가능성(Observability) 시스템을 직접 설계하고 구축해 본 경험이 있으신 분• GitLab CI, GitHub Actions 등을 활용해 데이터 애플리케이션 및 플랫폼의 CI/CD 파이프라인을 직접 설계하고 운영해 본 경험이 있으신 분• 대용량 데이터 처리 및 분산 시스템(e.g. Spark)에 대한 이해가 있으신 분."
두나무(업비트/증권플러스),• 데이터 시각화 웹 서비스 개발• Canvas·WebGL 기반 고성능 차트 및 인터랙티브 그래프 구현• 프로덕트 전반에서 활용 가능한 UI 컴포넌트 아키텍처 설계 및 유지보수• 마케팅/캠페인 페이지 개발• 내부 운영용 어드민 시스템 개발 및 유지보수• 대용량 데이터의 실시간 처리 및 시각화• 실시간 데이터 핸들링 및 캐싱 전략 구현• 자동화 테스트 환경 구축.,• 5년 이상의 웹 서비스 개발 경력 또는 그에 준하는 상용 서비스 실무 경험이 있으신 분• TypeScript·React·Vue·Nuxt·Next.js 기반의 고도화된 개발 역량이 뛰어나신 분• Canvas·WebGL을 활용한 고성능 렌더링 및 실시간 데이터 시각화 구현 경험이 있으신 분• React Query 기반 서버 상태 관리 및 대규모 데이터 캐싱 경험이 있으신 분• SSR 및 SEO 최적화를 통한 서비스 성과 개선 경험이 있으신 분• 복수 도메인(B2C·B2B·사내툴·마케팅 페이지 등)에서의 상용 서비스 개발 경험이 있으신 분• 웹 표준을 준수한 반응형 인터페이스 구현 경험이 있으신 분• 기획자·디자이너·백엔드 개발자 등과의 주도적인 협업 경험이 있으신 분• 요구사항 분석 기반 기능 구현과 단위·E2E 테스트를 통한 품질 관리 경험이 있으신 분• 대규모 트래픽 환경에서의 성능 최적화 및 신속한 배포 경험이 있으신 분.,• Highcharts·D3.js·ECharts 등 차트 시각화 라이브러리 활용 경험이 있으신 분• PixiJS·Cytoscape.js 등 WebGL 기반 그래픽 렌더링 및 대규모 관계 데이터 시각화 경험이 있으신 분• 대규모 트래픽과 데이터 확장을 지원하는 서비스 아키텍처 설계 경험이 있으신 분• 대규모 상태 관리 및 렌더링 환경 최적화 경험이 있으신 분• Unit·Visual·E2E 등 테스트 자동화 구축 및 운영 경험이 있으신 분• Webpack·Vite 등 빌드 시스템 최적화 및 CI/CD 파이프라인 운영 경험이 있으신 분• 핀테크·트레이딩·금융 서비스 도메인 경험이 있으신 분• AWS·Kubernetes 등 클라우드 인프라 활용 및 운영 경험이 있으신 분• 라이브러리·솔루션 형태 제품의 아키텍처 설계 및 배포 경험이 있으신 분.
센드버드코리아,"• 데이터베이스의 유연한 확장성, 비용 효율화, 운영 자동화 등 도전적인 개선 과제를 도출하고 수행 합니다.• 비지니스 확장 및 신규 서비스 발굴에 따른 최적의 데이터 관리 시스템을 설계하고 모델을 검토 합니다.• 클라우드 환경에서 전세계에 존재하는 mission-critical 대용량 데이터베이스들을 운영 합니다.• 고객의 다양한 needs를 만족 하는 성능과 가용성을 확보할 수 있도록 데이터베이스 관점의 해결책을 제공합니다.","• DB 업무 자동화를 위한 AI Agent 개발 경험이 있으신 분• 대규모 DB schema change를 위한 오픈소스 툴을 개발해 보신 분• Python 또는 Go 언어를 활용한 개발 및 자동화 스크립트 작성에 능숙한 분• Terraform과 같은 도구를 활용하여 인프라를 코드로 관리하고 배포(IaC) 이해도가 높은 분• Kubernetes (K8s) 또는 AWS EKS와 같은 컨테이너 오케스트레이션 플랫폼에서 서비스를 운영 및 관리 경험이 많은 분• Prometheus, Grafana 등을 활용하여 대규모 시스템 모니터링 및 트러블슈팅에 친숙한 분• Search 엔진, Redis/Valkey, MongoDB 등 NoSQL 데이터베이스 사용 경험이 있는 분• 다양한 부서와 능동적으로 소통하고 협업할 수 있는 능숙한 커뮤니케이션 스킬을 갖춘 분.","• 기술 문서, 테스트 환경 등에 친숙하고, 비지니스 요구 사항 및 어플리케이션 로직에 대한 이해• AI API, 머신러닝 모델, LLM 등 AI 기술을 활용하여 업무를 최적화·자동화에 관심이 많으신 분• ProxySQL, Vitess 와 같은 데이터베이스 프록시 사용 경험• Django와 같은 ORM (Object-Relational Mapping) 프레임워크에 대한 이해 및 사용 경험• 심층적인 DB admin에 대한 높은 관심."
한경에이셀,"데이터 플랫폼 엔지니어는 대체 데이터부터 자연어 및 비정형 데이터까지 모든 서비스에 걸친 다양한 데이터들의 안정적인 수급, 정제, 가공 및 전송 시스템의 개발과 운영을 담당합니다. 신속하고 안정적인 데이터 처리에 중추적인 역할을 하는 한경에이셀의 데이터 플랫폼 엔지니어로 합류하시면 다음과 같은 업무를 함께하게 됩니다.• 확장에 용이하고 안정적인 데이터 수급, 정제, 가공 시스템을 구현하고 운영합니다.• 데이터 라이프사이클을 고려한 스트리밍 혹은 배치 파이프라인을 설계합니다.• 서비스 혹은 데이터 특성에 맞는 컨테이너 기반의 CI/CD 전략을 수립하고 실행합니다.• 모니터링 부담을 최소화할 수 있도록 효율적인 운영 시스템을 고민하고 개선합니다.• 문제 발생 시 원인을 분석하고 해결 방안을 도출하여 지속적으로 개선합니다.• 지속 가능한 인프라를 설계하고 구축하여, 장기적으로 안정적이고 효율적인 서비스 환경을 만들어 갑니다.기술 스택• Python, uv/pip/poetry, asyncio• PostgreSQL, MySQL, Redis, MongoDB, OpenSearch• Kafka (streams/ksql/flink)• AWS, Kubernetes (EKS), ECS/Fargate, Docker• Airflow, ArgoCD, Datadog.","• 복잡한 문제를 분석하고 효과적인 해결책을 제시할 수 있는 문제 해결 능력• 데이터 라이프사이클 전반의 파이프라인 개발 경험• 확장성 있고 유연한 데이터 모델링 및 스키마 설계 역량• SQL 혹은 NoSQL 데이터베이스 설계 및 최적화 경험• 클라우드 환경과 컨테이너 기반 플랫폼(Docker, Kubernetes)에서의 배포 및 운영 경험.",• Airflow 등을 통한 ETL 및 워크플로우 작업 경험• Kafka 등을 통한 데이터 스트리밍 파이프라인 구축 경험• 데이터 레이크 혹은 데이터 웨어하우스 구축 역량• 분산 환경에서의 시스템 모니터링 및 트러블슈팅 경험• 지식 그래프 구축 혹은 운영 경험.
이지스헬스케어,-타사 소프트웨어 데이터 구조 분석-타사 프로그램 데이터 변환 개발 및 정합성 검증-업무 관련 자동화 도구 개발 및 기술지원 서비스.,"-기초 SQL 활용 능력: select, join, where 기본 쿼리 작성이 가능하신 분-데이터베이스 이해도: MSSQL/MySQL/PostgresSQL 중 택 1-기초적 프로그래밍 능력(C#)을 보유하신 분.",-유관업무 경험 보유하신 분-데이터 분석과 분석 중 오류를 개선하는 것에 흥미가 있으신 분-원활한 커뮤니케이션 역량을 보유하신 분.
위버케어,"• 병원 전자의무기록(EMR) 시스템의 데이터 마이그레이션 설계, 개발 및 실행• 다양한 형태의 기존 의료 데이터(DB, 파일 등)를 분석하고 PostgreSQL 기반 신규 시스템으로 이관• 마이그레이션 자동화 및 검증 스크립트 개발 (Node.js, TypeScript, NestJS 등 활용)• 데이터 정합성, 보안, 개인정보 보호 기준을 고려한 마이그레이션 정책 수립 및 관리• AWS 기반 클라우드 환경에서의 데이터 전환 작업 운영 및 배포• GitHub 기반의 형상 관리 및 협업기술 스택• Backend: TypeScript, NestJS, Node.js• DB: PostgreSQL, MySQL, 기타 관계형 DB• Infra: AWS (EC2, ECS, RDS, S3 등)• Tools: GitHub, Docker, CI/CD.","• Typescript, Node.js, NestJS 등 백엔드 개발 경험 3년 이상 또는 데이터 마이그레이션 관련 개발 경험• PostgreSQL을 포함한 다양한 관계형 데이터베이스 경험• GitHub 기반 협업 및 코드 리뷰 경험.","• EMR, EHR, 병원 전산 시스템 관련 업무 경험• 대용량 의료 데이터 처리 또는 민감 정보 처리 경험• 데이터 마이그레이션 자동화 또는 ETL(Extract-Transform-Load) 관련 실무 경험."
애자일소다,"• RAG 시스템 인프라 설계 및 구축• 데이터 파이프라인 구축• LLM 기반 AI 시스템 또는 Agent Workflow 시스템 개발• MLOps,LLMOps 환경 구축 및 운영• AI-OCR 시스템 구축 및 운영.","• Python 기반 AI 서비스 개발 경험이 있는 분• FastAPI 등 Python 웹프레임워크 개발 경험이 있는 분• React 기반 Frontend 개발 경험이 있는 분• Docker, Kubernetes 환경 서비스 개발 경험이 있는 분• RAG 시스템 구축 및 운영 경험이 있는 분• MariaDB, PostgreSQL 등 다양한 형태의 데이터베이스 경험이 있는 분• Javascript/TypeScript, Node.js 기반 backend 개발 경험이 있는 분.","• AI MLOps,LLMOps에 대한 이해가 있으신 분• AWS,GCP,Azure 등 클라우드 기반의 AI인프라 구축 및 관리 경험• LangChain, LlamaIndex 등 LLM 프레임워크 경험• 벡터 DB 및 검색 엔진 활용 경험• LLM 성능 최적화를 위한 프롬프트 엔지니어링 또는 RAG 구조 최적화 경험• AI 도구를 통한 개발자 생산성 향상, 자동화 개발 유경험자• GitHub 기여, 기술 블로그 운영, 개발 커뮤니티 참여 경험• 기술만이 아닌 ‘사용자 가치’를 고민하는 제품 중심 사고."
비상교육,"[포지션 안내]• 채용 구분 : 경력(8년 이상)• 근무 형태 : 정규직• 학력 : 대졸(4년제)• 채용 직무 : Backend 개발자[이런 업무를 합니다]• 서비스 UI 및 API를 구현합니다.• 시스템을 설계하고, 구현합니다.• 빌드, 테스트, 배포 정책을 수립하고, 자동화합니다.• Kubernetes (EKS) 환경을 설정하고 배포합니다.• 데이터를 수집, 분석, 모델링하고, 시각화합니다.","• Spring Boot(Java) 기반 백엔드 개발 능력이 있으신 분• 마이크로서비스아키텍처(MSA), 이벤트기반아키텍처(EDA)에 대한 이해 및 관련 경험이 있으신 분• AWS환경 (Docker, Kubernetes/EKS)에 대한 이해가 있고, CI/CD 파이프라인 구축 경험이 있으신 분• 서비스 운영, 모니터링, 트러블슈팅 능력이 있으신 분• 시스템 설계 및 기술 문제 해결 능력이 있으신 분• 데이터 기반 의사 결정 경험이 있으신 분[공통사항]• 관련학과 전공자 및 자격증 소지자는 우대합니다.• 국가보훈대상자 및 장애인은 관련법령에 의거 우대합니다.• 해외여행 또는 비자발급 요건에 결격사유가 없어야 하며, 남성의 경우 병역필 또는 면제자여야 합니다.","• 웹 보안 취약점에 대한 이해가 있고, 방어 구현의 경험이 있으신 분• B2C 사이트의 개발 및 운영 경험자• AI/ML 개발 경험이 있으신 분• Next.js(TypeScript) 기반 프론트엔드 개발 능력이 있으신 분• 클라우드 플랫폼(AWS)기반 데이터 활용 경험자• 데이터 파이프라인 구축 및 관리 경험자[저희 팀을 소개합니다]안녕하세요. 플랫폼개발1, 2Cell입니다. 저희는 비상교육 글로벌 Company 산하에 소속되어 있으며, 이름대로 글로벌시장을 타겟으로 다양한 플랫폼을 개발하고 운영합니다. 다양한 교육 컨텐츠를 연계하여 통합 플랫폼에서 제공하고, 컨텐츠를 작성하고 판매할 수 있는 마켓 플레이스, 그리고 AI 등 신기술을 활용한 교육 플랫폼을 직접 설계하고 구현합니다. 재미있고 보람있는 일들을 좋은 동료들과 협업하며 완성할 여러분을 모시고 싶습니다. [저희는 이렇게 일하고 있습니다!]• 다양한 서비스들을 연계하여 통합 플랫폼으로 구성합니다.• 신기술을 적용한 새로운 서비스를 기획하고 개발합니다.• 고객에게 더 나은 경험을 제공하기 위해 서비스를 개선하고 고도화합니다.[팀원의 한마디!]D CP님 ‍최고의 동료들과 함께 성장할 수 있어요~ 어려움이 생겨도 함께 이겨 나갈 수 있어요~ Y CP님 ‍기술적 도전을 통해 더 나은 서비스를 만들어가고 있습니다. 함께 고민하고, 함께 해결하며, 함께 성장할 분을 기다립니다. W CP님 ‍함께 성장하는 동료와의 협업을 소중히 합니다. 도전과 문제 해결의 과정을 즐기며, 더 나은 내일을 만들어갈 분을 기다립니다. S CP님 ‍우리는 새로운 도전을 즐기고, 변화를 통해 더 나은 서비스를 만들어갑니다.서로를 존중하며 함께 배우고 성장하는 팀, 단순한 일이 아닌 더 큰 가능성을 여는 여정이 기다리고 있습니다."
씨드로닉스,• 인공지능 학습용 RADAR 데이터 관리 : RADAR 데이터 검수 및 가공 관리 : 학습용 RADAR 데이터 가이드라인 수립.,• 관련 직무 최소 1년 이상 경력 필수· 이미지 편집툴(예)adobe photoshop)을 사용할 수 있는 컴퓨터 활용/학습 능력· 이미지 데이터 가공 또는 검수 경력 2개월 이상.,(우대) 인공지능용 학습데이터의 흐름에 대한 이해를 바탕으로 작업 및 관리할 수 있는 분(우대) 다양한 데이터를 응용하여 논리적인 결론을 도출해낼 수 있는 분(우대) Python 코드를 이용한 자체 툴 사용 경험 (코딩 능력 무관)(우대) 주도적으로 탐구하여 업무를 진행할 수 있는 분.
어센트코리아(Ascent Korea),"• ChatGPT 등 AI 응답 결과를 자동으로 수집(crawling, scraping)하는 시스템 개발 및 운영• 웹 브라우저 상의 특정 페이지(예: 검색결과, 문서 등) 데이터 크롤링• 수집한 데이터를 정제하고 Google Cloud Platform(GCP)의 데이터베이스(BigQuery 등)에 자동 적재• 수집/적재된 데이터를 조회/분석할 수 있도록 간단한 API 또는 대시보드 연동 지원• 크롤링 및 적재 자동화를 위한 스케줄링 시스템 관리 (예: Cloud Scheduler, Airflow 등)※ 자체 Saas솔루션인 리스닝마인드 허블에 대한 데이터 엔지니어 포지션은 아닙니다. 허블의 데이터도 활용은 하지만 컨설팅본부의 사업을 위한 별도의 데이터 엔지니어 포지션 입니다.","• 관련 경력 1~5년• 자연어 등 비정형 데이터 처리 경험• 웹 크롤링 및 데이터 수집 자동화에 대한 실무 경험 (HTML/CSS/DOM 구조에 대한 이해도)• Python기반의 자동화 스크립트 작성 능력 (Selenium, BeautifulSoup, Scrapy 등)• 데이터 정제 및 가공 경험 (pandas, SQL 등)• 데이터 파이프라인 구축/운영 경험 (ETL 또는 ELT)• GCP(Google Cloud Platform) 서비스 활용 경험 (특히 BigQuery, Cloud Storage, Cloud Functions 등)• Airflow 또는 Cloud Composer 등 워크플로우 스케줄러 활용 경험• Git 등 협업을 위한 기본적인 형상관리 도구 사용 능력.","• R, Node.js(선택) 활용 경험• JavaScript 렌더링 기반 사이트 크롤링 대응 경험 (예: Puppeteer, Playwright)• 개인정보보호 및 크롤링 윤리에 대한 기본 지식• Tableau, Power BI 등 BI 도구 활용 경험."
보이스루,"• AI 번역 플랫폼 및 LLMOps를 위한 데이터 파이프라인 아키텍처 설계 및 구축 (AWS 환경)• LLM 학습/서빙을 위한 대용량/실시간 데이터(텍스트, 벡터, 로그) 수집, 정제, 가공 파이프라인 (ETL/ELT) 구축 및 운영• 데이터 웨어하우스(DW) 및 데이터 레이크(Data Lake) 구축 및 운영• 데이터 파이프라인 모니터링, 성능 최적화 및 장애 대응• 실시간 번역 로그/스트리밍 데이터 수집 및 처리 시스템 구축 (Kafka, Kinesis 등 연동)• 데이터 분석가/AI 엔지니어와의 협업을 통한 데이터 모델링 및 제공.","• 데이터 엔지니어(Data Engineer)로서 3년 이상의 실무 경력• Python, Scala 또는 Java 기반의 데이터 처리 프로그래밍 역량• Apache Spark 등 분산 처리 프레임워크를 이용한 대용량 데이터 처리 경험• Airflow 등 워크플로우 오케스트레이션 도구 활용 및 파이프라인 구축 경험• AWS 환경 (S3, EMR, Kinesis, Glue, Redshift, Athena 등)에서의 데이터 파이프라인 구축/운영 경험• SQL을 활용한 능숙한 데이터 추출 및 가공 능력• 대용량 데이터 처리 파이프라인 트러블슈팅 및 장애 대응 경험• 데이터 웨어하우스(DW) 또는 데이터 레이크 구축/운영 경험.","• LLMOps / MLOps 환경 또는 AI/ML/번역 도메인 서비스에서 데이터 엔지니어로 일해 본 경험• Kafka, Kinesis, RabbitMQ 등 메시지 큐/스트리밍 플랫폼 활용 경험• Vector DB (Pinecone, Milvus, Chroma, PGVector 등) 연동 및 데이터 처리 파이프라인 구축 경험• PostgreSQL, Cassandra, Elasticsearch, Redis를 **데이터 소스(Source) 또는 타겟(Sink)**으로 활용해 본 경험 (운영/튜닝 X, 데이터 입출력 O)• Terraform, Ansible 등 **IaC (Infrastructure as Code)**를 통한 인프라 관리 경험• GCP, Azure 등 멀티 클라우드 환경에서의 데이터 파이프라인 구축 경험• Datadog, Prometheus/Grafana 등 모니터링 솔루션 활용 및 대시보드 구축 경험."
엘박스,"• Databricks 환경에서 Spark SQL 및 PySpark를 활용한 데이터 파이프라인 설계 및 구현해요.• 서비스 로그 및 유저 이벤트 데이터 수집, 가공, 적재 프로세스를 구축해요.• 전사 데이터 마트를 설계 및 운영해요.• 데이터 크롤링 시스템을 구축 및 운영해요.• ML/AI 팀과 협업하여 모델 서빙 파이프라인을 구축해요.• A/B 테스트 등 실험 환경을 구축 및 운영해요.","• 3년 이상의 데이터 엔지니어링 경험을 보유하신 분• Spark 기반 데이터 처리 및 분석 경험이 있으신 분 (SQL, PySpark)• 다음 중 하나 이상의 데이터베이스 실무 경험이 있으신 분: Elasticsearch, MongoDB, MySQL• 데이터 파이프라인 설계 및 운영 경험을 보유하신 분.",• Databricks 환경에서의 개발 경험• Flink 등 실시간 처리 시스템 활용 경험• AWS 등 클라우드 환경에서의 개발 경험• 백엔드 개발 경험• A/B 테스트 플랫폼 구축 경험• ML/AI 모델 서빙 경험.
놀유니버스,"[함께 할 업무예요]＞ 주로 데이터 기반 서비스와 API 개발 및 운영을 담당하게 돼요.• 데이터를 기반으로 사내외에 API 형태로 데이터를 제공하는 서비스를 개발하고 운영해요.• DI 조직에서 운영 중인 서비스로는 실험 플랫폼, 개인화 마케팅 캠페인 도구, 유입 채널 관리 시스템이 있어요.다음과 같은 업무도 함께 경험하실 수 있어요.＞ 데이터 파이프라인 구축 및 운영 (ETL/ELT)• 앱/웹과 각 Service 등에서 발생하는 원천 데이터 입수를 자동화할 수 있도록 시스템을 개발하고 운영해요.• 데이터를 실시간으로 가공하는 스트림 이벤트 파이프라인을 개발하고 운영해요.• 데이터 품질 및 신뢰성 확보를 위한 모니터링 및 자동화 시스템을 개발하고 운영해요.＞ Data Infrastructure 관리 및 운영• Databricks를 안정적으로 운영하기 위한 자동화 및 모니터링 시스템을 구축해요.• 놀유니버스에서는 Data Infra로 Databricks를 이용하고 있어요.","[이런 분과 함께하고 싶어요]• 5년 이상의 Back-end 개발 경력 혹은 그에 준하는 역량을 보유하신 분• 문제를 주도적으로 발견하고 빠르게 해결하는 실행력을 갖추신 분• 다양한 조직과 원활하게 소통하며 협업할 수 있는 분• 기술 변화에 민감하고, 새로운 도구와 방법론을 배우는 데 적극적인 분.","[이런 경험이 있다면 N배 좋아요]• 데이터 모델링, 데이터 아키텍처, 데이터 웨어하우징에 대한 깊은 이해를 기반으로 빅데이터 분야에서 3년 이상의 실무 경력을 보유하신 분 • Kubernetes, Docker 등 컨테이너 환경에서의 서비스 운영 경험을 보유하신 분• AWS, GCP, Azure 등 클라우드 인프라 운영 경험을 보유하신 분• 대용량 데이터 처리(분산 시스템, Spark, Kafka 등) 경험을 보유하신 분• RDBMS, NoSQL, 데이터베이스 설계 및 운영 경험을 보유하신 분• 데이터 품질 모니터링, CI/CD, 자동화 시스템 구축 경험을 보유하신 분• 실시간/배치 데이터 파이프라인 구축 및 운영 경험을 보유하신 분• 데이터 기반 서비스/플랫폼 개발 및 운영 경험을 보유하신 분."
카카오모빌리티(kakaomobility),• Multi ​modal inference and long-term ​learning• Learning ​based map ​construction• Sensor data fusion.,"• 5년 ​이상의 ​실무 경험이 ​있으신 ​분 ​(박사 졸업 예정자 ​지원 ​가능)• 컴퓨터공학, 전기공학, 수학, ​로보틱스 ​전공이나 ​이와 관련된 전공의 ​학위를 소지하신 ​분• C/C++, ​python 등의 ​숙련된 프로그래밍 ​기술을 ​보유하신 분• 장기적인 목표를 ​설정하고 끊임없이 ​도전하시는 분• 새로운 기술을 모빌리티 서비스에 적용하고 싶은 의지가 강하신 분.","• 관련 석사 혹은 박사 학위 소지자 또는 관련 경험자• 관련 분야 저서/학술활동(CVPR, ICCV, NeurIPS, ICRA, IROS 등) 이력• object detection, semantic segmentation, depth estimation 등의 다양한 딥러닝 모델 개발 경험자• 다양한 센서 데이터(camera, lidar 등) 활용 및 학습 데이터 파이프라인 구축 경험자• slam, optimization, online calibration 등의 로보틱스 관련 개발 경험자."
퍼슬리,"""증상 확인 Agent"", ""의학적 팩트체크 Agent"", ""부작용 대처 Agent""등으로 이루어진 퍼슬리의 Multi Agent System을 강화하는 역할을 맡게 됩니다.• 정량적인 내부 데이터 기반으로 AI Agent 혹은 Workflow를 설계하고 개선합니다.• 제품 팀과 협업하여 유저 피드백 기반 답변 퀄리티 개선 파이프라인을 구축합니다.• Knowledge base를 위한 크롤러와 Vector DB를 구축합니다.• 도메인 전문가의 데이터 라벨링, 주석을 위한 환경을 개발합니다.","• ML/데이터 엔지니어 경력 3년 이상 혹은 그에 준하는 실력을 가지신 분• Python 생태계에서 1년 이상의 경험을 가지신 분• RAG, Re-ranking, Multi-agent 등 최신 AI Agent 기술에 관심이 많으신 분[기술 스택]• Frontend : Typescript, React Native (Expo), NextJS• Backend : Typescript, NodeJS, tRPC (Express), Prisma• Infra : Supabase, GCP, Docker• AI : Python, FastAPI, LangChain, LangGraph, LambdaDB(Vector DB)• Etc : Sentry, Amplitude.",• Multi Agent 개발 경험이 있으신 분• LLM 관련 오픈소스에 기여하신 경험이 있으신 분• 대규모 데이터 파이프라인 및 워크플로우 자동화 경험이 있으신 분• 대규모 트래픽 서비스를 운영해 보신 분• 데이터 기반 의사결정에 능숙하신 분.
윌로그,"• 백엔드 설계 및 개발 담당- 서비스에서 사용되는 API 및 테스트 코드 작성을 통해 서비스 유지 및 보수성 향상- 신규 서비스에 대한 API 및 데이터베이스 설계업무[ 기술 스택 ]-Typescript, NestJs-GraphQL, Rest API-AWS, Github-Docker.",• 5년 이상의 개발 경력 또는 혹은 그에 준하는 역량• Typescript 을 사용한 NestJs + TypeORM으로 개발을 해본 분• GraphQL 을 사용한 API 개발 경험• AWS serverless lambda 에 대한 활용과 개발에 능한 분• 높은 가용성과 확장 가능성을 가진 시스템을 설계하고 운영한 경험• 다른 개발자 또는 비개발자와 커뮤니케이션이 원활한 분.,• B2B 서비스 혹은 물류 시스템 구축 유경험자• MSA 경험이 있는 분• Git 등의 분산 버전 관리 시스템 이용에 능숙한 분• Jira + Confluence 를 통한 업무경험.
위대한상상(요기요),"[우리는 이런 일을 해요]적시에(빠르게) 신뢰할 수 있는 리포트/대시보드/데이터 마트를 제공합니다.지표의 집계 기준, 표준화 하여 분석가, 현업의 생산성 향상을 높이는 일을 하고 있습니다.• 전사 리포트/대시보드 구현• 데이터 마트 설계/ 정제/ 변환 및 적재 개발 및 운영• 의사결정에 필요한 데이터를 적시에(탐색할 수 있는 환경) 제공• 전사 구성원들이 비즈니스에 필요한 데이터를 스스로 활용할 수 있는 환경 제공.","[우리는 이런 분과 함께 하고 싶어요]• BI(Business Intelligence) 관련 전반적으로 이해도가 높으신 분으로 최소 경력 3년 이상• SQL, Python, Airflow(ETL), Tableau 등 데이터 핸들링 및 시각화 경력자• BigQuery, Redshift 등 클라우드 데이터 웨어하우스 경험자• Data Mart 데이터 모델링 설계, 구현 및 SQL 능숙• BI 시각화 툴을 이용한 대시보드 개발 및 운영(Tableau, Looker Studio, Data Studio 등) 및 고급 기능(Tableau API, Tableau Extensions) 활용 경험이 있으신 분• 업무에 오너십을 갖고 책임감 있게 데이터를 꼼꼼하게 들여다 보시는 분 • Strong Work ethic.","[그 외 이런것이 있으면 더 좋아요]• 커머스 서비스에 대한 이해 및 다양한 부서(경영, 세일즈, 마케팅, 개발) 팀과 원활한 협업 및 요구사항 도출 능력을 갖추신 분• Python PANDAS 또는 기타 언어를 이용한 데이터처리 경험 우대• 컴퓨터공학, 산업공학, 통계학 등 데이터 관련 전공자."
마이리얼트립,"• 데이터 파이프라인 설계·구축 및 MART 최적화• BigQuery에서 활용되는 데이터 형태에 맞춰 비즈니스 로직을 적용하는 작업을 수행하며, 매일 유입되는 데이터를 자동으로 정리·시스템화합니다. 신규 파이프라인 설계와 기존 파이프라인의 데이터 적합성 검증을 통해 신규 비즈니스 기회를 더 쉽게 발굴하고, 자동화로 데이터 활용의 확장성을 높입니다.• DBT와 Airflow를 활용해 데이터 Manipulation과 자동화를 주도하며, MART 모델링으로 고성능 쿼리 환경을 구축합니다. 대용량 데이터셋 처리와 품질 최적화를 통해 비즈니스 적합성을 강화합니다.• AI 도구(Generative AI 등)를 적극적으로 도입해 반복 작업을 효율화하고, AI를 통한 자동화를 통해 비지니스 성장에 도움을 줍니다.2. End-to-End 문제 해결 & 데이터 문화 확산• 문제 정의부터 데이터 모델링, 실험 설계, 제품 반영까지 주도적인 오너십으로 이끌며, 반복적인 프로세스는 Generative AI와 Workflow Automation으로 지능형으로 업그레이드합니다. BigQuery MART 구축, 스키마 설계, 데이터 품질 관리 등 인프라 수준의 작업을 포함해 전체 데이터 라이프사이클을 관리합니다.• 전사 구성원이 데이터를 자유롭게 읽고, 쓰고, 활용할 수 있도록 교육과 가이드를 제공하며, 함께 성장하는 문화를 조성합니다. 특히 AI 기술을 활용한 워크숍을 통해 팀의 분석 워크플로를 고도화합니다.","• 데이터 조작 및 분석 능력• SQL로 데이터베이스에서 필요한 데이터를 추출하고, BigQuery 기반 DW/MART를 설계·관리한 경험이 있는 분• Python/R을 활용해 데이터 가공·전처리를 수행하며, DBT, Airflow 같은 ETL 도구나 빅데이터 프레임워크를 다뤄본 분• 데이터 기반의 변화 추진 능력• 데이터를 기반으로 서비스나 프로세스에 실질적인 변화를 이끌어낼 수 있는 분• 개발자, 디자이너, PM, 비즈니스 담당자 등 다양한 직군과 협업하며, 기술 솔루션을 제안하고 구현할 수 있는 분.","• 문제를 스스로 정의하고 끝까지 해결하려는 오너십을 지닌 분• 난관이 와도 쉽게 포기하지 않고 집요하게 파고드는 분• 익숙하지 않은 영역도 과감히 도전하며 자기 성장을 추구하는 분• AI·자동화 도구(Generative AI, AutoML, Prompt Engineering 등)를 활용해 반복적인 분석·리포트·Batch 작업을 자동화하고 팀 생산성을 향상시킨 경험, LLM·RAG 기반 분석/서비스 프로토타입을 신속히 구축하거나 운영에 적용한 사례• AI 기술을 팀원에게 전파하고 분석 워크플로를 ‘지능형’으로 고도화한 경험을 공유할 수 있는 분• 클라우드 기반 데이터 플랫폼(BigQuery, AWS, GCP 등)에서 DW/MART 구축 및 운영 경험• DBT/Airflow를 활용한 파이프라인 자동화 경험."
업스테이지,"[Representative projects]• Automatic quality assessment system development• Solar safety benchmark development• Solar edge-case (failure or error) benchmark development• Complex structured text generation benchmark development** 기술의 흐름과 상황에 따라서 개발하는 프로젝트는 변화하며, 프로젝트는 각 시점에 LLM 모델 발전에 가장 영향력있는 기술 요소에 집중합니다.","Strongly wanted• AI 모델 평가 및 분석 관련 토픽으로 국제 학회에서 출판 기록 (공저자 포함)• 또는 ML과 NLP 토픽으로 국제 학회에서 출판 기록 (1저자 혹은 교신저자)May helpful• AI 모델 평가를 위한 데이터 수집, 생성, 정제등을 수행해 본 경험• Agentic flow (w/ tool use)를 설계 및 개발해본 경험• Failure analysis를 기반으로 데이터를 하나하나 들여다 보고 인사이트를 얻을 수 있는 집중력• 논리적인 사고실험을 수행하고 가설/검증의 방식으로 실험 설계 및 결과를 도출할 수 있는 사고력• 복잡한 데이터 협업 프로토콜 (규칙) 을 정돈할 수 있는 시스템적 사고 능력 • 레슨런을 효과적이고 효율적으로 전파하고 논의할 수 있는 의사소통 능력.",
현대오토에버,"• 지도 데이터 구축/운영 및 서비스• POI 구축/유지보수, 생산 효율화 방법론 연구 개발 (Ex, 구축/작업환경 개선, 정제 로직 강화, 데이터 확대 등)• 데이터 분석 및 컨텐츠 서비스 기획• 내비 사용자 니즈, 트랜드 분석 기반 POI 신규 서비스 기획 (OEM 단말/센터, routo, 타OE 등 적용)• 지도 수준 고도화 및 개선 위한 기술 연구/개발.","• 지도 데이터 관련 업무 경험 2년 이상 (데이터 분석/데이터 구축/서비스 등)• SQL 활용 역량• GIS 관련 TOOL 활용 역량 (QGIS, ArcGIS 등)• 개선점 도출 및 문제 해결 / 분석적 사고 역량.",• 데이터 분석 및 사양 설계 有 경험• 객체 편집 TOOL 사용 有 경험• Python 활용 능력• 내비게이션/지도 서비스 기획 경험.
에이치에너지,"● OLAP 데이터 모델링: 다차원 데이터 분석을 위한 OLAP 스키마 설계 및 구축, 데이터 가공 처리● 데이터분석 및 보고서 작성: OLAP 데이터를 기반으로 분석 쿼리 작성, ML 분석, 분석 보고서 작성● 핵심 메타데이터 관리: 주요 메타데이터를 정의하고 관리 시스템을 구축 및 운영● 분석 서비스 개발: 데이터 분석 결과에 대한 서비스 개발.","• 대학교졸업(4년)이상• 관련 경력 3년 이상• 데이터베이스관련 전공 이수자• 데이터 거버넌스 이해: 데이터 표준화 및 메타데이터 관리의 중요성을 깊이 이해하고 있으며, 실제 적용 경험• 데이터베이스 시스템 이해: OLTP, OLAP 개념 이해 및 관련 시스템 활용 경험• OLTP 활용 경험: RDBMS, NoSQL, NewSQL 등 OLTP용 데이터 시스템의 이해 및 활용 경• OLAP 활용 경험: OLAP 개념 이해 및 관련 시스템 운영 경험, 데이터 분석용 스키마 작성 경험.","• 머신러닝 분석 경험: OLTP, OLAP 데이터로 부터 머신 러닝을 활용한 데이터 분석 경험• 클라우드 OLAP 시스템 경험: Google BigQuery, Snowflake 등 클라우드 시스템에서 OLAP 스키마 설계 및 구축 경험• Python 개발 경험: Python을 이용한 ETL 개발, Backend Service 개발 경험 • 클라우드 플랫폼 활용 경험: Google Cloud Platform, Amazon Web Service 등 클라우드 플랫폼을 활용하여 Serverless 개발, Backend 개발, Kubernetes 환경 사용 경험＜기술스택＞• 데이터베이스: MySQL,Google BigQuery• 운영체제: Linux• 부가 기술: Python Programming, Google Cloud Platform."
틸다,"다양한 산업의 기업과 협력하여 현실 세계의 문제와 요구사항을 정의하고, 학문적 수준에 머물러 있는 첨단 기술을 연구 및 개발을 통해 고도화하는 역할을 맡게 됩니다.• CO(Combinatorial Optimization) 기술의 연구 및 개발• 산업 현장 데이터 분석을 통한 Metheus 엔진 상용화.",• 관련 선행 연구 논문을 조사하고 분석하여 적용할 수 있는 능력을 갖추신 분• 연구개발에 필요한 프로그래밍 언어 및 프레임워크에 익숙하신 분• 현실 세계의 문제를 기술적으로 해결하고자 하는 열정을 가지신 분• 협업을 위한 열린 자세와 논리적인 의사소통 능력을 갖추신 분• 회사와 함께 성장하고자 하는 의지가 있으신 분.,"• 프로젝트 경력 2년 이상 또는 관련 전공 석사 이상 학위를 보유 또는 진행 중이신 분• 오픈소스 컨트리뷰션 경험이 있으신 분• 연구 결과를 실제 제품 및 서비스로 구현한 경험이 있거나, 이를 실현하고자 하는 의지가 있으신 분."
미트박스글로벌,• 대용량 데이터 분석 및 머신러닝 예측 모델 운영• 데이터 거버넌스 및 AWS 클라우드 인프라 운영·고도화• A/B 테스트를 통한 모델 성능 검증·개선 • 데이터 기반 의사결정 지원 및 협업.,• 3년 이상의 관련 실무 경험이 있으신 분• 시계열 예측 모델을 적용한 데이터 분석 및 예측 모델링 경험• SQL 및 Python 활용 능력이 있으신 분• 비즈니스 관점에서 데이터 해석 및 솔루션 제시 역량을 보유하신 분.,"• 머신러닝 관련 전공자(통계학, 산업공학 등)• Data Warehouse, Data Lake 구축·운영 경험• 데이터 표준화·품질관리 경험• Git, Airflow 등 워크플로우 관리 도구 경험• 축산, 이커머스, 물류, 금융 분야 데이터 분석 경험."
네이버클라우드,"• 고품질 이미지/비디오 데이터 큐레이션 모델 개발 - 각 데이터 도메인에 맞는 다양한 특징 추출 모델 (Aesthetics Score, Typography OCR, Optical Flow, Scene Change 등) 적용 및 개선 - 비정상 데이터 감지 및 품질 기반 필터링 적용 및 개선• 복합 시나리오 학습 데이터셋 구축 - 웹/문서/비디오 등의 원시 데이터에서 구조화된 Interleaved 데이터 추출 - 이미지/비디오 편집 기능을 위한 모델 기반 데이터 합성• 데이터 캡션링 파이프라인 고도화 - 이미지/비디오에서 추출한 다양한 특징을 반영한 캡션링 파이프라인 개발 및 개선• 데이터 통계 분석 및 시각화를 통한 지속적 품질 개선.",• 2인 이상이 참여한 프로젝트에서 6개월 이상의 코드 협업 경험이 있으신 분 - git & PR 기반 공동 코드개발에 능숙하신 분 - python 및 pytorch 활용이 능숙하신 분.,"• 100K 개 규모 이상 자체 데이터셋 구축 경험이 있으신 분• 데이터 품질 향상을 위한 자동화 툴·서비스 개발 경험이 있으신 분• AI/Vision 분야 논문 게재 또는 오픈소스 기여 경력이 있으신 분• 대규모 데이터셋 분산처리 개발 경험이 있으신 분 (Ray, PySpark, VectorDB 등 활용 경험)."
인티그레이션(메디스트림),"• AWS(EKS, EMR 등)·Redshift 기반 데이터 인프라 설계/구축/운영• 데이터 크롤링 파이프라인 설계·개발(수집·정제·저장 자동화)• Real-time Data Processing 시스템 설계 및 구축• 로그 분석 시스템 구축 (Segment, GA4 등)• 데이터 비식별화 처리 정책 수립 및 적용, 접근통제/암호화 등 보안 체계 운영• 데이터 파이프라인 오케스트레이션(Airflow), 모니터링/알림/리커버리 체계 구축.","• 3년 이상 데이터 유관 경력• Airflow 등의 Workflow Manager로 데이터 파이프라인 구축/운영 경험• Docker, Kubernetes(EKS) 등 컨테이너 기반 서비스의 아키텍처 설계 및 개발 경험• Python 및 SQL 쿼리 능숙• 데이터 웨어하우스(Redshift 등) 모델링·성능 최적화 경험• 대시보드/BI(Redash, Superset 등) 운영 경험.","• 대용량 데이터 엔지니어링 및 실시간 처리, CDC 도입 경험• 분산 데이터 처리(Spark/EMR 등) 실무 경험• 의료 데이터 도메인 경험, 개인정보보호법/ISMS 이해• 데이터 품질/거버넌스(dbt/Great Expectations, 데이터 카탈로그) 경험• AWS Glue, Athena, SageMaker 등 다양한 데이터 관련 AWS 서비스 활용 경험[팀 적응을 잘하신 분들의 공통점]팀에서 문제를 잘 해결하고 계신 분들과 인터뷰를 통해 정리한 특징입니다. • 안 되는 이유를 찾기보다, 되게 하는 방법을 고민하는 태도• 스스로 문제 정의를 하고, 불확실성을 줄이기 위해 가설과 실험을 반복하는 스타일• 관계를 해치지 않고 문제 해결을 목적으로 하는 대화 방식• 생소한 분야의 서비스에 도전하고자 하는 의지와 빠른 학습 능력."
퍼슬리,"""증상 확인 Agent"", ""의학적 팩트체크 Agent"", ""부작용 대처 Agent""등으로 이루어진 퍼슬리의 Multi Agent System을 강화하는 역할을 맡게 됩니다.• 정량적인 내부 데이터 기반으로 AI Agent 혹은 Workflow를 설계하고 개선합니다.• 제품 팀과 협업하여 유저 피드백 기반 답변 퀄리티 개선 파이프라인을 구축합니다.• Knowledge base를 위한 크롤러와 Vector DB를 구축합니다.• 도메인 전문가의 데이터 라벨링, 주석을 위한 환경을 개발합니다.","• 백엔드 or AI or 데이터 엔지니어 경력 3년 이상 혹은 그에 준하는 실력을 가지신 분• JS 혹은 Python 생태계에서 1년 이상의 경험을 가지신 분• RAG, Re-ranking, Multi-agent 등 최신 AI Agent 기술에 관심이 많으신 분[기술 스택]• Frontend : Typescript, React Native (Expo), NextJS• Backend : Typescript, NodeJS, tRPC (Express), Prisma• Infra : Supabase, GCP, Docker• AI : Python, FastAPI, LangChain, LangGraph, LambdaDB(Vector DB)• Etc : Sentry, Amplitude.",• Multi Agent 개발 경험이 있으신 분• LLM 관련 오픈소스에 기여하신 경험이 있으신 분• 대규모 데이터 파이프라인 및 워크플로우 자동화 경험이 있으신 분• 대규모 트래픽 서비스를 운영해 보신 분• 데이터 기반 의사결정에 능숙하신 분.
현대오토에버,"• 비전 AI 모델 개발 및 적용• : classification, detection, segmentation, anomaly detection 모델 최적화• 적용 분야 : 표면결함검사, 부품 사양검사, 기타 비전 품질 검사 등, 안전 부문 객체감지• 학습데이터 augmentation 기술 개발 및 적용• 머신비전시스템 인터페이스 개발 및 적용.","• supervised, semi, unsupervised learning 기반 비전 AI 모델 개발 경험• 비전 AI 모델의 현장 적용 및 Tunning 경험• 오픈/상용 영상처리 알고리즘 활용 경험.","• 제조 분야 Vision AI 모델 개발 및 적용 경험• Vision AI 모델의 타시스템 연계, 공장 제조 시스템 개발/구축/운영 경험• Socket 또는 ResfulAPI 등의 통신방법 개발 경험 및 이해• 영어 커뮤니케이션 역량."
사각,"[AI Agent 시스템 설계 및 개발]• On-Prem 또는 클라우드 환경에서 LLM 기반 AI Agent 시스템을 설계 및 구축합니다.• LangChain, CrewAI 등 프레임워크를 활용한 멀티 에이전트 아키텍처를 구현합니다.• 외부 API, 툴과 연동되는 Tool-Using Agent를 개발하며, RAG 기반 문맥 추론 시스템을 고도화합니다.[AI 기반 플랫폼 및 서비스 개발]• 대화형 AI, 분석 툴 등 다양한 형태의 서비스를 설계하고 운영합니다.• 사용자와 상호작용하는 Web/App 기반 UI를 개발합니다• AI, 백엔드 시스템 및 외부 서비스와 연동되는 서버 및 API를 구성합니다.[데이터 엔지니어링]• 대화, 로그, 사용자 입력 등 다양한 데이터를 수집하고 파이프라인을 설계합니다.• 실시간 데이터 수집 및 시각화, 대시보드 구현을 통한 모니터링 체계를 구축합니다.• 데이터 품질을 진단하고, Agent의 성능과 사용자 경험 개선에 활용합니다.[운영 및 협업]• 테스트 자동화, 모니터링, 서비스 안정화 등 운영 품질을 지속적으로 개선합니다.• 인프라 관리와 배포 자동화를 통해 지속 가능한 개발 및 운영 환경을 구성합니다.• 기획, 디자인, 연구 등 다양한 직군과 긴밀하게 협업하여 완성도 높은 제품을 함께 만듭니다.","• 최신 AI 기술을 빠르게 학습하고, 실제 서비스에 적용하는 데 주도적인 분• 1개 이상의 분야에서 Software Engineer로 실무 경험이 있으신 분(Backend / Frontend / AI / Data / ML 등)• RESTful API 설계 및 데이터베이스 운영 경험을 보유하신 분• AWS, GCP, Azure 등 클라우드 환경에서의 서비스 개발 및 배포 경험이 있으신 분• 복잡한 시스템 구조 및 데이터 흐름에 대한 이해와 최적화 능력을 보유하신 분• 다양한 팀과 명확하게 소통하며 협업할 수 있는 능력을 갖추신 분.","• 데이터 파이프라인, ETL, MLOps, DevOps를 설계하고 운영해보신 분• React, Svelte 등으로 사용자 중심 UI를 만들어보신 분• Docker, Kubernetes 등으로 자동화된 배포 환경을 구성해본 분• 스타트업 또는 스케일업 환경에서 서비스를 개발부터 런칭까지 주도적으로 경험하신 분• 헬스케어, 보험, 의료 도메인에 대한 이해가 있으신 분• GPU 서버 또는 클러스터 환경에서 모델을 운영해본 경험이 있는 분."
인포유앤컴퍼니,• 퍼블릭 클라우드 환경에 대한 이해 • 대용량의 데이터를 데이터 성격에 맞게 설계/적재• Delta Lake 저장 방식 및 형식 이해• Spark 엔진 이해.,"• 데이터 적재/관리 3년 이상의 경력 보유자• Python, SQL 기본.","• Databricks, Fabric, Snowflake 유 경험자 • Power BI 기본 이해• AI/ML 유 경험자."
그린카,"ㆍ카셰어링 데이터 분석, 추출 및 가공ㆍBI 도구를 활용한 시각화 및 분석 리포트 작성ㆍ문제정의/가설수립/검증/결과도출 및 제안 ㆍ유관 부서와의 커뮤니케이션 및 협업.","초대졸 이상 / 경력 5년 ~ ㆍ데이터 분석에 필요한 기본적인 통계지식을 보유하신 분ㆍ논리적인 사고 역량을 가지고 계신 분ㆍSQL query 능숙자 (mysql, redshift)ㆍ리눅스 사용 경험이 있으신 분ㆍBI 도구 사용 경험이 있으신 분.","ㆍ데이터 웨어하우스 , 데이터 마트 구축을 해보신 분ㆍ데이터 파이프라인 구성을 해보신 분ㆍAWS클라우드 사용 경험 해보신 분ㆍETL 도구 사용해보신 분 (Airflow)ㆍ머신러닝을 통한 모델 학습 해보신 분."
딥서치,"• 금융 전문가들이 유용하게 사용할 수 있는 AI 기반의 서비스를 개발해요.• LLM을 활용하여 RAG 기반으로 사용자에게 의미있는 데이터를 생성해요.• MCP, agent2agent와 같은 프로토콜에 맞는 API를 개발해요.• 국내/미국 시장 경제에 영향을 미치는 모든 데이터와 기업 데이터를 수집 및 가공해요.• 데이터를 효율적으로 수집할 수 있는 파이프라인을 구축해요.• 데이터를 클러스터링, 분석, 추천, 추측 알고리즘을 적용하여 사용자에게 제공해요.",• (필수) 백엔드 서비스 개발 경험이 풍부한 분 (언어·프레임워크 무관)• (택1) 안정적이고 확장 가능한 데이터 수집 및 파이프라인 설계 경험이 있는 분• (택1) AI 관련 서비스(ML포함) 개발 및 배포 운영 경험이 있으신 분• 새로운 기술 및 방법을 빠르게 학습하는데 익숙하신 분• 효율적이고 논리적인 커뮤니케이션을 잘 하시는 분• 빠른 성장을 추구하는 분.,"• LLM을 활용한 서비스 개발·운영 경험• Vector DB, OpenSearch 등 검색/추천 관련 경험• 머신러닝 모델 빌드, 배포, 운영 경험 (자체 LLM self-hosting 경험 포함)• 금융(주식, 투자, 경제 등) 도메인에 대한 높은 이해도가 있으신 분• 스타트업 환경에서 서비스 스케일업을 성공적으로 이끈 경험• AI 도구 및 툴 사용에 능숙하신 분."
와따에이아이,"• 백엔드 개발 아키텍쳐 계획 및 구현하는 Tech Lead 역할 수행• 물류관리 솔루션 백엔드 설계 및 구현• 다양한 데이터 수집, 통계, 처리 파이프라인 설계• 주니어, 미드 개발자와 협업하여 코드 리뷰 및 기술적 리딩.","• CTO 경험 또는 팀리드 경력 3년이상, 개발 경력 10년 이상• BtoB 서비스 시작부터 출시까지 개발 설계 및 기획 경험이 있는 분 • 비즈니스 요구사항을 이해하고 필요한 시스템 구조와 데이터 모델 설계 경험• 아키텍쳐 고도화 및 개발 리딩 경험이 많은 분• AWS 클라우드 환경에서 서비스 개발, 배포 및 운영 경험• 외부 연동/제공 API 개발 경험 또는 그에 필요한 기술 이해가 있는 분• GIt 등의 분산 버전 관리 시스템 이용 경험이 있는 분• 외부 연동/제공 API 개발 경험 또는 그에 필요한 기술 이해가 있으신 분• Git 등의 분산 버전 관리 시스템 이용 경험이 있으신 분.",• IOT 플랫폼 관련 개발 경험이 있는 분• 소프트웨어 전반적인 QA 및 프로젝트 관리 관련 지식이 있는 분• 개발 팀을 육성한 경험과 관심이 있는 분.
삼양식품,"• 대용량 트렌드 후보 영상 수집 파이프라인 확장 • TikTok 영상을 효율적으로 크롤링하고 가비지 데이터 및 노이즈를 효율적으로 제거하는 프로세스 구축• 스마트 필터링 & 트렌드 판단 로직 실험 • 현재 휴리스틱으로 진행하는 트렌드 여부 판단을 멀티모달 LLM 모델로 ‘트렌드 점수화’하여 예측 및 정확도 개선• 피드백 루프 기반 자동화 프로세스 구축 • 도출한 인사이트를 재학습을 통해 모델을 개선하고 precision·recall 모니터링을 통해 QC 진• 지표 중심 대시보드 & 리포트 제공 • 신규 트렌드 TOP N, 미션 채택률 등을 시각화해 팀 의사결정 속도 향상.","• 대규모 영상 수집·필터링 • 하루 수만 건 크롤링, 스트림 처리, 노이즈 제거 경험• LLM 활용 & 파이프라인 • 대형 언어 모델 프롬프트 설계, RAG 파이프라인, 파인튜닝 등으로 멀티모달 TikTok 데이터를 분석·기능화해 본 경험• 모델 피처 설계 → 자동화 배포·모니터링 • 학습용 피처 정의, 파이프라인·CI/CD 구축, 모니터링까지 운영한 경험• 빠른 프로토타입 & 반복 개선 • 아이디어를 1–2 주 내 기능으로 만들어 지표(참여율·완수율)로 검증한 경험• 미국 TikTok 데이터 인사이트 • 미국 TikTok 소셜 데이터를 기반으로 트렌드 감지·인사이트를 도출해 제품·마케팅 지표를 개선한 경험.",
워트인텔리전스,"데이터를 적시에 올바른 장소로 가져와 안전하게 보관하고, 데이터의 잠재력을 최대화하기 위한 플랫폼 서비스를 만드는 업무를 수행합니다.• 데이터 플랫폼을 운영하며 새로운 기술을 적용하고 자동화 및 고도화합니다.• 특허 데이터를 중심으로 연관된 다양한 데이터 파이프라인을 만듭니다.• 사내 보유한 모든 데이터를 분석하고 활용할 수 있는 환경을 만듭니다.• 데이터 품질을 향상시키기 위하여 고민합니다.• 검색 클러스터에 들어갈 데이터를 정제하고 생성하여 저장합니다.",• Spark 를 활용한 데이터 처리에 익숙하신 분• Iceberg 구축 및 운영해 본 경험이 있으신 분• Airflow 기반의 파이프라인 구축에 익숙하신 분• Python 에 능숙하신 분.,"• 데이터 임베딩, VectorDB, GraphDB 등 AI 특화 데이터 인프라 구축 및 운영 경험이 있으신분• Data Lake, Data Mart 구축 및 운영해 본 경험이 있으신 분• Kafka, Nifi 와 같은 스트리밍 기반 환경 경험이 있으신 분• 데이터 품질 관리 환경을 구축 및 운영해 본 경험을 보유하신 분• Data Governance 구축 및 운영해 본 경험이 있으신 분."
두잇 (Doeat),"데이터 분석을 넘어 사업 전략 전반에 기여하고, 주도적으로 프로젝트에 참여하며 팀의 의사결정을 가속화하는 역할을 맡습니다.• 데이터를 기반으로 전사 목표, 전략 방향성을 제시하고 실행하며 성과를 트래킹합니다. • 전사 핵심 KPI 재설계, 고도화하고, 모니터링 체계를 개선하여 전사 성과 관리를 지원 • 분석 결과를 기반으로, 경영진 및 각 팀에 전략적 방향성을 제시하고 실행 과정을 주도 • 사업 및 서비스 개선 과제를 리더와 함께 정의하고, 적극적으로 프로젝트를 오너십을 가지고 참여하여 성과를 높이는 데 기여• 데이터를 기반으로 인사이트 발굴하고 실험을 트래킹합니다. • 사용자 행태, 서비스 지표 등을 다각도로 분석하여 새로운 성장 기회를 발굴 • A/B 테스트 등 다양한 실험 기획 및 분석을 통해 프로덕트 개선 사항과 비즈니스 임팩트를 명확히 제시 • 통계적 모델링 및 예측 분석 등을 활용한 인사이트로 의사결정 효율을 극대화• 팀원들의 커뮤니케이션 코스트를 감축하고 노동생산성을 향상시킵니다. • 데이터 마트 설계, ETL 프로세스 개선 등을 통해 데이터 활용도와 신뢰도를 높임 • 사내 데이터 구조, 용어를 표준화하고 문서화하여 효율적인 커뮤니케이션 환경을 조성 • 반복 업무 자동화와 시각화 대시보드 구축을 통해 팀 전체 생산성 극대화• 이해관계자와의 커뮤니케이션을 주도하고, 데이터팀의 허리 역할을 맡습니다. • 프로젝트 내 업무 및 우선순위 설정을 주도하며, 리더 및 팀원들과 긴밀히 협업 • 이해관계자와의 원활한 커뮤니케이션으로 요구사항을 조율 • 데이터 분석 문화를 확산하고, 주니어 구성원의 역량 성장을 돕는 멘토십 발휘.","• 3년 이상의 데이터 분석 경력 또는 이에 준하는 역량을 보유하신 분 • 다양한 서비스/플랫폼 또는 B2C 영역에서 분석 프로젝트를 주도적으로 수행하고 탁월한 성과를 이끌어 내신 분• SQL 고급 능력을 보유하신 분 • 대규모 클라우드 환경에서 복잡한 쿼리를 빠르고 효율적으로 작성할 수 있는 역량• Python 분석 역량을 보유하신 분 • 데이터 분석, 시각화를 위한 라이브러리(예: pandas, numpy, matplotlib 등)를 능숙하게 활용하실 수 있으신 분 • 간단한 자동화 스크립트 작성부터 모델링 단계까지 주도적으로 수행 가능하신 분• 프로젝트 리딩 및 커뮤니케이션 역량을 보유하신 분 • 문제 정의부터 솔루션 도출, 구현, 트레킹까지 전체 과정을 수행하며 일정 관리를 체계적으로 수행할 수 있는 분 • 리더 및 여러 팀원들과 유기적으로 협력하며, 원활한 커뮤니케이션으로 조직을 조율할 수 있는 분• 문제 해결 역량 및 오너십을 보유하신 분 • 데이터로부터 인사이트를 발견하고, 근거 기반의 의사결정으로 비즈니스 임팩트를 창출해내는 분 • 급변하는 스타트업 환경에서 주도적으로 몰입하고 높은 책임감과 오너십을 발휘할 수 있는 분.","• 서비스/플랫폼 데이터 분석 프로젝트 리딩 경험을 보유하신 분• A/B 테스트 기획, 분석 경험이 풍부하신 분• BI 도구 (Tableau, Looker, Redash 등) 커스텀 대시보드 구축 경험을 보유하신 분• 통계적 모델링, 머신러닝 또는 추가적인 고급 분석 역량을 보유하신 분• 데이터 엔지니어링(ETL 파이프라인 설계, 마트 설계) 관련 지식을 보유하신 • 스타트업 환경에 대한 높은 이해와 유연한 대응력을 보유하신 분."
빗썸,"• IDC ORACLE, AWS AURORA, OCI ORACLE, IDC MYSQL 운영 및 관리 • 데이터베이스 분석, 설계, 구축• 데이터베이스 모니터링, 성능 최적화, 장애 대응• 데이터베이스 패치 및 업그레이드.","• 유관 경력 총 5년 이상 보유하신 분• ORACLE 데이터베이스 운영 3년 이상 경험을 보유하신 분• 대용량 DBMS 운영 경험을 보유하신 분• SQL 숙련도 중급, 튜닝 관련 중급 이상의 능력을 보유하신 분• 국내외 4년제 이상의 학위를 보유하신 분• 데이터베이스 아키텍처에 대한 이해도가 높으신 분• 동료들과 적극적으로 소통하고 협업할 수 있는 분• 긍정적인 성향을 보유하신 분.","• ORACLE 데이터베이스 운영 7년 이상 경험을 보유하신 분• AWS Aurora 데이터베이스 운영 5년 이상 경험을 보유하신 분• 대용량 데이터 추출을 위한 SQL 작성 및 튜닝이 가능하신 분• SQL 숙련도 상급, 튜닝 관련 상급 이상의 능력을 보유하신 분• EXADATA 운영 경력을 보유하신 분• 이기종간 DB Migration 경험이 있으신 분• OGG 구축 및 운영 경력을 보유하신 분• 차세대 프로젝트, 업그레이드 프로젝트 등을 주도적 또는 간접적으로 이끌었던 경험이 있으신 분• AURORA MYSQL SHADING 구축 및 운영 경험이 있으신 분• ORACLE 기반 SHARDING Architecture 경험이 있으신 분."
뤼튼테크놀로지스,"• 뤼튼의 투자자와 커뮤니케이션 함에 있어서, 필요한 데이터 제공을 수행합니다.• 뤼튼에서 운영중인 제품 (뤼튼, 크랙, 캬라푸)에 대한 현황과 비전에 대한 데이터이며, 이를 원활히 제공하기 위해서, 해당 기준에 맞는 마트 설계를 수행합니다.• 단순히 마트 설계 및 운영 뿐 아니라, 실질적인 투자자 리포트 자동화에 대한 고민도 함께 하게 됩니다.• 본 포지션은 Airflow, Git 활용 능력을 필수적으로 요구합니다.",• 2년 이상의 Airflow를 활용한 데이터 파이프라인 오케스트레이션 및 관리 경험이 있으신 분• Dimensional Modeling 기반의 데이터 모델링 설계 및 구축 경험이 있으신 분• 비즈니스 성과 지표에 대한 깊이 있는 이해와 이를 데이터로 연결하는 능력이 있으신 분• 데이터 거버넌스 원칙에 대한 이해 및 실제 적용 경험이 있으신 분.,• BigQuery 환경에서의 데이터 처리 및 분석 경험이 있으신 분• DBT를 활용한 데이터 마트 관리 경험이 있으신 분• 제품 분석 또는 IR데이터 공급 경험이 있으신 분• Git을 통한 협업 개발 경험이 있으신 분.
티맵모빌리티,"[사용자 주행이력 분석을 통한 맵 데이터 품질 고도화]• 익명화된 주행 로그 및 공간 데이터를 활용한 도로 변화를 탐지합니다.(신설/폐쇄/규제 변경 등)• 배경(건물·지형), POI 등과의 결합 분석을 통한 커버리지/정확도를 개선합니다.• 주행 로그 기반 지역/구간 통행량 및 인기/유명 장소를 분석합니다.","• 관련 경력 5년 이상이거나 이에 준하는 경험을 보유하신 분• 데이터 분석 및 모델링 능력 보유하신 분• Database 활용 경험을 보유하신 분 (SQL, Spark Scala 등)• 모델링 경험을 보유하신 분 (Python, R 등)• GIS 및 내비게이션 서비스에 대한 지식 보유하신 분.","• 공간정보, 산업공학, 통계 등 관련 분야 전공하신 분• Deep Learning, Database, Modeling 관련 tool 사용에 능숙하신 분 (SQL, Spark, Python)• 데이터에 기반한 논리적 사고 및 통계 지식 보유하신 분."
스트리미(Streami),"• 스트리미 시스템의 데이터관리, 추출 및 분석• Data Warehouse / Mart 내 모델링 구축• Data Pipeline 의 지속적인 개선• Business insight 도출.","• 전산학과, 수학, 통계 혹은 관련 분야의 학위 혹은 동등한 조건• SQL 문법의 이해 및 사용 경험• 적어도 1개 이상의 컴퓨터 언어 사용 경험과 코딩 스킬• 주도적으로 문제를 찾고 해결 할 수 있는 분• 새로운 기술을 익히고 적용하는데 흥미가 있는 분• 논리적으로 자신의 의견을 피력하고 구성원들의 의견을 비판적으로 수용할 수 있는 분• 조직과 개인의 성장에 관심이 있는 분.","• Elastic Stack 사용 경험• AWS Aurora 혹은 Athena 사용 경험• Apache Hive, Spark 또는 Airflow 사용 경험• Python 혹은 R 스크립트에 대한 탁월한 이해• Data Warehouse / Mart 모델링 및 구축 경험• 금융 혹은 비지니스 관련 데이터 관련 경험• DBMS에 대한 탁월한 이해• 통계, 데이터 분석 능력."
라플라스테크놀로지스,"• Spark, Trino를 활용한 ELT 프로세스 개발• 3rd Party API를 이용한 데이터 소싱 및 통합• SQL 기반 통계 분석• AWS Lambda, API Gateway를 사용하여 Serverless 백엔드 구축 (REST API)• Fast API를 활용하여 Serverful 백엔드 구축.","• 데이터 파이프라인 개발 경험• k8s에 대한 이해• 국내외 유수의 대학에서 정량적, 분석적 분야와 관련된 전공 (예. 수학, 컴퓨터공학, 물리학, 산업공학, 금융공학 등)으로 학사, 석사 혹은 박사학위를 취득하신 분• 컴퓨터 공학 전공자 혹은 그에 준하는 전공 지식을 보유한 자.","• B2B SaaS 서비스 운영 경험• 이커머스, 금융 투자 데이터 분석 경험• 오픈소스 프로젝트 활동 경험• OLAP 분석 경험• Kafka 등 데이터 스트리밍 구현 경험• InfluxDB 등 시계열 DB 관련 경험• ML, DL 관련 프로젝트 경험• VC, Growth hacking에 대한 경험• 영어회화 가능자."
토스뱅크,"[합류하면 함께할 업무예요]• 명확한 구조 설계, 표준 준수, 데이터 처리 로직 반영 및 관리, 데이터 정합성 검증, DQ 모니터링 등을 통해 금융권 도메인 지식 없이도 누구나 쉽게 이해하고 신뢰할 수 있는 데이터를 제공해요.• 데이터 관련 업무 중 비효율적이거나 반복적인 부분을 자동화하거나 표준화 해요.• 오픈소스를 활용하여 대용량 Data를 처리하고 최적화해요.• Data Mesh/Medallion Architecture를 기반으로 데이터를 모델링하고 운영해요.• 데이터 표준 관리에 대한 높은 이해를 바탕으로 다양한 업무 관련자와 효율적으로 소통하며, 최적의 데이터 처리 방법을 제안하는 역할을 해요.","[이런 분과 함께하고 싶어요]• Hadoop Ecosystem 환경 기반의 Python, Pyspark 프로그래밍에 능숙하신 분이 필요해요.• Spark 같은 분산처리 엔지니어링을 활용해 대용량 데이터 처리를 해보신 분이 필요해요.• Data Mesh/Medallion Architecture를 이해하고 데이터 모델링을 해오신 분이 필요해요.• 분산 처리 기반 query engine의 동작 원리를 이해하고 튜닝이 가능하신 분이 필요해요.• ETL 프로세스와 airflow orchestration 최적화를 통해 배치작업의 효율화를 경험해보신 분이 필요해요.• 단순요청을 처리하는 것이 아닌 명확한 데이터 구조와 효율적인 데이터 활용 관점에서 기준을 제시할 수 있어야 해요.• 다양한 이해관계자와 소통하여 데이터 요구사항을 구체화하고 정리하는 역량이 있어야 해요.",[이력서는 이렇게 작성하시는 걸 추천해요]• 그동안 해오신 업무 중 임팩트 있었던 프로젝트를 구체적으로 적어주세요.• 데이터 분석에 필요한 데이터 집계 마트 개발 및 구축 경험 또는 탄탄한 도메인 이해도를 바탕으로 데이터 분석과 관련한 업무 경험은 꼭 공유해주세요.• 단순히 구축과 개발에서 끝나는 경험이 아닌 실제 마트 운영 과정에서의 성과도 포함해 주세요.
현대오토에버,• 글로벌 Connected Car Service 운영/개발 및 매니저.,"• Java 등 주요 백엔드 언어 중 최소 한개 이상 숙련자• 관계형 데이터베이스 (MySQL, PostgreSQL)와 비관계형 데이터베이스(MongoDB, Redis 등)에 대한 활용 역량.","• 대규모 시스템, 클라우드 환경, 또는 API 설계 경험 우대• 영어 문서 해석 및 기술적 커뮤니케이션 가능 (구두 영어 능력 우대)• 글로벌 프로젝트 또는 팀과의 협업 경험 우대• 클라우드 컴퓨팅(AWS) 경험 및 마이크로서비스 아키텍처(MSA) 및 서버리스(Serverless) 설계 활용 역량• LLM API 활용 경험 및 NLP 서비스 개발 경험 우대."
위대한상상(요기요),"[우리는 이런 일을 해요]요기요의 방대한 데이터를 수집, 처리, 저장하여 누구나 데이터로부터 비즈니스 가치를 창출할 수 있도록 지원하는역할을 수행합니다. 최신 데이터 플랫폼 위에서 데이터 모델 및 데이터 파이프라인을 설계하고 개발하며, 안정적인데이터 서비스를 제공합니다.데이터에 대한 깊은 이해와 집요한 분석을 통해 논리적인 데이터 모델을 구축하고, 효과적인 데이터 처리 방안을제시하며, 동료들과의 적극적인 소통을 통해 요기요의 Data Democratization을 이끌어갈 분을 기다립니다.• 요기요의 DW/DM를 설계, 구축, 운영하고 고도화합니다.• 커머스, 머천트, 고객 행동 로그 등 요기요 전반의 데이터를 집계 및 가공하여 표준화된 데이터 모델을 구현합니다.• 비즈니스 요구사항에 부합하는 확장 가능하고 효율적인 데이터 모델을 설계, 구축 합니다.• 데이터 거버넌스 관리를 통해 전사 구성원의 데이터 접근성을 높이고, 데이터의 신뢰성과 일관성을 확보합니다.","[우리는 이런 분과 함께 하고 싶어요]• 아래 경험을 포함한 데이터 엔지니어링 경력 5년 이상이신 분 - 데이터웨어하우스/데이터마트 관련 깊이 있는 지식과 실무 경험 - 다양한 소스에서 수집된 데이터를 비즈니스 요구사항에 맞게 모델링하여 구축 가능한 분 - 데이터 표준화, 품질 관리, 관리 체계 등 데이터 거버넌스에 대한 이해가 있으신 분 - 숙련된 SQL 능력과 초급 이상의 Python 지식이 있는 분 - Airflow 등 워크플로우 도구를 사용한 ETL 설계, 개발이 가능하신 분• 팀원 및 유관부서 등 다양한 이해관계자와 정확하고 겸손한 커뮤니케이션을 실행하고 주도적인 업무 리딩 능력을 갖추신 분• 요구사항 분석, 문제 해결 등의 업무에 대한 적극적이고 투명한 공유를 실천하고 강한 Work Ethic을 갖추신 분• GitHub/Jira/Confluence/Slack 등 협업 도구에 익숙하신 분.","[그 외 이런것이 있으면 더 좋아요]• 대용량 데이터 처리 프레임워크 사용 경험이 있으신 분• Apache Kafka, Apache Flink 등 스트리밍 데이터 처리 기술 경험이 있으신 분• 이커머스 또는 음식 배달 플랫폼 도메인에서의 데이터 업무 경험이 있으신 분• Python, Java 중 하나 이상의 프로그래밍 언어로 개발 경험을 보유하신 분• 새로운 툴과 기술을 배우고 적용하는데 주저함이 없는 분• 프로젝트 또는 조직 리딩 경험이 있으신 분."
우아한형제들(배달의민족),"딜리버리서비스 내 ML 모델 구축을 위한 데이터 엔지니어링과 MLOps 수행• 온/오프라인 ML 모델 서빙 API 및 파이프라인 개발• 데이터 전처리, 모델 학습, 추론에 대한 AI 파이프라인 개발 및 운영• 피처 스토어와 피처 엔지니어링 고도화를 위한 기술 검토 및 적용• 다양한 소스의 데이터 적재/가공 및 AI 모델링 과제에 필요한 데이터 환경 구축• 데이터 관점 프로덕트 고도화를 위한 기획/개발 조직과 협업 및 최신 AI 기술 검토와 도입.",• AI/ML 도메인에 대한 종합적 이해와 최소 5년 이상의 관련 프로젝트 경험이 있는 분• AI 기술을 실제 서비스로 구현하여 사용자에게 가치를 제공하고 수익화한 경험이 있는 분• 다양한 직군의 이해관계자들과 효과적으로 소통하고 협업할 수 있는 커뮤니케이션 능력이 있는 분• AWS 클라우드 환경에서 Kubernetes 기반 MLOps 인프라 구축 및 운영 경험이 있는 분.,"• 주요 AI/ML 학회(NeurIPS, ICLR, ICML, CVPR 등) 논문 게재 또는 AI 경진대회 수상 경력• 오픈소스 프로젝트 기여 경험• ML 파이프라인 자동화(AutoML, 하이퍼파라미터 최적화 등) 경험• 딜리버리 또는 물류/공급망 운영에 대한 높은 수준의 지식 보유[개발환경]• 주요 기술 : Python, Spark, Flink, Airflow, Kafka, AWS Services, SQL• 업무 도구 : GitLab, Jira, Confluence• 코드 리뷰 : GitLab MR로 온라인 코드 리뷰 진행• 빌드, 배포 : GitLab CI• 테스트 : GitLab CI로 유닛 테스트 및 통합 테스트."
미소(miso),"• LangGraph 또는 유사 구조 기반 멀티 에이전트 워크플로우 설계 및 구현• 임베딩 모델을 활용한 벡터 검색 또는 지식 그래프 기반의 RAG 파이프라인 구축• 사용자 프로필, 과거 대화 등의 컨텍스트를 활용한 memory 설계 및 injection• 자동 평가 및 human-in-the-loop 평가 파이프라인 구축• 한국어 기반 사용자 시나리오에 최적화된 에이전트 품질 개선• 제품팀 (PM, 디자이너, 데이터 엔지니어)과의 긴밀한 협업 및 빠른 반복 주도.","• LangGraph, LangChain 등 멀티 에이전트 구조를 직접 설계 및 운영하며 실제 사용자 대상 LLM 기반 기능을 end-to-end로 구현한 경험• RAG 애플리케이션 개발 경험• OpenAI Evals / RAGAS 또는 그와 유사한 기능을 제공하는 평가 시스템 구축 경험• Python 기반 API (FastAPI 등) 및 프로덕션 코드 운영 경험• 제품 맥락을 이해하고, 구조적 사고로 문제를 정의하고 리드할 수 있는 역량• 영어 또는 한국어로의 기술 커뮤니케이션 능력미래 역할 확장 가능성• 에이전트 시스템이 성장함에 따라, 역할별 또는 도메인별 LLM을 fine-tuning하거나 경량화된 모델 튜닝이 필요할 수 있음• 데이터 사이언티스트 혹은 ML 엔지니어와 협업하여, 내부 LLM 튜닝 및 학습 워크플로우를 장기적으로 설계.",
임팩티브에이아이,"임팩티브AI의 데이터사이언티스트는 머신러닝/딥러닝 모델 구축, 시계열 예측, 데이터분석 업무를 수행하게 됩니다. 소프트웨어 엔지니어, 서비스 기획자, 도메인 전문가와 협력하여, 정확하고 확장가능한 예측모델을 개발 및 최적화하는 역할을 담당하게 됩니다. • 수요예측 위한 데이터 분석 및 예측모델 설계/개발 • 데이터 전처리 및 피처 엔지니어링 • 인과 추론 및 설명가능성 구현을 위한 분석 • 고객사 딜리버리 위한 예측모델 구축 및 배포 • 최신 모델 및 데이터 분석 트렌드 연구 및 적용.","• 시계열 예측 모델 및 시스템 구축 프로젝트 경험자• 인공지능, 데이터과학, 전산학, 통계 등 관련 전공 석사학위 이상• 머신러닝 및 데이터 분석 분야에서 5년 이상 경력 보유하신 분• 팀 협업 및 소통 능력이 우수하신 분• 어려운 문제를 풀어나가는 데 진취적 성격을 지닌 분.",• AI 기반 SaaS 서비스 관련 모델링 및 데이터 분석 경험• 실전 인과추론·설명가능 인공지능(XAI) 프로젝트 수행 경험• 수요예측 및 원자재 가격예측 관련 대규모 실전 데이터셋/고객사 프로젝트 리딩 경험.
임팩티브에이아이,"• 산업별·업종별 특성 파악을 위한 도메인 리서치• 다양한 내외부 소스에서 데이터 탐색 및 수집 (크롤링 포함)• 데이터분석(EDA), 데이터 전처리 및 정제• 머신러닝·딥러닝 모델링을 지원하기 위한 데이터셋 구축 및 제공• 수집·저장된 데이터의 품질 관리.","• 시계열 예측 모델 및 데이터 분석 프로젝트 경험자• 인공지능, 데이터과학, 전산학, 통계 등 관련 전공 학사학위 이상• 머신러닝 및 데이터 분석 분야에서 3년 이상 경력 보유하신 분.",• 새로운 도메인에 대한 리서치 능숙자• 수요예측 및 원자재 가격예측 관련 모델 개발 및 데이터 분석 경험• 실전 인과추론·설명가능 인공지능(XAI) 프로젝트 수행 경험• 팀 협업 및 소통 능력이 우수하신 분• 어려운 문제를 풀어나가는 데 진취적 성격을 지닌 분• 데이터 파이프라인 자동화 설계 및 구축 경험.
세이지,"• AI 솔루션을 기획하고 개발해요. - 고객의 문제를 분석하고, 본질적인 니즈 까지 해결할 수 있는 솔루션을 정의해요. - 최신 연구 트렌드를 반영하여 최적의 기술을 설계하고 구현해요. - 문제 정의부터 솔루션 설계, 기술 실험, 구현, 성능 개선, 현장 적용까지 주도적으로 수행해요.• 연구 성과와 지식을 자산화해요. - 프로젝트 성과를 체계적으로 문서화하여 사내 AI 기술 자산으로 축적해요. - 동료와 적극적으로 소통하며 연구 완성도를 높이고, 활용할 수 있는 형태로 공유해요. [합류하시게 될 팀]• 세이지의 AI Researcher로 합류하시면 세이지에서 서비스하는 제품에 필요한 원천 기술을 개발해요. - 스쿼드는 보통 2~4명의 인원으로 구성되며, 하나의 목표를 향해 긴밀히 소통하고 협업해요. - 프로젝트 성격에 따라 단독 스쿼드 형태로 운영되기도 하며, 이 경우 연구자가 직접 문제 정의부터 실행까지 주도해요. - 스쿼드 배정은 회사의 전략적 우선순위와 연구자의 전문성을 종합적으로 고려하여 이루어지며, 이를 통해 각 연구자가 자신의 역량을 가장 효과적으로 발휘할 수 있는 환경을 갖추게 돼요.","• 컴퓨터 공학, 기계공학, 수학, 물리 또는 기타 관련된 전공의 석사 이상의 학위를 소지하고 계신 분• 인공지능 프로젝트를 주도적으로 기획 및 수행한 경험이 3년 이상 있으신 분• 기계 학습 관련 소프트웨어 개발 및 엔지니어링 실무 경험이 있으신 분• Vision (이미지 처리) 혹은 Video (영상 처리) 기술 관련 전문적인 지식이 있으신 분• Python 및 주요 데이터 분석/머신러닝 패키지, PyTorch 프레임워크 활용에 능숙하신 분• Git 기반 협업 경험을 보유하신 분• 주도적으로 업무를 이끌고, 논리적인 커뮤니케이션 역량을 갖추신 분• 지원일로부터 4개월 내 온보딩이 가능하신 분.","• 관련 전공 박사 학위를 소지하신 분• 기계 학습 관련 국제 Conference나 Journal에 논문을 출판한 경험이 있으신 분• 연구 프로젝트 기획부터 실행, 검증, 제품/서비스 전달까지 전체 과정을 매니징한 경험이 있으신 분• B2B 인공지능 솔루션 스타트업 또는 관련 산업에서의 근무 경험이 있으신 분• 다음과 같은 기술을 다뤄본 경험이 있으신 분 - 사람 검출, 객체 추적 등 작업 환경 안전 모니터링 기술 - Language Model, Vision-Language Model 관련 기술."
고위드,"• 비즈니스 요구에 맞춰 확장 가능한 데이터 모델을 설계하고, 안정적인 파이프라인을 구축합니다.• 주요 비즈니스 지표(KPI)를 정의하고 모니터링하며, 데이터를 심층적으로 분석해 비즈니스 성장을 위한 유의미한 인사이트를 도출하고 가설을 검증합니다.• 데이터의 정확성과 신뢰도를 보장하기 위한 데이터 거버넌스 정책을 수립합니다. 데이터 계보(Lineage) 관리, 품질 테스트 자동화, 메타데이터 정의를 통해 누구나 믿고 사용할 수 있는 데이터 플랫폼을 구축합니다.• 다양한 이해관계자가 데이터에 쉽게 접근하고 활용할 수 있도록 대시보드를 개발하고, 직접 데이터를 분석할 수 있는 환경을 조성합니다.• 전사적인 데이터 리터러시 향상을 위해 데이터 활용 교육과 가이드를 제공합니다.","• 3년 이상의 데이터 분석 또는 데이터 엔지니어링 경험이 있으신 분• SQL을 활용해 대규모 데이터를 분석 목적에 맞게 가공할 수 있으신 분• 도메인 이해를 바탕으로 문제를 정의하고, 데이터 분석을 통해 개선방안을 도출하는 역량을 갖추신 분• Data Warehouse / Data Mart 모델링 및 성능 최적화 경험이 있으신 분• 데이터 품질 개선 및 파이프라인 운영 문제 해결을 주도적으로 경험해 보신 분• 다양한 이해관계자와 명확하게 소통하고 협업할 수 있는 커뮤니케이션 능력을 갖춘 분.","• 금융 또는 핀테크 도메인에서의 데이터 분석 및 모델링 경험이 있으신 분• 분석 결과·데이터 제품을 실제 서비스에 적용하여 비즈니스 임팩트를 증명한 사례가 있는 분• dbt 모델링·테스트·배포 자동화 경험 또는 도입 프로젝트를 리딩한 경험이 있는 분• DataHub·Amundsen 등 데이터 카탈로그/메타데이터 플랫폼 운영 경험이 있으신 분• GCP(BigQuery 등) 환경에서 데이터 작업을 해보신 분• Terraform, Pulumi 등 IaC 기반의 데이터 인프라 관리 경험이 있으신 분• 실시간 스트리밍 파이프라인(Beam, Spark Structured Streaming 등) 구축 경험이 있는 분• 다양한 업무 자동화 도구(Python, Shell Script, Airflow 등)를 활용해 반복 작업을 최소화해본 경험이 있는 분."
마크앤컴퍼니,"[신규 사업 아이디어 구현 및 제품화]• 신규 발굴된 사업 아이템을 AI 기술로 구현하여 실제 서비스와 제품으로 개발• 혁신의숲 데이터를 활용한 AI 중심의 신규 프로덕트 및 B2B 서비스 확장 지원[AI 모델을 활용한 시스템 개발]• 스타트업의 산업 카테고리 분류(Hierarchical Taxonomy) 및 핵심 키워드 자동 추출 (유사도 기반)• PDF 문서 및 비정형 데이터 분석을 위한 프롬프트 설계 및 최적화• LLM 기반 검색 및 질의응답 시스템 개발 및 성능 개선[데이터 처리 및 서비스 운영]• OCR 등의 기술을 활용한 PDF 등의 문서 내 이미지/그래프/텍스트 데이터 추출 및 처리• AWS 환경에서 AI 서비스 운영 및 성능 최적화• OpenAI, Claude, Gemini 등 다양한 LLM의 특성에 맞춘 프롬프트 설계 및 토큰 효율화※ 처음 합류하시게 되면 이런 업무를 담당하시게 됩니다!• 내부에서 발굴된 아이디어를 AI 기술로 구현하고 서비스화 가능성을 검증합니다.• 스타트업 데이터의 산업 분류 자동화와 핵심 키워드 추출 모델을 구축합니다.• PDF, OCR 등 비정형 데이터를 처리하기 위한 프롬프트와 파이프라인을 설계합니다.• LLM 기반 검색·질의응답 시스템을 개발하고 성능을 개선합니다※ 새롭게 합류하는 분에게 이런 점을 기대 합니다!새로 합류하실 분은 단순한 모델 개발을 넘어, 내부에서 발굴한 다양한 아이디어를 AI 기술을 활용해 실제 서비스와 제품으로 실현하는 주도적인 역할을 맡게 됩니다.• AI 기술을 활용해 스타트업 산업 분류 및 핵심 인사이트 도출을 자동화합니다.• 비정형 문서를 검색·분석·요약할 수 있는 LLM 기반 시스템을 설계하고 운영합니다.• B2B 서비스와의 연계 가능성을 고려해, 기술을 실제 비즈니스 가치로 연결합니다.※ 이런 성장의 기회를 함께 합니다!• 국내 최대 규모의 스타트업 데이터를 다루며, 실제 비즈니스 임팩트를 만드는 AI 시스템을 직접 구축할 수 있습니다.• LLM, 벡터DB, RAG 등 최신 AI 기술을 기반으로, 실험을 넘어 상용 서비스 수준의 품질과 확장성을 고민하며 성장할 수 있습니다.• 프로덕트의 방향성과 아키텍처를 설계하고, 제로투원(Zero-to-One) 단계의 성장을 경험합니다.• 데이터 플랫폼과 투자사가 결합된 독특한 환경에서, 스타트업 생태계의 흐름과 투자 관점의 인사이트를 함께 얻을 수 있습니다.• 장기적으로는 AI, 데이터, 비즈니스가 교차하는 복합 영역에서의 경험을 쌓을 수 있습니다.","[직무능력]• LLM 및 NLP 모델 실무 경험 (예: Hugging Face Transformers, OpenAI API 등)• 텍스트 처리, 임베딩 기반 유사도 분석, NLP 파이프라인 구축 경험• 문서 분석, 검색, 질의응답 시스템 설계 및 구현 경험• Python 등 프로그래밍 언어에 능숙한 개발 역량• 데이터 파이프라인 및 API 설계 경험• 다양한 이해관계자와 협업하며 명확하게 기술을 설명하고 문서화할 수 있는 능력[개인역량 및 성향]• AI 기술 트렌드와 새로운 지식에 대한 빠른 학습 능력과 높은 러닝커브• 새로운 것을 만들어가는 과정(Zero to One) 에서 성취감을 느끼는 분• 연구 중심보다는 실질적인 제품을 빠르게 구현하고 결과를 내는 것을 중시하는 분• 유연한 사고를 가지고 다양한 시도와 도전을 멈추지 않는 분.","• 스타트업/투자/기업 분석 도메인에 대한 이해 또는 경험• SetFit 등 소규모 라벨링 기반 분류 모델 구축 경험• OCR(예: Tesseract, PaddleOCR 등) 등을 활용한 이미지/그래프/텍스트 추출 및 처리 경험• AWS 환경에서 AI/ML 서비스 운영 경험 (S3, Lambda, SageMaker 등)• LangChain, LlamaIndex 등 LLM 애플리케이션 프레임워크 활용 경험• RAG(Retrieval-Augmented Generation) 기반 검색/질의응답 시스템 구축 경험• 외부 파트너와의 데이터 연계 및 협업 경험."
잉클,• FastAPI 기반의 REST API 서버 개발 및 운영• 제조 특화된 기능에 대한 백엔드 비즈니스 로직 개발• Keycloak 기반의 OIDC 및 OAuth2.0 인증/인가 서버 개발 및 운영• On-premise Kubernetes 기반의 컨테이너 어플리케이션 개발 및 배포/운영• PostgreSQL 또는 ScyllaDB 등의 Data Warehouse 활용• DeltaLake 와 Ceph 로부터 big data 추출 및 집계 서비스 개발• MCP (Model Context Protocol) 구현.,"• Python 프로그래밍이 능숙하신 분• Flask, FastAPI 등 framework을 이용하여 REST API 개발 경험이 있으신 분• PostgreSQL 등과 같은 RDBMS 활용 경험이 있으신 분• Kubernetes 환경을 이해하고 사용이 능숙하신 분• Micro Service 및 분산 시스템 개발/운영 경험이 있으신 분• 리눅스 개발 환경에 익숙하신 분• Git 을 잘 활용할 줄 아시는 분• 동료 엔지니어 들과 원할한 커뮤니케이션으로 협업이 가능하신 분.",• Kubernetes 기반 DevOps 경험이 1년 이상 있는 분• 오픈소스 컨트리뷰션 경험이 있으신 분.
에이드리븐,"• 사용자 행동 및 설문 데이터를 기반으로 고객 세그먼트 정의 및 특성 추출• 머신러닝 모델을 활용한 사용자 클러스터링, 예측 모델링, 퍼널 분석• 사용자 특성에 따른 광고 매칭 로직 개발 및 성과 분석• BigQuery 기반의 데이터 분석 파이프라인 설계 및 쿼리 최적화• 데이터 시각화 및 인사이트 도출을 통한 서비스/마케팅 팀 협업• A/B 테스트 설계 및 효과 분석.","• 데이터 사이언스 또는 관련 분야 2년 이상의 실무 경험• Python 기반 데이터 분석 능력 (pandas, numpy, scikit-learn 등)• BigQuery 또는 유사 SQL 기반 데이터 웨어하우스 활용 능력• 사용자 행동 데이터 분석 경험• 모델링 및 통계적 가설 검정에 대한 이해• Git 등 기본 협업 도구 사용 경험.","• 광고 추천 시스템 또는 타겟팅 알고리즘 개발 경험• Looker Studio, Tableau 등 BI 도구 사용 경험• 사용자 세분화 및 마케팅 퍼널 분석 경험• 스타트업 또는 빠르게 변화하는 환경에서의 업무 경험."
에이젠글로벌,"• 금융 및 비금융 데이터 기반의 AI 모델 연구 및 개발• 차세대 금융서비스를 위한 AI 알고리즘 설계 및 최적화• 딥러닝, 머신러닝 기반의 신규 R&D 프로젝트 수행• 금융기관 및 글로벌 파트너와 협력하여 AI 기반 솔루션 상용화.","• 컴퓨터공학, 데이터사이언스, 수학, 통계학, 전기전자공학 등 관련 전공 학사(병역특례 포함),석·박사 또는 이에 준하는 연구/개발 경험• Python, TensorFlow, PyTorch 등 AI 개발 프레임워크 활용 능력• 데이터 처리 및 분석 경험 (금융/비금융 데이터 모두 가능)• 머신러닝/딥러닝 기반의 모델링 및 AI 적용 수행 경험• 논리적 문제 해결 능력과 창의적 아이디어를 바탕으로 한 실험 및 구현 역량.","• 실제 비즈니스 또는 연구 프로젝트에서 AI 모델을 설계·개발·운영한 경험• 금융 데이터 모델링, 신용평가, 리스크 관리 관련 경험• ESG, 모빌리티, 헬스케어 등 비금융 산업 데이터 활용 경험• 국제 학회, 저널, 특허 등 AI 연구 성과 보유자• 글로벌 협업 환경에서의 프로젝트 경험 및 영어 커뮤니케이션 능력."
두나무(업비트/증권플러스),• 두나무 서비스 내/외에서 발생하는 다양한 데이터에 대해 데이터 마트 및 대시보드를 개발하고 DW 데이터 워크플로우 업무를 자동화합니다.• 효율적인 데이터 저장 / 검색 및 분석을 지원하기 위한 데이터 모델을 설계합니다.• 비즈니스와 데이터 간 연결고리 역할을 통해 최적의 의사결정을 할 수 있는 데이터 환경을 구성합니다.• 사내 데이터 카탈로그 운영 및 개선을 통해 전사 구성원이 데이터를 쉽게 접근하고 활용할 수 있도록 지원합니다.,"• 만 5년 이상의 데이터 분석과 마트설계 경력을 보유하신 분 • 주도적으로 DW/DM 데이터 모델링, 파이프라인 구축 및 운영 업무를 능숙하게 진행하신 경험을 보유하신 분• Hadoop Ecosystem 기반 혹은 클라우드 환경에서의 대용량 데이터 분석 경험이 있으신 분• 문제 해결을 위한 기본적인 CS 지식과 프로그래밍 역량을 갖추신 분• 상급 정도의 SQL, 중급 이상의 Python 기술 역량을 보유하신 분• Airflow 운영 및 트러블 슈팅 경험을 보유하신 분• BI(Business Intelligence) 플랫폼 등 데이터 시각화 툴(Redash, Superset 등) 사용 및 운영 경험을 보유하신 분• 데이터 품질 관리를 위한 환경 설계 및 운영 경험을 보유하신 분.","• 새로운 환경에 유연하고 빠르게 적응하실 수 있는 분• 협업 프로젝트 수행 경험 및 유연한 커뮤니케이션 능력을 보유하신 분• 문제 해결을 위해 오픈 소스 코드를 직접 분석하거나 수정해 본 경험이 있으신 분• 새로운 기술에 도전적이며, 그 지식을 동료와 공유하고 이를 통해 서비스 품질 향상에 기여할 수 있는 분• 블록체인 거래소의 지표 데이터 분석 경험이 있으신 분[지원서 작성 방법]• 이력서에는 실제 수행한 프로젝트를 중심으로, 본인의 역할과 기여 내용을 구체적으로 작성해주시기 바랍니다.• 프로젝트명이나 결과만 나열하기보다는, 아래 항목을 참고하여 경험의 전반적인 맥락을 전달해 주세요. (예시: 프로젝트 개요, 목적, 팀 구성, 주요 업무, 문제 해결 과정, 기여 성과/결과 등)• Github, GitLab, Bitbucket 등의 개인 프로젝트나 포트폴리오가 있다면 함께 첨부해 주세요. 실무 경험과 역량을 이해하는 데 도움이 됩니다.[유의사항]• 이력서는 자유 양식이며 모든 지원 서류는 수정 불가한 파일 형태(PDF 등)로 제출 부탁드립니다. (URL 첨부 불가)• 재직 이력은 빠짐없이 정확하게 작성해 주시고, 휴직 이력이 있다면 기간과 사유를 구체적으로 기재해 주세요.• 채용 과정에서 전/현직 직장의 영업 비밀이 침해되지 않도록 유의해 주세요.• 주민번호, 현재 연봉, 희망 연봉 등 민감한 정보는 삭제하거나 마스킹 후 제출해 주세요.[공통 지원자격]• 해외 여행에 결격 사유가 없으신 분[채용절차]서류전형 ＞ 1차면접 ＞ 2차면접 ＞ 처우협의 ＞ 최종합격 • 전형은 상황 및 일정에 따라 변경될 수 있습니다.• 지원서 내용 중 허위사실이 있는 경우에는 지원이 취소될 수 있습니다.• 국가 유공자 및 장애인 등 취업 보호 대상자는 관계 법령에 따라 우대합니다.• 최종 전형 전, 인성검사를 진행합니다• 본 포지션에 합격하시는 경우, 3개월의 수습 기간을 적용합니다.[채용정보]• 채용인원 : 0명• 고용형태 : 정규직• 채용유형 : 경력직• 근무지역 : 서울시 서초구 강남대로 369, DF Tower• 공고기간 : 상시채용 (채용 완료 시 조기에 마감될 수 있습니다.)."
버즈빌(buzzvil),"팀에 조인하셔서, 아래의 과업들을 같이 풀어나가면 좋겠습니다.1. SSOT거의 모든 데이터 파이프라인이 배치 워크플로우으로 운영되고 있어, 실시간으로 데이터를 보고싶은 니즈를 충족시켜주지 못하는 상황이고, unified logging system이 없어 유지보수하는데 많은 시간을 쏟고 있습니다. 현재 Confluent Kafka로 기존의 데이터 스트리밍 인프라를 이전하고 있으며, 함께 unified logging system을 만들어 가고자 합니다.2. DataDiscoveryAmundsen이라는 데이터 카탈로그 툴을 도입했으나 사용성이 낮아 이를 교체하는 작업을 계획하고 있습니다. 데이터 파이프라인의 히스토리를 체계적으로 관리하고 데이터 메타데이터를 쉽게 확인할 수 있는 방법을 함께 고민하고자 합니다.3. DataQuality2024년 2분기부터 데이터 퀄리티의 체계적인 관리 및 보장을 위해 여러 initiative를 시도하고 있습니다. 데이터 생산자와 소비자가 SLO와 expectation을 맞춰 볼 수 있는 교각을 만드는 일을 함께 해주셨으면 좋겠습니다.4. DataLake2024년 2분기에 데이터 플랫폼 단순화를 위해 데이터 웨어하우스로 사용하던 Redshift를 제거하고 S3/Athena인 데이터 레이크로 데이터 플랫폼을 통합하는 작업을 진행했습니다. 그 과정에서 Iceberg 테이블 포맷을 도입하여 ACID 트랜잭션이나 업데이트 작업등 유연한 기능들을 제공하고 있습니다. 데이터 플랫폼 상에서의 비효율을 포착하고 최적화하는 일을 같이 진행해보고 싶습니다.• 데이터 엔지니어의 Airflow 데이터 파이프라인 CI 테스트 개선기: https://buly.kr/BTQYU43• Self Serving Data Platform 구축하기 (feat. Airflow): https://buly.kr/1xzdW14.","• 1년 이상의 AWS, GCP등 cloud native 환경에서의 데이터 인프라 구축 및 운영 경험을 가지고 있습니다.• 안정적이고 확장가능한 데이터 제품을 설계하고 이를 서빙하기 위해 필요한 사항을 직접 구현할 수 있습니다.• 높은 코드 퀄리티와 아키텍쳐 수준을 지향하며, 이를 데이터 플랫폼 및 데이터 제품에 녹여낼 수 있습니다.• Airflow와 같은 워크플로우 scheduler (Prefect, Oozie등)에 대한 이해와 이를 활용한 워크플로우 개발 경험이 있습니다.• CS 전공자 또는 그에 상응하는 알고리즘, 데이터구조, OS, 데이터베이스 등 기본적인 전산 지식에 대한 이해도가 있습니다.","• Kubernetes의 전반적인 구성요소와 동작원리를 이해하고 있으며, Kubernetes 환경에서의 데이터 인프라 구축의 경험이 있습니다.• 언제든 Airflow, Spark와 같은 오픈소스의 코드를 직접 딥다이브 할 수 있는 의지와 능력이 있습니다."
나이스지니데이타,ㆍ다양한 소스(내/외부)의 데이터를 수집하고 정제하는 데이터 파이프라인 설계 및 운영ㆍ빅데이터 플랫폼(Hadoop/Spark 등)을 활용한 데이터 적재/가공 처리ㆍETL 워크플로우 자동화 및 모니터링ㆍ데이터 웨어하우스 및 데이터 레이크 구조 설계 및 최적화.,"ㆍ학력 : 대졸이상ㆍ경력 : 경력3년ㆍPython, Scala, SQL 등 데이터 처리 언어에 능숙하신 분ㆍSpark, Hadoop, Airflow 등 빅데이터/워크플로우 시스템 경험ㆍRDBMS/NoSQL 시스템 설계 및 운영 경험 (예: PostgreSQL, Hive 등)ㆍ대용량 데이터 처리 경험 또는 데이터 파이프라인 구축 경험ㆍ데이터 품질 관리 및 품질 향상에 대한 경험.",ㆍAWS/GCP/Azure 등 클라우드 환경에서의 데이터 플랫폼 구축 및 운영 경험ㆍLinux 기반 환경에서의 시스템 운영 및 쉘 스크립팅 경험.
도슨티,"사업체를 위해 고객 상담 맞춤 AI를 자동 생성해주는 B2B SaaS를 개발합니다.https://docenty.ai 를 2023년 12월 출시했습니다.국내 최고 수준 성장 속도• 모든 직군 채용합니다.Frontend engineerProduct ownerMarketing, SalesDesignerBackend engineer...backend tech stackspython (또는 nodejs, nestjs)langchain, FastAPI, MongoDBOpen AIGCP, firebasefrontend tech stackstypescriptreactjs, nextjsVercelPostgreSQL.","Preferences급속 성장하는 startup 초기 멤버로 참여할 기회를 갈망하시는 분급속 성장하고자 하는 의지가 크고, 꾸준한 열정으로 성장하실 분docenty 제품, 사업에 꾸준히 관심과 열정을 가지실 분. LLM, chatbot, SaaS해외 시장에서 global tech 기업들과 경쟁하는 것을 즐기실 분일반적인 전형 과정1. 서류 심사2. casual video call (회사, 제품, 전형 설명)3. on-site interview a. (전공 과목 또는 연구 주제 있는) in-depth 기술 주제 하나 정해서 문답 토론 b. tech position 실무 면접의 경우, live coding, system architecture design (google 등 미국 big-tech interview와 일부 유사).","• 스스로의 힘으로 높은 수준의 허들을 넘어 온 사람, 남들이 정해 놓은 선을 넘어 결과를 만들어 온 사람 (*)• 특별한 우수성 입증 실적• 특별히 노력해서 특별한 성과를 달성했던 자랑스러운 이력• 세상을 혁신, 변화 시킨 경험 또는 습관오해 없도록 주의• 살면서 동료들, 남들, 환경 때문에 자기 성과가 안 나왔다고 생각이 든다면, 초기 스타트업이랑 안 맞을 가능성이 큽니다. 최종 결과가 고객에 도달하기까지 추진력 있게 문제를 직접 해결 할 분을 채용합니다. 동료들도 적극적으로 돕고, 능력을 발휘합니다.• 최고의 성과를 먼저 증명하고, 회사를 성장시킬 potential을 증명한 분들께, 회사가 제공 가능한 모든 것을 최대한 제공합니다. (**) 아이디어 출처* ""스스로의 힘으로 높은 수준의 허들을 넘어 온 사람, 남들이 정해 놓은 선을 넘어 결과를 만들어 온 사람"" - https://ko.antler.co/ 2024년 데모데이 행사** ""용병 아닌 선교사를 채용하라"" - https://vimeo.com/731186065 , Jeff Bezos at Amazon."
아이오트러스트,"【직무소개】 이렇게 일을 해요• 데이터 기반 의사결정을 신속하고 정확하게 수행할 수 있도록 안정적인 데이터 인프라 구축하고 운영하는 역할을 해요.• 앱/웹·마케팅 등 다양한 소스에서 데이터를 체계적으로 수집·저장·가공하여, 구성원이 필요한 정량 정보를 쉽게 활용하도록 지원해요.• 데이터 모델링을 통해 주요 의사결정 지표를 효율적으로 추출하고, 시각화 도구로 인사이트를 제공해요.• DW/BI 엔지니어로서 비즈니스 성장과 서비스 최적화를 데이터로 뒷받침해요.【업무소개】 이러한 일을 해요• GTM·GA4 기반 이벤트 데이터를 수집·관리하고, 이벤트 택소노미와 이벤트 정의서를 작성·유지보수해요.• BigQuery 기반 데이터 웨어하우스를 설계하고, Airflow로 데이터 파이프라인·배치를 설계·개발·모니터링해요.• 서비스/운영 목적에 맞는 데이터 마트를 구축하고, 메타베이스를 통해 BI를 제공해요.• 광고 플랫폼 API를 연동해 원천 데이터를 수집하고, 마케팅 퍼널/KPI 대시보드를 구축·운영해요.• 의사결정 지원을 위한 핵심 KPI를 정의·모니터링하고, 분석 인사이트를 제공해요. 【업무도구】 이러한 툴을 활용해요• 데이터 인프라 및 분석: Airflow, Python, AWS EC2, AWS Lambda, GCP, BigQuery, PostgreSQL, Metabase, Amplitude, Google Tag Manager, Google Analytics 4• 개발 도구: VS Code, Cursor, Claude Code• 협업: Github, Slack, Notion, Jira, Confluence 【업무방향】 이러한 경험도 할 수 있어요• 지갑 서비스의 BM에 필요한 데이터가 무엇인지 깊이 이해할 수 있어요.• DW/BI 뿐만 아니라 데이터에 관련한 새로운 업무영역을 시도하고 개발할 수 있어요.• AI툴을 적극 활용하여 업무 효율을 높이고, 더 많은 아이디어를 빠르게 실험할 수 있어요.","【자격요건】 이러한 분을 찾고 있어요• 2년 이상의 DW/BI 엔지니어링 관련 경력은 필수예요. (Web3/블록체인 관련 경험은 없어도 무방해요.)• 핵심 지표들을 정확하게 추출할 수 있는 SQL 작성 역량을 가진 분을 찾아요.• GA4·GTM, Metabase/Amplitude 등의 분석·시각화 도구를 실무에서 활용해 본 경험이 필요해요.• Python과 API를 활용해 데이터 수집/배치를 자동화해 본 경험이 있거나, 단기간에 구현할 수 있는 역량이 필요해요.• 이벤트 정의서, 데이터 사양서, 대시보드 가이드 등 산출물을 체계적으로 문서화하는 스킬이 필요해요.","【우대사항】 이러한 분이면 더욱 좋아요• 이벤트 정의서와 택소노미를 수립하고 운영한 경험이 있으면 좋아요.• Airflow를 활용한 데이터 오케스트레이션과 모니터링 경험이 있으면 더욱 좋아요.• 간단한 리눅스 명령어와 Git/GitHub를 통해 코드를 배포해 본 경험이 있으면 환영해요.• OpenAI API나 LLM을 통해 자동화 환경을 구축해본 경험이 있으면 더욱 환영해요.• 개발, UI/UX, 마케팅, 기획, 전략 등 다양한 팀과의 유연한 커뮤니케이션 경험이 있으면 최고예요."
와드(캐치테이블),"• 캐치테이블의 서비스/제품(예약/대기, 광고 사업 등)을 이용하는 모바일 유저들의 행태 Data를 정제/가공/적재하며, 유관부서에서 Data 기반의 의사결정을 할 수 있도록 정량적 수치와 분석 결과를 제공• Product Manager와 함께 유저의 앱사용성에 대한 문제를 정의하고 이를 평가하기 위한 지표를 설계하고 분석과제를 발굴• 데이터 엔지니어와 협업하여 시각화 툴 등을 활용하여 주요 지표를 모니터링하는 대시보드를 만들고 운영.","• SQL(MySQL, BigQuery), Python 등 을 활용하여 5년 이상의 데이터 분석 및 실무 경력을 보유하신 분• 원천 데이터 정제부터 문제 정의, 인사이트 도출 및 액션아이템 제시까지 데이터분석 전반의 과정을 수행하신 분• 최소 1개 이상의 데이터 시각화 툴(Superset, Redash, GA4, Tableau, Quicksite 등)을 능숙히 사용하실 수 있는 분• 모바일 서비스 데이터 분석 방법(Customer Lifetime Value, Retention, Cohort Analysis 등)에 대한 이해도를 가지신 분.","• Snowflake, BigQuery 중 하나이상의 사용경험이 있으신 분• 실시간 데이터 스트리밍 서비스 구성 경험이 있으신 분• 데이터 엔지니어, 데이터 사이어티스트와의 협업에 익숙하신 분• 파이프라인 자동화, 모니터링, 데이터 품질 검증 자동화, 보안 경험이 있으신 분• MLOps 관련 경험이 있으신 분."
이모코그,"• 다양한 의료 데이터 분석(EDA/ML)을 통해 새로운 데이터 레벨에서의 인사이트 발굴• 의료 데이터 파이프라인 설계·운영 (ETL, 검증, 모니터링 자동화)• 의료진·AI 연구진과 협업하여 임상 가치 창출을 위한 ML 모델 기획·실험·평가• 의료 데이터 기반의 언어 모델(LLM) 그래프 노드 아키텍처 설계를 통한 서비스 설계·성능 최적화.",• 경력 2년 이상• 학력무관.,"• 의료 데이터 처리를 위한 파이프라인 구축 경험• 헬스케어 빅데이터(EMR, CDW, CDM 등) 기반의 데이터 분석 및 임상 연구 경험• Python, R, SQL 등 활용한 데이터 추출, 가공, 탐색, 분석, 모델링, 시각화 가능• 의료 분야와 데이터 기반 임상 가치 창출에 대한 관심과 열정• ML, LLM 연구 및 개발 프로젝트 참여 경험(유관 분야 학회/학술지 논문 실적 보유)• 솔루션 개발팀과 협업 경험 보유(AI 서비스 개발-배포 경험)."
인포유앤컴퍼니,"• LLM 기반 AI 에이전트 및 RAG 시스템 개발·운영 • AI 애플리케이션 품질 관리 및 프롬프트 엔지니어링 • 사용자 피드백 기반 품질 성능 개선 • 최신 AI 기술 동향 파악 및 도입 검토[인터뷰] AI 백엔드 개발자가 되고 싶다면? https://blog.naver.com/in4ucloud/223811762475 ＜ 클릭해주세요![현재 진행중인 프로젝트]• 엔터프라이즈 특화 LLM 구축 및 고도화 - S사 복지 메뉴얼 분석 솔루션, L사 CHATDA 데이터 분석 솔루션https://blog.naver.com/in4ucloud/223570648227 ＜ 클릭해주세요!• LLM 기반 Business Tool 플랫폼 구축 및 고도화 - D사 AICHAT 플랫폼 솔루션, S사 AICHAT 플랫폼 솔루션 등등• BXG - 기업용 AI LLM 솔루션 개발 https://blog.naver.com/in4ucloud/223920418480 ＜ 클릭해주세요!","• Elasticsearch/Cosmos DB(vCore)등 벡터 DB 기반 RAG 시스템 구현 경험 보유자 • LLM API 및 프레임워크(LangChain/LlamaIndex 등) 기반 AI 에이전트 개발 경험 • LLM 애플리케이션 성능 최적화(토큰/속도/정확도) 및 프로덕션 운영 경험 • 프롬프트 개선 및 생성형 AI 품질 검증 경험 보유자 • Hugging Face/Ollama 등 오픈소스 모델 활용 및 최신 NLP 기술 스택 전문가 • Git 기반 협업 및 코드 리뷰 경험 • AI Coding Assistant(Claude Code, Cursor 등) 실무 활용 경험 • 요구사항을 기술 문서로 구체화하고 효과적으로 커뮤니케이션하는 능력.",• 최신 AI 연구를 빠르게 습득하고 팀에 효과적으로 전파할 수 있는 커뮤니케이션 스킬 • 최신 AI 논문을 신속하게 이해하고 비즈니스 관점에서 평가할 수 있는 능력 • AI/ML 관련 오픈소스 프로젝트 기여 또는 개인 연구 프로젝트 경험 • AI Coding Assistant의 한계를 이해하고 적절히 활용할 수 있는 분 • 확장 가능하고 유지보수 용이한 코드 구조 설계 능력.
슈프리마,"이 포지션은 당사의 해외 기술지원 전용 AI Chatbot 운영 및 고도화를 위해 신설되었습니다.Python 기반 개발 역량과 데이터 분석·품질 관리 능력을 바탕으로, Chatbot 성능 향상과 서비스 안정성 확보를 주도하며,데이터 품질 관리와 일부 소프트웨어 기술지원 업무를 통해 부서 전체의 역량 향상에 기여하게 됩니다.메인 업무• 해외 기술지원 전용 AI Chatbot(자사 서비스)의 유지·보수 및 신규 기능 개발, 성능 개선을 주도함• Chatbot 응답 데이터 검증·품질 관리 및 통계 리포트 작성• Chatbot 서비스의 성능과 안정성을 높이기 위한 테스트 수행• LMS(Learning Management System), 해외기술지원 포털 등 해외기술지원 업무에 사용되는 플랫폼 운영 관리 공통 업무• 소프트웨어 기술지원 티켓 대응(문제 재현·분석 포함)• 해외 파트너/지사 대상 기술 트레이닝과 기술 문서 작성.","• Python과 JavaScript를 활용해 AI Chatbot을 개발하고 개선할 수 있는 분이에요.• 데이터 분석과 시각화 도구를 활용해 인사이트를 도출할 수 있는 분이에요.• LLM, RAG, 멀티모달 AI를 실제 서비스에 적용한 경험이 있는 분이에요.• 서비스 테스트를 설계하고 실행해 품질을 높이는 데 기여할 수 있는 분이에요.• 새로운 기술과 환경에 빠르게 적응하고, 자기 주도적으로 문제를 해결하는 분이에요.• 해외 지사와의 협업과 다양한 업무에 열린 태도로 임할 수 있는 분이에요.• 영어로 기술 문서를 작성하고 커뮤니케이션이 가능한 분이에요.(비즈니스 영어 수준)• 학력: 학사 이상 (관련 전공 우대)• 경력: Python 기반 개발 경력 3년 이상.","• API 개발·연동 경험이 있고, 해외 기술지원 또는 해외 고객 대응 경험이 있는 분이에요.• AWS, Azure, GCP 등 클라우드 환경에서 개발 경험이 있는 분이에요.• 서비스 성능 최적화 경험이 있고, 데이터 품질 관리 도구를 활용할 수 있는 분이에요."
네이션에이,"• 데이터베이스 & 데이터 레이크 구축• 스타트업 환경에서 유저 로그·모션 데이터·AI 학습를 통합 관리할 수 있는 데이터베이스 구조 설계\• Cloud SQL / Firestore 등 운영 데이터베이스 설계 및 관리• Motion / Video / Text / Log 등 원천 데이터 수집 및 관리• Composer(Airflow)와 Dataflow 기반 ETL/ELT 파이프라인 설계 2. 3D 캐릭터&모션 데이터 및 유저 로그 및 서비스 데이터 관리• AI 학습용 데이터셋 생성 파이프라인 구축• 모션 품질 지표 자동 평가 시스템 구축• AI+3D 캐릭터챗 대화 로그, 세션, 감정/의도 데이터 수집 및 가공 3. 검색 시스템 및 품질/모니터링 및 협업• Text / Embedding 기반 Semantic Search 시스템 구축• 메타데이터 스키마 설계• 데이터 검증/품질 관리 자동화.","• 데이터 엔지니어링 또는 데이터 인프라 관련 실무 경력 3년 이상• Python, SQL, PySpark 등 데이터 파이프라인 개발 역량• AWS, GCP 기반 데이터 인프라 설계 및 구축 경험• Airflow, Prefect, Dagster 등의 배치 파이프라인 운영 경험• Elasticsearch, OpenSearch, FAISS 등 검색 인프라 이해.","• Docker 및 CI/CD 환경 기반 배포 경험• RBAC(Role-Based Access Control), IAM, KMS 기반 보안 데이터 아키텍처 설계 경험• Vector DB 구축 및 모션/텍스트 검색 시스템 경험• 유저 로그 기반 대화·행동 분석 및 대화 RAG 파이프라인 경험• MLOps/MLFlow/SageMaker 등과 연계된 DataOps 설계 경험• AI 학습용 Feature Store 및 Evaluation Pipeline 운영 경험• FBX/BVH/JSON/OBJ 등 3D 캐릭터&모션 데이터 포맷 처리 경험• 오픈소스 프로젝트 기여 경험."
토스뱅크,[합류하면 함께할 업무예요]• 토스뱅크의 재무분석팀과 긴밀한 커뮤니케이션을 통해 재무분석 마트를 설계하고 관리회계 시스템을 개발하고 운영해요.• 토스뱅크의 재무ALM팀과 긴밀한 커뮤니케이션을 통해 재무ALM 마트를 설계하고 재무 ALM 시뮬레이션 시스템을 개발하고 운영해요.• Hadoop-Ecosystem과 오픈소스솔루션 기반으로 Workflow 개발 및 자동화 업무를 수행해요.,[이런 분과 함께하고 싶어요]• 금융권에서 관리회계 or ALM 시스템 관리 업무 경험이 있는 분이 필요해요.• Java or python 의 언어로 주어진 비즈니스 로직을 구현할 수 있는 분이 필요해요.• SQL의 언어를 자유롭게 다룰 수 있는 분이 필요해요.• 재무분석 or ALM에 필요한 마트 설계 / 배치 스케줄링을 구축하고 운영하신 분이 필요해요.• Frontend / Backend 기술을 활용해 관리회계 or ALM 시스템 개발이 가능하신 분이면 더 좋아요.• Hadoop-Ecosystem 환경의 데이터처리 기술 활용 경험이 있으면 더 좋아요.,"[이력서는 이렇게 작성하시는 걸 추천해요]지원서에는 아래 2가지 내용을 꼭 포함해주세요. 서류전형 검토의 중요한 자료로 활용됩니다.• 업무에서 반복적으로 발생하는 문제를 해결하기 위해 자동화했거나, 기존과 다른 방식으로 문제를 해결한 사례를 하나만 작성해 주세요.• 최근 새로운 기술에 대해 깊이 있게 학습한 경험을 작성해 주세요."
코드잇(codeit),"【 이런 일을 해요 】• AI 분야의 교육 콘텐츠를 제작합니다. • 콘텐츠 제작을 위한 리서치 • 커리큘럼 기획 • 영상, 노트, 실습, 퀴즈 제작 • 콘텐츠에 대한 피드백과 반영콘텐츠 프로듀서(콘텐츠 PD)를 쉽게 설명하면, 온라인 강의 콘텐츠를 만드는 '선생님' 역할입니다.코드잇은 인터랙티브하게 코딩을 배울 수 있는 구독 서비스입니다. 플랫폼 뿐만 아니라 콘텐츠까지 직접 제작하는 것이 코드잇의 차별화 전략입니다. 그리고 이 콘텐츠를 만드는 분들이 바로 '콘텐츠 PD'입니다. 온라인 강의를 만든 경험이 없으셔도 괜찮습니다. 콘텐츠 PD로서의 자질이 보이는 분을 발굴하고, 코드잇이 제공하는 인프라 안에서 좋은 콘텐츠를 제작할 수 있도록 돕는 것이 저희의 임무입니다. 그리고 그 분들이 창출할 가치는 엄청나기 때문에, 조건에 부합하는 분들에게는 확실한 대우를 해 드리려고 합니다.【 이런 팀에서 일해요 】콘텐츠 팀은 현 시대의 교육의 문제점을 직면하고, 이를 해결하기 위해 가장 앞단에 있는 팀입니다. 실무 역량과 콘텐츠 역량을 모두 갖춘 훌륭한 팀원들이 모여 수강생 분들이 보다 쉽게 이해하고, 보다 재미있게 배울 수 있도록 항상 고민합니다. 그리고 깊은 고민 끝에 가장 필요한 주제를 선정하여 모든 레슨이 유기적으로 연결될 수 있도록 커리큘럼을 기획하고 콘텐츠를 제작합니다. 단순히 배우는 것에 그치는 것이 아닌, 사람들이 배움의 기쁨을 느끼고 배움에 빠지도록 합니다.","코드잇은 항상 세계 최고 수준의 콘텐츠를 목표로 합니다. 확실하게 검증하고 확실한 분들만 모셔서, 확실한 대우를 해 드립니다.【 이런 분을 찾고 있어요 】• 머신러닝, 딥러닝 및 생성형 AI 전반에 대한 뛰어난 역량과 지식을 갖추신 분 • 전통적인 머신러닝 이론과 알고리즘을 이해하고 있습니다 • CNN, RNN 계열부터 Transformer 기반 모델까지 다양한 딥러닝 모델의 구조와 원리를 이해하고 있습니다 • LLM을 포함한 생성형 AI 기술의 원리와 최신 트렌드를 파악하고 있습니다 • Scikit-learn, PyTorch, LangChain, Hugging Face 등을 능숙하게 활용할 수 있습니다 • 실제 동작하는 AI 애플리케이션을 설계하고 구현할 수 있습니다• 콘텐츠 제작 역량이 뛰어난 분 • 이해하기 쉽고 간결한 글을 작성합니다 • 새로운 내용을 빠르고 정확하게 리서치할 수 있습니다 • 설명에 있어서 절대 틀리지 않을 자신이 있습니다 • 사람들이 어떤 것을 어렵게 느끼고, 어떤 것을 궁금해 하는지 잘 파악합니다• 커뮤니케이션 능력이 뛰어난 분 • 피드백을 이해하고 반영할 자신이 있습니다 • 또 반대로, 좋은 피드백을 줄 수 있습니다 • 효율적이고 깔끔한 커뮤니케이션에 자신이 있습니다.","【 이런 분이면 더 좋아요 】• 교육 분야에 관심이 많은 분• AI 분야에서 연구 또는 엔지니어링 실무 경험이 있으신 분데이터 사이언스 분야 실무 경험이 있는 분• 디자인 감각이나 영상 기획력이 있는 분• 자신있게 촬영에 임할 수 있는 분• 코드잇을 수강한 적이 있으신 분• 아래 주제의 교육 콘텐츠를 자신 있게 만들 수 있는 분 • 머신러닝, 딥러닝, 컴퓨터 비전, 자연어 처리, LLM 애플리케이션 개발, MLOps, 수학과 통계학 등 • 이 외에도 다양한 주제의 콘텐츠를 제작할 예정이니 편하게 지원해 주세요【 현직 콘텐츠 프로듀서에게 물었어요 】Q. 이 일을 하면서 가장 좋은 부분은 무엇인가요?A. 파급력 있는 일을 한다는 점이 즐겁습니다.온라인 콘텐츠는 도달 범위의 제한이 없잖아요? 그래서 콘텐츠 하나를 잘 만들면 계속해서 많은 분이 이용할 수 있죠. 심지어 우리가 자고 있는 순간에도요. 우리가 만든 교육을 통해 많은 사람들이 프로그래밍을 배우고 뛰어난 개발자가 된다는 점이 참 멋진 것 같아요. 매일 올라오는 후기를 읽는 것도 재미가 쏠쏠하답니다.Q. 실무를 하다가 콘텐츠 PD로 오셨는데, 두 역할이 어떻게 다른 것 같으세요?A. 실무에서 일할 때는 보지 못하던 것들을 발견하는 것 같아요.실무에서는 만들어 내는 것에 초점을 두는 반면, 콘텐츠 PD는 이해하고 원리를 파악하는 것에 초점을 두거든요. 예전에는 일정 맞춰서 만들어 내기 급급해서 지나친 부분이 많았는데요. 누군가에게 가르치려고 그 내용을 다시 보니, 새롭게 깨닫는 것들이 많더라고요. 하나를 가르치기 위해 열 이상을 공부하게 될 때도 많고요. 제대로 공부할 기회가 주어진다는 점이 콘텐츠 PD의 메리트인 것 같습니다."
데이터라이즈,"• 500개가 넘는 고객사의 모든 커머스 데이터와 일 5천만 건 이상의 고객 행동 로그를 바탕으로 비즈니스 요구사항을 데이터로 해석하여 알맞은 데이터를 만들어냅니다.• 수억 건 이상의 가공된 데이터들을 최종 고객에게 빠르게 전달할 수 있는 다양한 어플리케이션을 설계, 개발, 운영하고 이 과정에서 다양한 직군의 동료(데이터 직군, 백엔드 엔지니어, PM, 세일즈 등)와 함께 협업하여 데이터로 서비스에 가치를 부여합니다.• 데이터 사이언티스트, 분석가, 엔지니어와 함께 협업하여 데이터라이즈의 복잡하고 방대한 데이터를 서비스에서 활용할 수 있도록 파이프라인을 구축합니다.• 글로벌 환경에 맞는 데이터 서비스를 만드는데 긴밀히 참여합니다.","• 데이터를 활용하여 비즈니스 문제를 해결해보신 경험이 3년 이상이거나, 이에 준하는 실력을 가지신 분• SQL 활용 능력이 탁월하신 분• Spark 등의 대용량 분산 처리 기술 사용 경험이 있으신 분• Airflow와 같은 job orchestration framework 사용 경험이 있으신 분• Python 사용 경험이 있으신 분• 다양한 직군의 동료들과 거침없이 커뮤니케이션하며 결과를 만들어내실 수 있는 분.",• 정의되지 않은 과제를 정의하고 스스로 해결하는 것을 즐기시는 분• 새로운 도메인 지식을 빠르게 학습하시는 분• CS 전반 지식 및 프로그래밍 능력이 뛰어나신 분• CRM에 대한 이해가 있으신 분.
에이아이트릭스(AITRICS),"About the PositionVirtual Doctor 부문은 LLM을 비롯한 AI 기술로 의료 서비스 패러다임을 혁신하는 V.Doc을 개발하고 있습니다. 진료 현장에서 의사-환자 간 음성 대화를 실시간으로 이해하여 의료진의 업무 부담을 획기적으로 줄이는 Ambient AI 기술을 구현하고 있습니다.의료 전문 용어와 복잡한 진료 상황을 정확히 인식하는 음성인식 기술을 고도화하고, 더 나아가 Speech LLM을 함께 개발할 뛰어난 AI 연구원을 모십니다.• V.Doc 서비스에 탑재되는 의료 음성인식 모델 연구 및 성능 고도화• 의료 환경에 특화된 STT 모델 학습 및 평가 파이프라인 설계 및 구축• 대규모 음성 데이터 전처리, 정제, 증강을 포함한 데이터 구축 전략 수립 및 실행• 최신 강화학습 기법을 활용한 모델 alignment 및 성능 최적화• Speech Foundation Model 고도화 및 Ambient AI를 위한 Speech LLM 연구/개발• 유관부서와의 긴밀한 협업을 통한 기술의 실제 서비스 적용, 테스트 및 지속적인 개선.",• 음성인식(STT) 분야에서 3년 이상의 연구/개발 경력을 보유하신 분 (석/박사 학위 기간 포함)• PyTorch 등 주요 딥러닝 프레임워크를 활용한 모델 개발 및 구현에 능숙하신 분• STT 모델의 상용 서비스 적용 및 운영 경험을 보유하신 분• STT 모델 학습 및 평가 파이프라인을 직접 설계하고 구축해 본 경험이 있으신 분.,"• 음성, 컴퓨터, 통계, 인공지능 관련 분야 석사 학위 이상 소지자• ICASSP, Interspeech 등 음성 AI 분야 주요 학회 논문 게재 경험이 있으신 분• LLM 기반 Speech-Language 멀티모달 모델 연구/개발 경험이 있으신 분• Speaker Diarization 혹은 Speech Separation 모델 연구/개발 경험이 있으신 분• 의료 AI 또는 디지털 헬스케어 도메인에 대한 경험 및 이해도를 갖추신 분."
아임웹,"• Kafka 기반 CDC 시스템을 구축하고 운영하여 서비스로부터 발생하는 내부 데이터를 수집해요.• Python, Spark 기반의 안정적이고 효율적인 데이터 파이프라인을 구축 및 운영해요.• 데이터 거버넌스 및 권한 체계를 구축해요.• 데이터 플랫폼, 인프라를 안정적으로 운영하고 최적화 시켜요.• 데이터 품질, 처리 성능을 모니터링해요.","• 데이터 엔지니어링 유관 업무 3년 이상의 경력을 보유한 분• Hadoop & Spark 등 분산 처리 시스템에 대한 이해가 있고 직접 경험해보신 분• Kafka & Kafka Connect, Streaming 등 Kafka에 대한 이해도가 높고 운영 경험이 있으신 분• 프로그래밍 언어(Python, Scala 등)와 Database 전반에 대한 이해도가 있으신 분• 뛰어난 커뮤니케이션 역량으로 팀원들과 소통하고 능동적인 협력이 가능하신 분.","• AWS & Databricks 등 클라우드 환경에서 개발 및 운영 경험이 있으신 분• 대용량 데이터 처리를 위한 분산시스템을 구축하고 운영한 경험이 있으신 분• Airflow, Airbyte, Perfect 등 Workflow manager 운영 경험이 있으신 분• Docker/Kubernetes와 같은 컨테이너 환경에서의 경험이 있으신 분• 데이터 거버넌스 구축 및 운영 경험이 있으신 분."
핸디즈,"• 시장/수요/경쟁/재고 데이터를 수집·정제하여 동적 가격 전략을 분석하고, A/B 실험을 설계·수행해 결과를 지표로 검증·반영합니다.· 기존 가격 알고리즘/룰을 운영·모니터링합니다.· 자사 브랜드(urbanstay, LECOLLECTIVE) 고객의 정형/비정형 데이터 분석을 통하여, 비즈니스 인사이트 도출합니다.· 서비스&비즈니스 데이터를 구축하고 운영합니다.","• 학력 : 학사 이상 (수학/통계학, 경제학, 공학 계열 등 유관 전공)· 주요 기술 스택 : Python, SQL, BI 도구· 5년 이상의 데이터 분석 및 리포팅 관련 경력을 보유한 분· 통계적 분석, 가설 수립 및 검증에 능숙한 분· 복잡한 비즈니스 문제를 데이터 관점에서 재정의하고 해결책을 도출하는 능력이 있는 분· 고객 중심으로 데이터를 이해하고 해석하는 리터러시를 보유한 분· 성과지향적인 목표를 설정하고 과제에 몰입하여 추진하는 분· 분석 PoC를 설계하고 실효성을 지표로 검증하며, 회귀·분류 등 기본 모델링을 통해 인사이트를 강화할 수 있는 분· 데이터 중심의 커뮤니케이션을 하는 분.","• Google Cloud Platform 및 Google BigQuery를 활용한 대규모 데이터 핸들링 경험이 있는 분· 마케팅 퍼널, 고객 행동 데이터, 코호트 분석 등 제품/서비스 운영 데이터 분석 경험이 있는 분· 데이터 전처리 및 간단한 모델링(회귀, 분류) 경험이 있는 분▷ 핸디즈는 이런 사람을 찾습니다!· 변화를 즐기고 목표를 달성했을 때 성취감을 느끼는 분· 팀 성공을 위해 주도적으로 먼저 달려가는 분· 원활한 커뮤니케이션으로 다양한 이해관계를 조율하여 결과를 이끌어 내는 분· Plan-Do-Check-Action 업무 사이클을 이해하고 한 걸음 더 나아가는 분."
아이넥스코퍼레이션,• 의료 영상 인공지능 데이터의 수집 전처리 가공 및 분석• 의료 영상 인공지능 기술에 대한 조사 연구 및 구현• 의료 영상 인공지능 모델의 설계 구현 및 성능 평가• 의료 영상 인공지능 알고리즘의 개발 최적화.,• 경력 무관• 대학교졸업(4년)이상• Python 기반 개발 환경과 TensorFlow 또는 PyTorch 활용 경험• 기본적인 의료영상 처리 및 전처리 역량• 논문 기반 기술 검토와 기술 적용 경험 또는 관심• 협업 중심의 커뮤니케이션 역량.,"• 의료 영상 AI, 특히 내시경, CT, MRI 등 분야 경험자• 실시간 추론 최적화 또는 Edge 환경 배포 경험• 해외 영어 커뮤니케이션 가능자."
플랜잇스퀘어,"대형 병원 EMR 데이터를 가공해 데이터 파이프라인 설계·구축• DW 모델링 및 실시간 분석 환경 구현을 위한 데이터 적재·전송• 임상 질지표 & 병원 경영 통계 관리 DB 설계·운영• 질환별 임상 레지스트리(데이터 라이브러리) 설계·배포• 시스템 운영·유지보수, 성능 튜닝 및 데이터 품질 관리• DW Engineer 포지션 업무의 대부분은 SQL로 수행됨• 주로 다루는 DBMS: Vertica(경험 없어도 문제 없음), Oracle, MSSQL, PostgreSQL• ＜주의: 비대상 업무＞ ML, LLM, 알고리즘 등 AI 관련 업무 아님. Tableau/Power BI 등 시각화 업무 아님.","필수 조건• PL/SQL 기본 개념 이해• 데이터베이스 기본 지식 · 테이블, 인덱스, 뷰, 트랜잭션 제어(커밋/롤백)의 개념 이해 · PK/FK, 정규화/비정규화 개념 숙지• PL/SQL 블록 작성 경험• PL/SQL 함수·프로시저 개발 기초• 간단한 성능 고려 · SQL 작성 시 JOIN 순서나 인덱스 필요 여부를 고민해 본 경험 · EXPLAIN PLAN을 통해 쿼리 실행 계획을 기본적으로 확인해 본 경험 (기본적인 INDEX 사용 여부 확인 수준)• SQL 쿼리 작성 및 분석 능력 · 테이블 간 JOIN을 이용해 두 날짜 컬럼 간 기간을 계산하고, 그 기간이 정해진 임계값을 초과하는 건수를 집계하여 반환하는SQL 작성 경험 · 예: ""TBL_A의 시작일·종료일과 TBL_B의 기준일을 JOIN하여 기준일과 종료일의 차이가 30일 이상인 레코드를 집계"" · 가장 빈도수가 높은 기간(예: 가장 많이 존재하는 특정 일자 범위)을 찾아서 해당 기간에 속하는 모든 레코드를 한 번에 조회하는 SQL 작성 경험 · 예: ""고객 행동 로그 테이블에서 7일 단위 세그먼트를 기준으로 가장 많은 트랜잭션이 발생한 구간을 식별하고, 그 구간 내 상세 데이터를 조회"" · 위 두 시나리오를 하나의 복합 쿼리나 PL/SQL 블록으로 처리하여, 집계 및 상세 조회를 동시에 수행할 수 있는 능력 (예: 서브쿼리, CTE, 윈도우 함수 결합)경력에 따라 아래 역량 가산점• 커서(Cursor) 및 단순 예외 처리 · 명시적(explicit) 커서를 사용해 다중 행 조회 후 반복 처리한 경험 · NO_DATA_FOUND, TOO_MANY_ROWS 같은 표준 예외를 EXCEPTION 블록으로 처리한 경험• 커서 및 REF CURSOR 활용 · 다중 행 처리(Complex Cursor) 및 커서 변수(Cursor Variable)를 사용해 동적 결과 집합(Return Set)을 반환하는 프로시저 구현 경험 · SYS_REFCURSOR를 통한 결과셋 반환 및 이를 호출 프로그램(Java, PL/SQL 등)에서 처리한 경험• 기본 트리거(Trigger) 작성 · 삽입 또는 갱신 시점에 간단한 로깅/데이터 검증 로직을 AFTER/BEFORE 트리거로 구현해 본 경험 (예: INSERT 시 컬럼 값 체크 후 오류 발생)• 트리거(Trigger)로 복잡한 비즈니스 로직 구현 · UPDATE/INSERT/DELETE 시점에 변경 전·후 값을 비교하여 이력 테이블에 자동 기록(Audit Log)하거나, INSERT 시 유니크 조건을 추가 검증하는 등 고급 트리거 로직 작성 경험 · 트리거 내부에서 커서 호출, PL/SQL 함수 호출 등 복합 로직을 실행하여 데이터 무결성 및 감사 기능을 구현한 경험• 동적 SQL 및 바인드 변수 사용 · EXECUTE IMMEDIATE 또는 OPEN cursor_name FOR 구문으로 입력 파라미터(WHERE 절 조건이 가변적일 때)를 동적으로 조립하여 SQL을 실행한 경험 · 동적 SQL 작성 시 SQL 인젝션을 방지하기 위한 바인드 변수 사용 경험• 예외 처리 및 트랜잭션 제어 · NO_DATA_FOUND, TOO_MANY_ROWS 이외에 사용자 정의 예외(Custom Exception)를 선언·발생시키고, SAVEPOINT/ROLLBACK TO SAVEPOINT을 활용해 트랜잭션 오류 복구 로직을 구현한 경험 · 예시: ""잔액 업데이트 중 음수 잔액 발생 시 ROLLBACK TO SAVEPOINT로 복구 후 별도 처리"" 같은 시나리오 설계 및 구현 경험• PL/SQL 성능 최적화 및 코드 품질 관리 · EXPLAIN PLAN 분석 실행 계획에 따른 인덱스 재설계(Clustered/Non-Clustered), 파티셔닝(Partitioning) 또는 힌트(HINT) 적용을 통해 쿼리 성능을 개선한 경험 · PL/SQL 코드 가독성을 위해 적절한 모듈화, 주석, 네이밍 컨벤션을 준수하며, 주기적으로 코드 리뷰·리팩토링을 수행한 경험 · 예시: ""월별 1억 건 이상 로그 테이블에 대해 인덱스/파티셔닝 전략을 적용해 쿼리 응답 시간을 5초 500ms로 줄인 경험""• 테스트 및 디버깅 스킬 · PL/SQL 단위 테스트(Unit Test) 작성 또는 DBMS_OUTPUT.PUT_LINE을 활용한 로직 검증 경험 · SQL Developer, TOAD, PL/SQL Developer 등의 도구로 복잡한 스택 추적(Trace) 및 디버깅을 수행한 경험.","• 의료정보 시스템 관련 업무 유경험자(HIS, EMR, CDW 등)• ETL/ELT 개발 경험 · Pentaho, Informatica, Talend, SSIS 등의 ETL 도구와 연계하여 PL/SQL 기반 데이터 파이프라인을 구현한 경험• 데이터 모델링 툴 활용 경험 · PowerDesigner, Erwin 등으로 논리/물리 모델을 설계하고, 해당 모델을 바탕으로 PL/SQL 코드 작성 경험."
오케스트로,"• 최신 LLM(Llama, Mistral 등)의 성능 벤치마킹 및 솔루션 적합성 검증• 특정 도메인에 맞는 LLM 파인튜닝(Fine-tuning) 및 경량화 기술 연구/적용• vLLM, TensorRT-LLM 등 LLM 서빙 프레임워크를 활용한 추론 최적화• Kubeflow, MLflow 등을 활용한 MLOps 파이프라인 설계 및 구축• 분산 학습(DeepSpeed, FSDP) 환경 구축 및 학습 프로세스 자동화.",• 3년 이상의 ML 모델 개발 또는 MLOps 관련 업무 경험• Python 및 PyTorch/TensorFlow 등 딥러닝 프레임워크에 대한 높은 숙련도• LLM의 구조 및 동작 원리에 대한 깊은 이해• Kubernetes 및 Docker 환경에서의 개발 경험.,• LLM 파인튜닝 또는 서빙 최적화 관련 프로젝트 경험• 대규모 GPU 클러스터 환경에서의 분산 학습 경험• NLP 관련 논문 구현 및 최신 연구 동향에 대한 높은 이해도• 오픈소스 MLOps 도구 기여 또는 관련 커뮤니티 활동 경험.
티맵모빌리티,"[데이터 플랫폼 아키텍처 설계 및 고도화]• 데이터 플랫폼 전반에 대한 이해를 바탕으로 아키텍처를 설계하고, 안정적이며 확장 가능한 플랫폼을 고도화합니다.• 데이터 기반 의사결정을 위한 기술적 기반을 마련하고 서비스 성장을 주도할 수 있는 솔루션을 설계합니다.[클라우드 기반 데이터 인프라 구축 (AWS)]• AWS의 EMR, EKS 등 클라우드 서비스를 활용하여 데이터 인프라를 구축하고 자동화합니다.[데이터 거버넌스 설계 및 운영]• 데이터 보안 및 정책 준수를 위한 거버넌스 체계를 설계하고 구축합니다.• 접근 제어 및 감사 기능을 구현하여 데이터의 안전성과 신뢰성을 확보합니다.[모니터링 및 시스템 운영]• 플랫폼 및 데이터 파이프라인을 지속적으로 모니터링하고 장애 및 성능 이슈를 해결합니다.• 필요에 따라 시스템을 개선하거나 확장합니다.[팀 리딩 및 기술 방향성 제시]• 데이터 엔지니어링 팀을 리드하며 기술적 방향성을 제시하고, 팀원의 성장업무 수행을 지원합니다.",• 소프트웨어 엔지니어링 경력 10년 이상이거나 이에 준하는 경험을 보유하신 분• 데이터 엔지니어링 및 팀 매니징 경험이 있으신 분• 여러 유관 부서와의 협업을 통해 팀 프로젝트를 성공적으로 이끈 경험이 있으신 분• 뛰어난 문제 해결 능력을 보유하신 분.,"• 기술 로드맵 수립 및 데이터 모델링 프로젝트 리딩 경험을 보유하신 분• 클라우드 환경(AWS 등)에서의 프로젝트 수행 경험을 보유하신 분• 고품질 코드 작성 역량, 원활한 협업 및 커뮤니케이션 능력을 갖추신 분."
커넥트웨이브,"커넥트 웨이브 그룹사 전사의 데이터를 모으고 정제하고 서빙합니다.• 그룹사 전체의 DB(상품, 컨텐츠, 로그 등)를 하나의 DataLake로 모으기 위한 CDC 파이프라인 개발• 분산 DB 기반의 어플리케이션 개발 및 실시간 스트리밍 처리(Kafka)를 사용한 어플리케이션 개발• 빅 데이터 플랫폼 운영 및 수집 분석 시스템 개발.","• 신기술 센싱과 분석을 즐기시는 분 • 코드리뷰 등을 통해 주변 동료들에게 자극을 주는 분• docker 및 kubernetes 이해 및 경험• hadoop및 hadoop eco system 이해• spark / spark streaming 개발 역량 보유• kafka 클러스터에 대한 이해 및 활용, 개발 역량 보유• NoSQL 및 분산 Database에 대한 이해 및 서비스 경험.",• CDC 구축 경험• DataLake 구축 경험• Business Intelligence (BI) 구축 경험.
웰로,"• 웰로 개발팀 소속으로 데이터실과 사업실의 요구사항을 기반, 웰로의 정책 데이터셋을 고도화하고 RAG 기반 LLM 고도화를 위한 기초 데이터를 고도화 하는 업무를 담당하실 예정입니다.• FASTAPI 기반 스크래핑 시스템의 아키텍처를 설계하고 고도화 합니다.• 대규모 웹 데이터를 안정적으로 수집할 수 있는 크롤링 시스템을 설계하고 개발합니다.",• 전체 개발 경력 중 최소 2년 이상 스크래핑 또는 크롤링 시스템 개발 경력 보유 (신입 지원 불가)• Python 기반 웹 크롤링 및 스크래핑 개발 경험과 Javascript 개발 경험 보유• SQL을 활용한 간단한 데이터 전처리 경험• Gitflow 기반 협업 경험• 이상 위의 자격요건에 대해 제출 이력서 또는 포트폴리오를 통해 확인이 가능해야 합니다.• 해외여행에 결격사유가 없는 분.,"• 리버스 엔지니어링을 통한 보안 프로그램 분석 경험 (CAPCHA 자동화 처리 및 키보드 보안 솔루션 분석 경험)• 세션유지 및 차단 방지기술에 대한 이해 (IP차단 및 탐지 우회 및 비정상 접속 탐지 대응)• 공공서비스(인터넷등기소, 정부24 등)의 스크래핑 경험• User-agent 위장, 캡차 우회, 프록시 서버 등 실전 크롤링 방어 대응 경험• 데이터 수집 자동화 (cron, Airflow 등) 및 데이터베이스 연동 경험."
현대캐피탈,"표준화된 데이터베이스 관리 및 운영 프로세스를 구축하고 수행할 수 있는 DBA• 당사 데이터베이스 아키텍처 설계, 운영 표준을 수립하고 전반적인 관리 및 운영을 수행• 성능 최적화 및 문제 해결을 통해 안정적인 데이터 환경을 조성• 장기적인 데이터베이스 구축 / 운영 전략을 주도하여 당사 데이터 인프라를 지속적으로 발전시킬 전문가• 데이터베이스 표준 및 관리 프로세스 수립• 데이터베이스 설계, 구축 및 운영 (유지관리, 성능모니터링, 장애 대응 등)• 데이터베이스 성능 최적화 및 문제 해결• 데이터베이스 운영 자동화 및 관리 프로세스 최적화.","• RDBMS (Oracle, PostgreSQL EDB, MySQL) 및 NoSQL (MongoDB, Redis) 설계 및 구축 역량 필수• 데이터베이스 성능 모니터링, 장애 분석 및 로그 기반 문제 해결 역량 필수• SQL 실행 계획 분석, 인덱스/샤딩/캐싱 등 최적화 전략을 통한 성능 튜닝 역량 필수• Public(AWS, GCP, Azure) / Private 클라우드 환경에서의 데이터베이스 구축 및 운영 경험• 학사 이상.",• 적극적인 커뮤니케이션 및 비즈니스 영어 회화 역량 우대.
핵클(Hackle),"• 핵클 SDK에서 수집되고 처리되는 데이터의 안정적인 처리를 위한 데이터 파이프라인을 설계하고, 개발, 운영합니다.• 대용량 데이터를 실시간으로 분산처리하기 위한 데이터 파이프라인을 개발, 운영하여 핵클 플랫폼 서비스에 기여합니다.• 데이터 플랫폼 고도화를 위한 새로운 기술을 리서치하고, 도입합니다.","• 데이터 어플리케이션 개발을 위한 개발 역량을 갖추신 분 (Kotlin, Java, Python, Go, Scala중 한가지 이상)• Spark, Flink, Kafka, Airflow, Trino 등을 활용한 데이터 파이프라인 개발 경험• MSA 환경에서 대용량 데이터 처리(1억건/Daily 이상) 및 준 실시간 데이터 처리 경험• Kubernetes 환경에서 데이터 파이프라인 구축 및 운영 경험• Iceberg 또는 Hudi 를 활용한 데이터 마트 구축 및 운영 경험.","• Hadoop / Spark 등을 통한 ETL 데이터 레이크 운용 및 엔지니어링 경험• Kubernetes 구축/운영 경험• Cloud 환경에서의 업무 경험• 준 실시간 성 데이터를 Low Latency 로 제공하기 위한 솔루션을 적용해본 경험• 데이터 엔지니어링을 활용해 외부 고객에게 솔루션을 제공해본 경험[핵클이 사용하는 기술]• AWS Kinesis, AWS Glue, AWS Lamda, AWS S3, AWS EKS, AWS DynamoDB etc• Kubernetes• Apache Spark• Flink• Presto/Trino• Airflow• Iceberg• Terraform• Prometheus."
텔레픽스,"ㆍ이미지/영상 기반 AI 모델 설계 및 개발 (Detection, Segmentation, Pose Estimation, Image Restoration 등)ㆍ 최신 컴퓨터 비전 및 멀티모달 AI 논문 조사 및 실험 수행 (SAM, DINO, LLaVA, I-JEPA 등)ㆍ모델 성능 평가 및 실험 설계 주도ㆍ연구 결과를 논문, 특허, 오픈소스 등의 형태로 확장.","ㆍ컴퓨터 비전 분야 딥러닝 모델 연구개발 경험 (3년 이상 또는 그에 준하는 역량)ㆍTop-tier 학회(CVPR, ICCV, ECCV, NeurIPS 등) 논문 구현/응용 경험 또는 이에 준하는 논문 독해 능력ㆍPyTorch 기반 연구 환경에 능숙하며, 논문 reproduction 및 baseline 구현 역량ㆍ복잡한 데이터셋 기반 실험 설계 및 성능 분석 역량.","ㆍTransformer 기반 비전 모델 경험 (ViT, DINO, SAM, DETR 등)ㆍ멀티모달 데이터 학습 경험 (Vision-Language, EO-SAR Fusion 등)ㆍRemote Sensing, 위성/항공 영상 분석 경험ㆍ논문 저자 경험 또는 국제 학회 발표 경험ㆍ서비스 배포를 위한 모델 경량화 및 최적화 경험ㆍ오픈소스 프로젝트 참여 경험."
원티드랩,"• 비즈니스/제품/데이터 조직의 요구사항을 반영한 인프라(데이터 흐름 및 파이프라인) 설계, 개발 및 운영 자동화• 데이터팀 내외 협업 및 데이터 파이프라인 테스트, 배포 프로세스 자동화• 여러 서드 파티 API, 오픈소스를 사용한 데이터 통합• BigQuery 웨어하우스의 거버넌스 및 리니지 시스템 운영• Kafka를 활용한 유저 행동 이벤트 처리 플랫폼 개발 및 운영• Kafka를 활용한 Change Data Capture 개발 및 운영• 데이터 이상 감지 시스템 구축 및 운영.","• Python 3.11 이상 능숙• 데이터 엔지니어 경력 3년 이상• 일시적인 해결이 아니라 근본적인 문제 해결을 고민하는 분• 이슈 및 버전 관리를 중시하는 분• 능동적인 커뮤니케이션을 하시는 분• BigQuery, Redshift, Snowflake 등의 data warehouse platform 운영 경험이 있으신 분• Kafka 운영/Producer, Consumer 개발 경험이 있으신 분• Airflow 구축 및 DAG 운영/개발 경험이 있으신 분• 오픈 소스 사용 및 문제 해결 경험이 있으신 분• 다양한 도메인 담당자와 복잡한 문제를 커뮤니케이션 하시는 분.",• 데이터 거버넌스 관리 경험이 있으신 분• 서버 개발 경험이 있으신 분• MLOps 프로세스를 경험이 있으신 분• 애자일 프로세스 경험이 있으신 분• 멀티 클라우드 및 교차 계정 경험이 있으신 분• 봇 개발 등 AI를 활용한 생산성 개선 경험이 있으신 분.
크레이버코퍼레이션,"• 내,외부 데이터 수집 및 크롤링을 통한 전략적 데이터 분석 및 마켓 리서치• AARRR 프레임워크 기반 유저 행동 분석 및 전환, 유지 전략 수립• 주요 지표 분석을 통한 데이터 기반 의사결정 지원• SEO 성과 분석 및 개선안 도출.","• 데이터 분석 및 전략 기획 경력 3년 이상• ROAS, CAC 등 주요 지표 간의 관계를 이해하고 분석할 수 있는 능력• 세일즈 지표 기반 문제 진단 및 개선 방안 도출 능력• 애널리틱스 툴 활용 겅험이 있는 분 (GA4, Amplitude, Mixpanel 등)• 마케팅 및 비즈니스 퍼포먼스 분석 경험• 다양한 부서와의 원활한 커뮤니케이션 및 협업 역량.","• B2B 플랫폼 또는 소비재 산업에 대한 이해도를 갖추신 분• K-Beauty, 화장품, 유통 관련 산업 경험을 보유하신 분• 글로벌 시장/트렌드 분석 경험을 보유하신 분• 복잡한 데이터 환경에서의 전략 수립 경험을 보유하신 분."
퓨쳐스콜레,"합류하시면 이런 일을 해요! (What You'll Do)• AWS 및 GCP 클라우드 기반의 데이터 인프라 설계 및 운영• 다양한 데이터 소스에서의 수집, 처리, 적재 자동화• 데이터 시각화를 위한 도구 활용• 데이터 카탈로그 및 품질 관리 체계 구축• REST API 기반 데이터 서비스 개발.","이런 분을 모시고 싶어요.• AWS 또는 GCP 등 클라우드 환경 경험• ETL/ELT 파이프라인 개발 및 운영 경험• 데이터 모델링에 대한 기본적인 이해• 데이터 시각화 도구 활용 경험• Python, JAVA 등 하나 이상의 프로그래밍 언어에 능숙해야 해요.• Airflow 등 워크플로우 오케스트레이션 도구 사용 경험.","이런 분이면 더할 나위 없어요! (Preferred Qualifications)[스킬]• CDC(Change Data Capture) 구현 경험• 대규모 로그 및 실시간 데이터 처리 경험• 데이터 품질 관리 및 메타데이터 체계 구축 경험• 사용자 행동 데이터, 학습 분석 경험• 데이터 접근 권한 관리 체계 구축[컬처핏]이런 분이면 정말 좋아요!• 데이터 품질의 중요성을 이해하고 꼼꼼하게 일하시는 분• 새로운 기술 습득에 적극적이신 분• 비즈니스 임팩트를 고려하여 우선순위를 정할 수 있는 분• 문서화와 지식 공유를 중요하게 생각하시는 분• 유관 부서와의 커뮤니케이션 능력이 원활하신 분."
업스테이지,"• 데이터 수집 파이프라인 설계 및 구축 - 멀티모달 데이터(문서 이미지, 현장 사진, 차트 등)의 수집 및 필터링을 포함한 데이터 수집 파이프라인 설계 및 구축 - 데이터 품질 향상을 위한 전처리 및 개선 기법의 연구·적용 - 데이터팀과의 협업을 위한 Human-in-the-loop 기반 어노테이션 워크플로우 설계 및 운영• 모델 학습 - 대규모 Multi-modal representation learning 및 Cross-modal pretraining 기법의 연구 및 적용 - 다양한 질의응답 태스크에 대응하기 위한 Instruction tuning 전략 개발 - 학습과 추론 효율을 고려한 모델 구조 개선 및 최적화 기법 연구• 평가 - 문서 중심 VLM 모델의 성능을 평가하기 위한 다양한 평가 기법 조사 및 적용 - 실제 사용 환경에 부합하는 새로운 평가 방법의 개발 및 도입 - 지속적인 개선과 확장이 가능한 내부 벤치마크 도구의 설계 및 구현• 그 외 - 연구 결과를 탑티어 국제 학회 논문 또는 오픈소스 코드 형태로 공유 - 최신 논문 재현 및 기법 도입을 위한 선행 연구 주도 및 팀 내 기술 공유 - 제품팀, MLOps팀 등과의 긴밀한 협업을 통한 모델의 실서비스 적용 및 시스템 통합.","• 관련 분야 석사 혹은 박사 학위• AI 문제를 정의하고 해결하는 능력• 기초 머신러닝 알고리즘에 대한 깊은 이해• Python, C++ 등의 언어를 활용한 강력한 프로그래밍 능력 및 Linux/Shell 활용 능력• 컴퓨터 비전(CV), 자연어처리(NLP), 멀티모달 학습 최신 알고리즘 이해• 주요 기계 학습 프레임워크에 대한 깊은 이해(예: TensorFlow, PyTorch)• 다양한 협업 환경에서 일할 수 있는 능력• 훌륭한 의사 소통 능력.","• Vision–Language Model 관련 연구 및 논문(e.g. CVPR, ICCV, ACL, EMNLP) 게재 경험• 국제 혹은 국내 AI 대회(Kaggle 등) 상위권 입상• 새로운 연구 혹은 개발 방향성을 제시할 수 있는 능력• 멀티모달 VLM 최적화 및 도메인 적응(fine-tuning) 경험."
오토메타,"• 스마트오더 (오더홉) 시스템 개발 및 유지 보수• 기업형 이커머스 솔루션 시스템 개발 및 유지 보수• Zenith Ai 신제품 개발 (Data Science, Model Pipeline 구축)• 데이터베이스 모델링 및 ETL 아키텍처 설계 및 구현• Cloud Native 환경에서 대용량 병렬 처리와 동시성 문제 해결• 클라우드 인프라 유지 보수 및 개선 작업.","• Python, Javascript, Elixir 중 최소 한 언어에 대한 깊은 이해• 웹 서버 framework 2년 이상 실무 경력 (django, fastapi, Nest.js, phoenix)• React.js 기반 웹 framework 2년 이상 실무 경험 • 웹 기반 통신에 대한 깊은 이해 (RESTful, Websocket 등)• Figma 등의 디자인 협업 툴 사용을 통한 기획자/디자이너와 협업 경험• HTML & CSS 3년 이상 실무 적용• RDBMS DB 설계 및 SQL 개발 역량.","• 주문, 정산, 상품, 결제 솔루션: DB 설계 및 로직 개발 경험이 있는 분• AI model, ML model, Big Data processing 중 하나 이상의 전문적인 경험• Flutter / React Native 사용 경험 있으신분• 하나 이상의 HTML 템플릿 엔진 사용 경험• Tailwind CSS 경험• 디자인 토큰, 컴포넌트화를 통한 디자인 시스템 자동화 경험• xState 등의 완전 상태 머신을 제품에 적용해 본 경험• Playwright, Selenium 등을 이용한 웹 테스팅 자동화 경험• AWS, Azure, GCP, Cloudflare 등 클라우드 상에서 인프라 구성 및 제품 개발 경험• GitHub Actions, Azure DevOps, AWS CodePipeline, Jenkins 등을 이용한 DevOps 경험• 코드 리뷰가 두렵지 않으신 분• TDD를 위해 노력하시는 분• Network (http, TCP/IP 등) 지식이 풍부 하신 분."
한국딥러닝,"• 최신 Vision/LLM/RAG 연구 동향 파악 후 Custom Backbone/Head 및 Retrieval 파이프라인 설계·검증(PoC)• 이미지·자연어 등 비정형 대규모 데이터의 전처리 및 Vector Embedding·Indexing·Reranking을 포함한 RAG 파이프라인과 딥러닝 모델 아키텍처 구축• 모델 개발 과정에서 발생하는 성능 이슈를 분석·디버깅하고, 지표 기반 알고리즘·하이퍼파라미터 개선• 제품 연동을 위한 모듈형 API 및 Demo 제공, 고객사 요구사항 반영 기능 고도화.","• AI(Vision/LLM/RAG) 분야 3년 이상 실무 경험 (모델 연구·개발·배포 등)• 자료구조·알고리즘·선형대수·통계 등 컴퓨터공학 기초에 대한 탄탄한 이해• PyTorch 등 딥러닝 프레임워크 활용 및 모델 구현·디버깅 능력• Vision AI 모델 혹은 RAG(Vector DB, Embedding, Reranking)를 활용한 대규모 데이터 기반 모델링 경험.","• 논문·특허 성과 혹은 오픈소스 기여 경험• Latency·메모리 최적화를 위한 ONNX·TensorRT·Quantization·vllm 적용 경험• Vector DB(Faiss, Milvus, Weaviate 등) 기반 RAG 시스템 구축 경험• 모델 경량화(Quantization, Pruning 등) 및 Inference Optimization 경험• Git, Notion, Jira, DVC 등 협업 툴 활용 및 프로세스 관리 능력."
인포유앤컴퍼니,• 대용량의 데이터를 데이터 성격에 맞게 분석/설계• 효과적인 DataMart를 설계/구축• 쿼리 분석 및 개발• 고객사 상주 운영 업무 또는 프로젝트 수행.,• 마트 설계 업무 3년 이상의 경력 보유자• SQL 툴 1개 이상으로 2년 이상 업무 경험이 있으신 분.,• 클라우드 기반의 데이터 플랫폼 구축 및 운영 경험이 있으신 분• 데이터 수집(ETL) 구축 및 운영 업무 경험이 있으신 분• ERP System 개발/운용 경험이 있으신 분.
이노케어플러스,ㆍ AWS Glue를 활용한 대용량 ETL/ELT 파이프라인 설계 및 개발ㆍ AWS Data Catalog 기반 메타데이터 관리 및 데이터 거버넌스 구축ㆍ Amazon Athena를 통한 서버리스 쿼리 환경 구축 및 최적화ㆍ S3 기반 데이터 레이크 아키텍처 설계 및 데이터 파티셔닝 전략 수립ㆍ Python을 활용한 데이터 처리 로직 구현 및 성능 최적화ㆍ 규모 추정 알고리즘 설계 및 구현ㆍ 데이터 검증 및 이상치 탐지 알고리즘 개발ㆍ BI 도구와의 연동을 위한 데이터 마트 구축 및 API 개발ㆍ실시간 스트리밍 데이터 파이프라인 구축 및 운영ㆍ데이터 품질 모니터링 시스템 구축 및 이상 탐지 알고리즘 구현ㆍ데이터 파이프라인 성능 튜닝 및 비용 최적화[개발 문화]ㆍ데이터 중심의 의사결정 문화ㆍ지속적인 기술 공유 및 학습 지원ㆍ자율적이고 책임감 있는 업무 환경.,"ㆍ데이터 엔지니어링 관련 5년 이상의 실무 경험ㆍPython 활용 능력 (pandas, numpy, boto3, pyspark 등)ㆍAWS 데이터 서비스 (Glue, S3, Athena, Data Catalog) 운영 경험 3년 이상ㆍSQL 고급 활용 및 복잡한 쿼리 최적화 능력ㆍETL/ELT 프로세스 설계 및 대용량 데이터 처리 경험ㆍ데이터 웨어하우스 및 데이터 레이크 아키텍처 설계 경험ㆍ통계적 분석 및 알고리즘 구현 경험 (규모 추정, 이상치 탐지 등)ㆍ모델링 및 비즈니스 로직 구현 능력ㆍ리눅스 환경에서의 개발 및 운영 경험ㆍGit을 활용한 협업 및 코드 관리 경험[필요 역량]ㆍ대용량 데이터 처리 및 성능 최적화에 대한 깊은 이해ㆍ복잡한 비즈니스 요구사항을 데이터 파이프라인으로 구현하는 능력ㆍ데이터 품질과 신뢰성에 대한 높은 기준과 책임감ㆍ클라우드 네이티브 아키텍처 설계 및 구현 능력ㆍ팀 리딩 및 주니어 개발자 멘토링 능력ㆍ새로운 기술 트렌드 파악 및 빠른 학습 능력ㆍ다양한 이해 관계자와의 원활한 커뮤니케이션 능력[기술 스택]ㆍ언어 : Python, SQL, Scala(우대), R(통계분석용 우대)ㆍAWS 서비스 : Glue, S3, Athena, Data Catalog, Redshift, Kinesis, Lambda, Step Functionsㆍ빅데이터 처리 : Apache Spark, PySpark, Pandasㆍ스트리밍 : Apache Kafka, Amazon Kinesisㆍ워크플로우 : Apache Airflow, AWS Step Functionsㆍ데이터베이스 : Amazon Redshift, RDS(PostgreSQL, MySQL), DynamoDBㆍBI 도구 : Tableau, Power BI, QuickSight, Lookerㆍ알고리즘/분석 : scikit-learn, numpy, scipy, statsmodelsㆍ인프라 : Docker, Kubernetes, Terraformㆍ모니터링 : CloudWatch, Grafana, DataDogㆍ버전 관리 : Git, GitHub/GitLabㆍ테이블 포맷 : Delta Lake, Apache Iceberg(우대)ㆍ데이터 변환 : dbt(data build tool).","ㆍAWS 자격증 (Data Engineer Associate/Professional, Solutions Architect 등)ㆍApache Spark/PySpark를 활용한 대용량 데이터 처리 경험ㆍApache Kafka, Amazon Kinesis 등 스트리밍 데이터 처리 경험ㆍTerraform, CloudFormation 등 IaC 도구 활용 경험ㆍApache Airflow, AWS Step Functions 등 워크플로우 도구 운영 경험ㆍRedshift, RDS, DynamoDB 등 AWS 데이터베이스 서비스 경험ㆍDocker, Kubernetes 컨테이너 기술 활용 경험ㆍdbt(data build tool)를 활용한 데이터 변환 경험ㆍScala, Java 등 추가 프로그래밍 언어 능력ㆍDelta Lake, Apache Iceberg 등 테이블 포맷 기술 경험ㆍ 데이터 거버넌스 및 데이터 보안 구현 경험ㆍ 머신러닝/딥러닝을 활용한 예측 모델링 경험."
하이퍼리즘,"하이퍼리즘 금융 플랫폼 엔지니어는 가상 자산 관리에 특화된 사내 플랫폼을 개발하고 운영합니다.• 수천 개의 가상자산 및 파생상품 포지션을 추적하고 데이터베이스화• 금융 트랜잭션을 실시간으로 처리하고 정확하게 저장할 수 있는 시스템 설계• 어드민 페이지의 UI 설계 및 구현• 비즈니스 로직(출자, 환매, 대출 등)을 모델링하고 소프트웨어 모듈로 구현• 다양한 사내 금융 오퍼레이션을 탐색하여 자동화하고 서비스화/모듈화.","기술 스택• Python: 인하우스 시스템 및 각종 스크립트• Git, Kubernetes, AWS, Datadog, NoSQL, PostgreSQL, Streamlit이런 엔지니어를 환영합니다• 소프트웨어 개발 경력 7년 이상• 단순 스크립트가 아닌 제품 개발에 Python을 사용한 경험이 있는 분• RDBMS 사용에 대한 깊은 이해가 있는 분• 프론트엔드 또는 UI 엔지니어링 경험이 있는 분• 오퍼레이션 자동화를 위한 사내 어드민 툴 개발 및 운영 경험이 있는 분• 비즈니스 로직을 정확하게 프로그래밍하고 철저하게 QA 할 수 있는 분• 사용자 요구사항을 체계적으로 정리하고 효율적인 해결 방법을 기민하게 모델링 할 수 있는 분• 정확한 커뮤니케이션 능력과 높은 업무 스탠다드로 꼼꼼한 일 처리를 하는 분• 문제를 찾아내고 분석하는 비판적 사고 능력을 가진 분.","이런 엔지니어를 더 환영합니다• 프로덕션 환경에서 Rust 사용 경험이 있는 분• 암호화폐 생태계에 대한 깊은 이해가 있는 분• 금융 관련 시스템 또는 서비스 개발/운영 경험이 있는 분• 금융, 회계, 트레이딩 관련 경험 또는 지식이 있는 분• Streamlit 프레임워크에 익숙한 분• 풀스택 엔지니어링이 가능한 분."
미트박스글로벌,• SCM 시스템 구조 설계 및 구현• API 상세 설계 및 성능 최적화• 클라우드 기반 서비스 운영 및 개선• 시스템 성능·안정성 개선 및 유지보수.,"• 소프트웨어 개발 경력 10년 이상• 시스템 요구사항 분석 및 설계 경험• Java, Spring Boot, Vue.js 개발 경험• Kafka, Redis 등 활용한 대용량 데이터 처리 경험• 물류 및 커머스 도메인 전문성.","• 대규모 물류 시스템(WMS, OMS, TMS 등) 개발 경험• 클라우드 환경(AWS, GCP, Azure 등) 서비스 운영 경험• 아키텍처 개선 및 신규 기술 도입 경험• 물류·유통·이커머스 업계 시스템 개발 경험• 조직 내 원활한 커뮤니케이션 및 협업 경험."
넥스트증권,"- 대용량 ​정형/비정형 ​거래 데이터, 시세 ​데이터, 고객 ​행동 데이터 등을 효율적으로 처리하고 분석하기 위한 데이터 웨어하우스(Data Warehouse) 및 데이터 레이크(Data Lake) 아키텍처를 설계하고 구축합니다.- 온프레미스(On-premise) 환경과 퍼블릭 클라우드(AWS, GCP 등) 환경을 연동하는 하이브리드 클라우드 데이터 인프라를 설계, 구축하고 안정적으로 운영합니다.- 실시간 및 배치 데이터 처리를 위한 확장성 높은 데이터 파이프라인을 개발하고, 성능 병목 구간을 분석하여 지속적으로 최적화합니다.- IaC(Infrastructure as Code) 기반으로 인프라 구성 및 관리를 자동화하고, 데이터 플랫폼의 상태와 성능을 실시간으로 모니터링하는 시스템을 구축하여 장애를 사전에 예방하고 신속하게 대응합니다.- 데이터 품질, 데이터 수명 주기 관리 등 데이터 거버넌스 정책을 기술적으로 구현하고, 금융 규제 준수를 위한 강력한 데이터 보안 아키텍처를 적용합니다.- 데이터 분석가, AI/ML 엔지니어, 프로덕트 엔지니어와 긴밀하게 협업하여 데이터 요구사항을 파악하고, 이를 만족하는 최적의 기술 솔루션을 제공합니다.","- 5년 이상의 데이터 엔지니어 경력- Python 또는 Java 등 하나 이상의 프로그래밍 언어에 능숙하신 분- SQL 활용 능력이 뛰어나고 데이터 모델링에 대한 깊은 이해를 갖추신 분- 하이브리드 클라우드 아키텍처 환경에서 데이터 파이프라인 구축 및 운영 경험이 있으신 분- Apache Airflow 등을 활용한 워크플로우 자동화 경험이 있으신 분- Apache Kafka, Apache Flink 등 실시간 스트리밍 데이터 처리 기술 경험이 있으신 분- 대용량 데이터 처리 프레임워크(Apache Spark, Hadoop 등) 사용 경험이 있으신 분- RDBMS(Oracle, PostgreSQL 등) 및 NoSQL DB에 대한 이해와 운영 경험이 있으신 분.","- 증권, 은행, 카드사 등 금융 도메인에서 데이터 플랫폼 구축/운영 경험이 있으신 분- 데이터 웨어하우스(Snowflake, BigQuery, Redshift 등) 설계 및 마이그레이션 경험이 있으신 분- Docker, Kubernetes 등 컨테이너 기반 기술 활용 및 MSA 환경에 대한 이해가 높으신 분- Terraform, Ansible 등 IaC(Infrastructure as Code) 도구를 활용한 인프라 자동화 경험이 있으신 분- 데이터베이스 성능 튜닝 및 대규모 분산 시스템 트러블슈팅 경험이 있으신 분- 데이터 카탈로그, 데이터 리니지, 데이터 품질 관리 시스템 구축 경험이 있으신 분- CI/CD 파이프라인 구축 및 DevOps 문화에 대한 이해가 높으신 분."
레브잇,"• AWS EKS 환경에서 오픈소스 기반으로 데이터 플랫폼 구축 및 운영합니다.• 데이터 분석, 머신러닝, 데이터 프로덕트 개발을 위한 실시간/배치 데이터 파이프라인을 개발합니다.• 전사 데이터 플랫폼을 구축하고 데이터 품질, 디스커버리 등 전사 데이터를 운영하고 관리합니다.","• 대용량 데이터 파이프라인의 구축, 개발 경험이 있으신 분이 필요합니다.• 빅데이터 프레임워크 (Hadoop, Kafka, Spark, Flink 등)의 활용 경험이 있으신 분이 필요합니다.• 워크플로우 (airflow, luigi 등)의 구축, 개발 경험이 있으신 분이 필요합니다.[기술 스택]• Data Processing & Transformation : Spark, Kafka, Flink...• Data Storage : S3, Iceberg, Kafka, Schema Registry, Elasticsearch, MongoDB• Interactive Query Service : Athena, Presto• Orchestration : Airflow• Data Governance : AWS Lake Formation• Data Visualisation : Kibana, Redash, Superset• DataWarehouse• AI 개발 툴 : Claude Code, Cursor, Copilot, ChatGPT 등.","• 데이터 분석 플랫폼 구축 및 운영 경험이 있으신 분을 선호합니다.• Capture Data Change (debezium 등)의 파이프라인 구축, 개발 경험이 있으신 분을 선호합니다.• AWS 기반의 인프라 (EMR, EKS, athena, 등) 구축, 개발 경험이 있으신 분을 선호합니다.• 로그 설계부터 수집까지 자동화 경험이 있으신 분을 선호합니다.• CI / CD 개발 경험이 있으신 분을 선호합니다.• OLAP 시스템 구축, 사용 경험이 있으신 분을 선호합니다."
쿠팡,• 기존 데이터 파이프라인을 관리 및 유지하여 작업 일관성과 데이터 무결성 확보• 데이터 품질을 최고 수준으로 유지• 다양한 작업에 데이터를 제공하기 위해 새로운 파이프라인 생성 또는 기존 파이프라인 수정• 실시간 데이터 생산 및 소비가 가능한 새로운 데이터 흐름 프레임워크 설계 및 구축• 다양한 이해관계자와 협의하여 원시 데이터 교환 방식 개선.,"• 컴퓨터공학 또는 관련 기술 분야의 학사 또는 석사 학위• 알고리즘, 자료구조, 디자인 패턴, 데이터 파이프라인 및 데이터 웨어하우징에 대한 깊은 이해를 바탕으로 한 8년 이상의 소프트웨어 개발 경험• Java, Scala, Python 등 하나 이상의 프로그래밍 언어에 대한 실무 경험• 외부 데이터를 수집 및 변환하여 리포팅에 활용할 수 있는 API 서비스 설정 경험• Spark 및 Hive를 활용한 분산 처리에 대한 강력한 실무 경험• AWS 클라우드 컴퓨팅 플랫폼에 대한 실무 경험 및 확장성과 신뢰성에 대한 이해• 내부/외부 부서와의 능동적인 커뮤니케이션 능력 및 문제 해결 태도.","• Kafka, Redis, Hive/Spark on Hadoop 등 대규모 분산 인프라를 활용한 데이터 처리 경험• 머신러닝 도메인에 대한 이해 및 관련 팀과의 협업 경험."
빅밸류,• 데이터 파이프라인 설계/구축/운영• DL/DW/DM 구축/운영• AI 및 자동화 기술을 활용한 업무 효율화• 최신 데이터 처리기술 연구 및 도입• 데이터 처리 및 제어 SW 개발.,"• 경력: 3년 이상• 공간 데이터, 빅데이터, 인공지능 기술 전반에 대해 관심이 있는 분• 해외 출장에 결격사유가 없는 분※ 전문연구요원 지원 가능.","• 데이터 파이프라인 구축 경험자• 컴퓨터공학, 산업공학, 데이터사이언스, 소프트웨어 아키텍처, 데이터 아키텍처 석사 이상 전공자• 통계학 및 데이터 분석 관련 지식 보유자• 다양한 직군의 이해관계자들과 효과적으로 소통하고 협업할 수 있는 커뮤니케이션 능력이 있는 분기술 스택• Postgresql, Airflow, Grafana, Python, DSL."
데브시스터즈(Devsisters),"• 다양한 게임의 출시와 운영에 맞출 수 있도록, 높은 확장성을 가지는 데이터 플랫폼을 목표로 하고 있습니다.• 최근 5년간 99.999% 이상의 높은 가용률을 유지하고 있는 Kafka 클러스터 운영을 통해 유지되는 신뢰를 기반으로, 중앙화된 로깅 인프라 서비스를 운영합니다.• 누구나 필요할 때, 수십 TB의 메모리, 수천 코어의 CPU, 수백 대의 노드가 필요한 대용량 분석 작업도 쉽게 할 수 있는 환경을 제공합니다.• 로그 스키마 관리 및 스키마 기반 적재의 자동화를 통해서 여러 서비스를 아우를 수 있는, 좋은 퀄리티의 데이터를 수집할 수 있는 환경을 운영하고 있습니다.• 특정 조직에 국한되지 않고, 데브시스터즈의 구성원이 활용할 수 있는 다양한 데이터엔지니어링 솔루션을 제공합니다.","현재 팀에서 사용하는 기술 스택에 대한 경험이나 관심이 가지고 있으며, 팀에 합류하시고 나서 짧은 시간 내에 실질적인 기여가 가능하고, 기존 팀에서 보지 못했던 새로운 시각을 제공하실 수 있는 분을 찾고 있습니다.• 컴퓨터과학 분야 학부 졸업자 혹은 이에 준하는 전공지식을 갖춘 분• 1개 이상의 프로그래밍 언어를 능숙하게 활용할 수 있는 프로그래밍 역량을 보유한 분 (데이터 처리, 요구사항에 맞는 올바른 로직 구현, 효율적인 아키텍처 설계 등)• 팀에서 사용하는 기술에 대한 광범위한 경험, 혹은 그 중 일부 기술에 대한 깊은 이해를 가진 분• 자신이 하는 일에 대한 책임감을 가지고, 문제 해결을 중심으로 역할을 확장해 나가는 분• 데이터의 가치를 이해하고, 엔지니어링을 통해 데이터 중심 문화를 이끌어 갈 의지가 있는 분• 다양한 조직과 협업을 즐기며, 팀의 동반 성장을 위해 적극적으로 행동할 수 있는 분.",
테서,"• 의료 데이터를 사용한 다양한 태스크를 수행하는 LLM(Large Language Model)을 개발하고, 최적화하기 위한 알고리즘을 연구해요.• 모델 경량화와 배포 환경 최적화, AI Ops와 안정적인 추론환경을 구축해요.• 태스크에 적합한 프롬프트 체인과 RAG, 멀티모달 API를 개발해요.","[이런 연구 경험을 갖고 계신 분들을 찾고 있어요]• BERT, Hugging Face 등 Transformer 기반 자연어 모델 처리• 모델 최적화 오픈 소스 및 엔진(ONNX, TensorRT 등) 활용한 추론 최적화• Pytorch 기반 학습 프레임워크(DeepSpeed, Accelerate, Bitsandbyte 등) 활용 모델 구현• LLM 기반 서비스 상용화에 필요한 요건을 분석하고 직접 구현• LLM 기반 서비스 평가와 시스템 개발에 관한 실제 구현.","[ 이런 분들과 함께하고 싶어요 ]• BERT 기반 자연어 Fine-Tuning 및 경량화를 통한 API 구축 및 런칭 서비스 적용 경험을 가지고 계신 분이면 좋아요.• Docker 컨테이너 기반 운영 환경 기반 서비스 운영 경험이 있으신 분이면 더 좋아요.• Quantization에 대한 이해 및 학습/추론에 적용 경험이 있으신 분이면 좋아요. • Prefix Tuning, Adapter, LoRA 등 여러 PEFT 기법에 대한 높은 이해도를 갖고 계신 분이면 좋아요.• 최신 LLM 논문을 동향 파악 및 SOTA 알고리즘 적용 경험이 있는 분이 좋아요. • 자연어 처리 분야 석사 이상 또는 관련분야 논문 참여 경험이 있으신 분이면 좋아요.[합류 여정]• 서류 검토 ＞ 온라인 직무 인터뷰 ＞ 오프라인 컬쳐핏 인터뷰 ＞ 처우 협의 ＞ 합격 및 입사."
씨제이올리브영(CJ올리브영),"• 데이터 기반 핵심 비즈니스 로직 (지표분석, 데이터 제공등) 개발 및 운영• 데이터 기반 웹서비스 개발 (MSA 환경에서의 API 개발 ) 및 운영• Front-End 및 외부 시스템과의 원활한 연동을 위한 RESTful API 설계 및 개발.","• 5년 이상 Back-end Application 개발 경력이 있으신분• Golang을 이용한 서버 개발 경험이 있으신분• GCP, AWS, Azure 등의 클라우드 컴퓨팅 활용 경험이 있으신분.","• Docker, Kubernetes 등 컨테이너 기반 기술을 활용한 배포/운영 경험이 있으신분• MSA 환경을 구축하고 운영해 본 경험이 있으신 분• MQ 나 Kafka 등의 비동기 처리 Stream Engine 운영/개발 경험이 있으신 분."
에이아이트릭스(AITRICS),"• 주요 프로젝트: LLM을 활용한 예측모델 개발, 의료XAI, Real Time시그널 데이터 활용 연구• 선행연구 주제 발굴 및 논문 연구 리딩• 국내/외 병원과의 협업을 통한 의료 인공지능 모델 개발 프로젝트 기획• 연구팀의 연구 문화 고도화 및 팀 빌딩• 회사의 연구 전략 및 로드맵 수립.",• 머신러닝 관련 박사학위 소지자 또는 석사 이상 학위 소지 후 3년 이상 경력자• 선진사 인공지능 연구팀 리딩 경험• 머신러닝 혹은 유관분야 학회/학술지 논문 실적 보유자• 솔루션 개발 팀 및 비즈니스 팀과의 협업이 가능한 자• AI 제품 런칭 경험자.,• 머신러닝 관련분야 Top-tier 학회 논문 실적• 헬스케어 분야 경력• 스타트업 근무 경험.
제이와이피엔터테인먼트(JYP),"- 데이터 파이프라인 설계 및 구축: 다양한 소스로부터 안정적인 ETL 프로세스 구현- 데이터 인프라 운영: 클라우드 기반 데이터 웨어하우스/레익 구축 및 최적화- 데이터 통합 플랫폼 개발: 전사 데이터를 연결해 하나의 체계로 관리- 분석/시각화 지원: Tableau, Power BI 등으로 경영진/사업부 의사결정 지원- 자동화 및 품질 개선: 데이터 처리 자동화 및 품질 관리 체계 확립.","- (필수) 데이터 엔지니어링 경력 3년 이상- Python, SQL 숙련 및 데이터 처리/분석 능력- ETL 파이프라인 구축 및 자동화 경험- 데이터 시각화 툴 (Tableau, Power BI 등) 사용 경험- 데이터로 비즈니스 문제를 해결한 경험.","- 클라우드 (AWS, GCP, Azure) 기반 데이터 시스템 경험 보유자 우대- 엔터테인먼트/미디어 산업 데이터 분석 경험 보유자 우대- 머신러닝/통계 분석 경험 보유자 우대- 글로벌 데이터 활용 프로젝트 경험 보유자 우대."
뉴로엑스티,• 헬스케어/의료 데이터 기반 파운데이션 모델 및 질병예측 모델 설계 & 개발 검증• 기존 AI/백엔드 개발자 및 도메인(헬스케어/의료) 담당자와 협업• 코드 관리 및 문서화.,"• 산업계 AI/ML 개발 경력 3년 이상• PyTorch 기반 모델 개발 경험을 갖추신 분• Git 등 버전관리 사용 경험, 실험 재현성/문서화 습관을 지닌 분• 전공자 및 비전공자(의료진, 타부서 등)와 명확히 소통할 수 있는 분.","• 헬스케어/의료 데이터 (특히, EHR 데이터) 전처리 및 분석 경험을 지닌 분• 개인정보 비식별화, 의료정보 관련 법규 및 윤리 지식 보유하신 분 (국가별 규정을 이해하신 분이면 더욱 좋습니다!)• 관련 학회 및 컨퍼런스 발표 또는 논문 게재 경험을 지닌 분."
씨메스(CMES),"• Blender, NVIDIA Isaac Sim, Omniverse를 활용한 시뮬레이션 환경 구축 및 합성 데이터 생성• Generative Model(Diffusion, GAN, NeRF, Text-to-3D 등)을 활용한 데이터 생성 및 확장• Real-to-Sim/Sim-to-Real Domain Adaptation 연구 및 파이프라인 구축• Vision 및 3D Perception 연구팀과 협업하여 학습용 Synthetic Dataset 설계 및 자동화• Domain Randomization, Sensor Simulation, Lighting/Material Variation 등 데이터 다양성 확보 전략 수립• 실제 센서 데이터와 합성 데이터 간의 Domain Gap 최소화 및 품질 검증• 데이터 생성 및 시뮬레이션 워크플로우의 엔드투엔드 자동화 및 최적화.","• 학력 : 석사 이상(Computer Graphics, Simulation, Robotics, Machine Learning 관련 분야)• 경력 : 신입 또는 2년 이상• Blender, Isaac Sim, Omniverse, Unreal Engine 등 시뮬레이션 툴에 익숙하신 분• Python/C++ 기반 API 제어 및 스크립팅 능력이 있는 분• Computer Vision, 3D Perception, Generative AI에 대한 이해가 있는 분.","• Diffusion/GAN/NeRF/3D Generative Model 기반 데이터 생성 경험이 있으신 분• Domain Adaptation, Domain Randomization, Sim-to-Real Transfer Learning 관련 연구 경험이 있으신 분• 카메라, LiDAR, IMU 등 센서 모델링 및 물리 기반 렌더링(PBR) 경험이 있으신 분• 대규모 데이터 생성 파이프라인 구축 및 자동화 경험이 있으신 분• 로봇 시뮬레이션 및 강화학습 환경 구축 경험이 있으신 분."
씨메스(CMES),"• 물류/제조/휴머노이드 과제용 시뮬레이션 환경 설계 (물리·접촉·마찰·센서 모델링)• NVIDIA Isaac Sim/Omniverse(USD) 기반 에셋 파이프라인 및 자동 시나리오 생성• 합성데이터 렌더링 파이프라인 구축(PBR, 라이트/재질 도랜, 카메라/라이다/IMU 모델)• 인시뮬 학습(RL/IL/JEPA 계열 표현학습) 및 대규모 분산 트레이닝 워크플로우 구축• Sim2Real 갭 분석·보정(도메인 랜덤라이제이션/어답테이션, 센서 캘리브레이션)• 데이터 카탈로그/메타데이터/리플레이·리그레이드 시스템 운영• 월드모델 선행 연구.","• 학력 : 석사 이상(관련 전공)• 경력 : 신입 또는 2년 이상• Isaac Sim/Omniverse 또는 동등 스택(Unity/Unreal/Gazebo/MuJoCo/PyBullet 등) 경험이 있는 분• Python/C++ 능숙, PyTorch 기반 학습 파이프라인 개발 경험이 있는 분• USD/에셋 파이프라인, 대규모 배치 렌더링 및 도메인 랜덤라이제이션 이해가 있는 분• 분산실험/컨테이너(Docker), 스케줄러(Slurm 등) 환경 운영 경험이 있는 분• 메니퓰레이터 또는 휴머노이드 로봇 프로젝트 경험이 있는 분 (실 환경or시뮬레이터 환경).","• Omniverse Kit/Isaac ROS, Isaac Gym/Orbit, Blender 사용 경험이 있으신 분• JEPA/자기지도 표현학습, World Model, NeRF/GS 계열 생성·표현 모델 및 Real2Sim 경험이 있으신 분• Photorealistic 합성데이터로 실성능 개선(Sim2Real) 프로젝트를 진행한 경험이 있으신분• PBR 셰이딩/카메라 모델·노이즈 모델링, 포토그래메트리·모션캡처 파이프라인 경험이 있으신 분• 센서 동기화/타임스탬프/메타데이터 표준화, 데이터 거버넌스 경험이 있으신 분• 제조·물류 설비(AMR, 컨베이어, 피킹 스테이션 등) 연동/인터페이스 경험이 있으신 분."
씨제이이엔엠(CJ ENM),"데이터 분석가는 Mnet Plus의 서비스 데이터를 기반으로 팬 경험을 정량적으로 이해하고, 비즈니스 및 제품 의사결정을 지원하는 역할을 담당합니다.• 도메인 내 다양한 서비스와 비즈니스 영역에 대한 데이터 분석 및 문제 정의를 주도적으로 수행• 비즈니스 변화에 따라 데이터 리소스를 관리하고, 적절한 데이터 분석과 리소스 계획 수립• 데이터분석 파트 내에서 리더십을 발휘하며 팀원들의 멘토링 및 성장 코칭.",• 데이터 분석 또는 관련 실무 경험 5년 이상 경험하신 분• Google Analystics 등 데이터 리포팅 툴 사용 능력을 갖추신 분• SQL을 이용해 대용량 데이터를 추출하고 다룰 수 있는 능력을 보유하신 분• 비지니스 중요도를 고려하여 리소스 분배및 업무 우선순위 설정 경험이 있으신 분• 다양한 지표를 이해하고 이를 시각화 대시보드로 구현하여 비지니스 인사이트를 제공해보신 분.,"• 글로벌 B2C 서비스에서 데이터 분석 경험을 보유하신 분• 클라우드 환경에서 대용량 데이터 분석 경험을 보유하신 분[캐릭터&성향]• 직군과 관계없이 어울릴 수 있고, 적극적인 커뮤니케이션을 하려고 노력하는 분• 우선순위를 명확히 하여 Resource 대비 최대의 Impact를 만들어 줄 수 있는 분• 나의 팀만을 위한 의사결정이 아닌 사업부 차원의 의사결정을 할 수 있는 분• 사업과 조직의 Stage변화에 맞춰 유연하게 사고하고, 일하는 방법과 Role, Formation 방식 등에 유연하게 대응할 수 있는 분• 콘텐츠에 대한 진심과 애정으로 콘텐츠業을 사랑하며 진정한 덕업일치를 이루고 싶은 분."
현대오토에버,"• 생성형AI 플랫폼 운영 및 데이터 파이프라인 관리• 생성형AI 플랫폼 기반의 현업 AI과제 개발 지원• 플랫폼 기능 업그레이드 지원• 서버 구성 관리 (운영서버, DB, 개발/학습 및 sLLM 추론서버 등).","• SI 프로젝트의 수행 또는 관리 경험 (PM, PL 등)• 생성형AI의 기초 개념 및 기술 트렌드를 이해• Kubernetes(RKE2, Rancher, Helm 등) 기반 업무 경험• 고객사 및 협력사와의 소통 및 의사결정 조율에 능숙한 자.","• 생성형AI 서비스의 개발/운영과 관련한 업무 경험• AI 플랫폼 (OpenAI, Azure 등) 기반 API 활용 경험• 데이터 파이프라인 또는 데이터 전처리 관련 업무 경험."
현대오토에버,• AWS 서비스 분석/구축 : 비즈니스 요구사항 분석 : AWS 서비스 구축 : CI/CD 및 IaC(Infrastructure as Code) 구축• AWS 인프라 운영 및 최적화 수행 : AWS 리소스 관리 및 최적화 : EOS Life-cycle 관리 프로세스 정립 : 장애 분석/해결 : 서비스 이슈 대응 및 품질/VoC 관리.,"• AWS 인프라 구축 및 운영(3년 이상)• AWS Cloud Native 서비스 구축(EKS, IoT, CI/CD 등)• Multi-Hybrid Cloud 네트워크 구축 및 운영• AWS 마이그레이션 수행• Orgarnization(Multi Account 환경) 구축 및 운영• AWS Workload의 Monitoring 구성, Alert 설정/운영.","• Python 등 프로그래밍 경험• Kubernetes, Kafka 클라우드 인프라 구축 및 운영 경험• ArgoCD, Gitlab, Jenkins 등 CI/CD 환경 구축 경험• AWS 서비스 구축/관리 방법론에 대한 지식 보유• 하이브리드 Cloud 간의 Mass Migration 경험• 커뮤니케이션에 적극적이고 긍정적인 분• 해외 업무협의를 위한 비즈니스 영어 가능한 분• IT 계열(컴퓨터공학 등) 전공하신 분."
위드네트웍스,"• 방화벽 정책 설계, 구축 및 운영• 보안 정책 및 규정 준수 점검• 네트워크 보안 유지보수 및 장애 대응.",• 신입 가능• 문제 해결 능력 및 커뮤니케이션 역량.,"• 네트워크 및 방화벽 솔루션 구축 경험자• 보안 자격증( 정보보안기사, CCNP 등) 보유자• • 방화벽(Fortinet, Palo Alto, 안랩 등) 운영 경험."
샵라이브,"소개샵라이브에서 발생하는 다양한 데이터에 대한 파이프라인을 구축, 통합하고 시각화하는 업무를 수행하며, 데이터를 통한 인사이트 도출과 비즈니스 기여를 주도할 시니어 데이터 엔지니어를 모집합니다. 이 역할은 실무 중심의 기술적 기여뿐만 아니라 소규모 팀의 운영과 기술적 리더십을 통해 데이터 조직의 방향성을 함께 만들어가는 것을 목표로 합니다.주요업무• 다양한 소스에서 발생하는 데이터의 파이프라인 설계, 개발 및 운영• 데이터 저장소의 품질, 비용 효율성, 보안에 대한 관리 및 최적화• 데이터 시각화 및 모니터링 시스템 구현• 비즈니스 인사이트 도출을 위한 ETL/ELT 프로세스 설계 및 개선• 분석가, 제품 관리자 등 다양한 직무의 동료와 협업하여 데이터 기반 문제 해결• 주니어 데이터 엔지니어의 멘토링 및 코드 리뷰, 기술 의사결정 주도• 팀 내 기술 방향성과 우선순위 설정 등 소규모 팀 운영.","• 컴퓨터 관련 학과의 학사 이상 학위• 데이터 엔지니어링 분야에서 5년 이상의 경력• SQL 숙련도 및 RDBMS 운영 경험• Python, Java, Scala 중 하나 이상의 프로그래밍 언어 숙련• BigQuery, Redshift, Snowflake 등 데이터 웨어하우스 솔루션에 대한 숙련• Airflow 등의 데이터 워크플로우 도구 사용 경험• Looker, Tableau 등 시각화 도구 사용 경험• 데이터 파이프라인 아키텍처 및 대용량 데이터 처리에 대한 이해• 원활한 기술적 커뮤니케이션 및 조직 간 협업 능력.","• Hadoop, Spark, Kafka 등 분산 처리 프레임워크 활용 경험• AWS, GCP 등 클라우드 환경에서의 데이터 아키텍처 설계 및 운영 경험• Docker, Kubernetes 등 컨테이너 및 오케스트레이션 기술 이해• 데이터 거버넌스 및 보안 정책 수립 경험• 분석가 및 제품 조직과 협업하여 데이터 기반 문제 해결을 주도한 경험."
메크랩,• CAD/Simulation 특화 LLM 모델 파인튜닝• LLM 알고리즘 분석 및 개선• 다양한 튜닝 방법 적용 및 평가• 도메인 전문가와 데이터셋 파이프라인 구축• 도메인 전문가와 데이터 클리닝.,• AI 모델 개발 및 튜닝 경험자• 코드 생성 LLM 개발 경험자.,• AI 관련 학위 소지자 우대해요• 클라우드 플랫폼 경험자 우대해요• 오픈소스 프로젝트 기여 경험자 우대해요• 팀 협업 및 커뮤니케이션 능력 우대해요.
넛지헬스케어(캐시워크),"ㆍSQL을 사용한 데이터 추출 및 전처리를 통한 지표 관리ㆍ주요 지표(KPI) 설계 및 대시보드 개발·관리ㆍFunnel 분석, Cohort 분석, AARRR 분석을 통한 인사이트 도출ㆍ서비스 개선을 위한 가설 수립 및 검증.","ㆍ병역특례 대상자ㆍSQL (Bigquery), Python 등을 이용해 데이터 추출/가공/분석을 능숙하게 하실 수 있는 분ㆍData-Driven 커뮤니케이션이 가능하신 분ㆍFunnel, AARRR, Cohort 분석 등 데이터 분석 방법에 대한 지식과 경험이 있으신 분.","ㆍGCP(BigQuery), Google Analytics 사용 경험이 있으신 분ㆍ데이터 기반으로 서비스 품질 향상 및 마케팅 성과에 기여한 경험이 있으신 분ㆍ데이터에 기반한 가설을 세워 A/B Test를 설계하고 진행해보신 분ㆍ머신러닝 또는 예측 분석 경험이 있으신 분ㆍ대용량 데이터 처리 경험이 있으신 분."
뤼튼테크놀로지스,"• Kubernetes 환경에서 Strimzi를 기반으로 Kafka 클러스터 및 Kafka Connect 생태계를 안정적으로 운영합니다.• Kafka 프로듀서/컨슈머 애플리케이션을 개발하고 운영합니다.• Flink, Spark Streaming과 같은 분산 스트림 처리 프레임워크를 사용하여, 실시간 추천 및 이상 탐지 등 비즈니스 가치를 창출하는 데이터 애플리케이션을 개발하고 운영합니다.• 실시간 데이터 파이프라인의 처리량, 지연 시간 등을 면밀히 모니터링하고 지표화하여, 잠재적인 문제를 사전에 감지하고 해결합니다.","• Java, Python 중 하나 이상의 언어를 이용한 데이터 처리 애플리케이션 개발에 능숙하신 분• Kafka를 이용한 데이터 파이프라인 개발 및 운영 경험이 있으신 분• 새로운 기술을 빠르게 학습하고 적용하는 것에 즐거움을 느끼시는 분• 동료와의 토론과 리뷰를 통해 함께 성장하는 것을 중요하게 생각하시는 분.",• 스키마 레지스트리와 함께 Avro/Protobuf 포맷을 다뤄본 경험이 있으신 분• Flink를 통한 스트림 처리 프레임워크 사용 경험이 있으시거나 관심이 있으신 분• Strimzi 환경에서 Kafka Connect를 구축하고 운영해 본 경험이 있으신분• Kubernetes 환경에서 스트리밍 애플리케이션을 운영해 본 경험이 있으신 분• MSA(Microservice Architecture) 환경에서의 실시간 데이터 처리 경험이 있으신 분.
텔레픽스,"• 도메인 특화 LLM 어플리케이션 개발 및 AI 모델 추론 서버 구축• 지리공간 RAG 설계: 벡터DB + 메타데이터 인덱싱 + 검색/리랭킹• 위성/항공 이미지와 텍스트를 아우르는 멀티모달 어플리케이션 개발 및 배포• 에이전트/툴체이닝 기반의 업무 자동화• 프로덕션 품질 보장: 프롬프트/파인튜닝 데이터 관리, 평가, 모니터링 등.","관련 학과 학사 졸업 이상(졸업 예정자 포함)• 관련 분야 경력 2년 이상이신 분(Python 숙련자, LLM 엔지니어링 역량 보유자)• 아래 중 2개 이상 실전 경험 ㆍLangGraph 기반 멀티 에이전트 프로덕트 구축 및 운영 경험 ㆍLLM 파인튜닝(지식주입, 지침튜닝, 안정성) 또는 프롬프트 엔지니어링 ㆍRAG 설계/운용(인덱싱, 하이브리드 검색, 리랭킹, 캐싱)멀티모달(이미지텍스트) 파이프라인 구성 및 서비스화.","• MLOps 경험• 도메인 특화 데이터셋 구축/정제 경험(라벨링·필터링·데이터카드)• 클라우드(AWS/GCP/Azure)에서의 ML 배포·서빙 경험, 컨테이너/Docker·Kubernetes 실무• LangChain/LangGraph, 벡터DB 운용, GPU 최적화, 스트리밍/실시간 응답 최적화• 국방/재난·농업·자원 등 EO 활용 과제 경험, 보안 요구사항 준수 배포 경험• 타일 서버를 활용한 GIS 엔지니어링 경험."
하얀마인드,"• Lead the development of purchase likelihood prediction models based on large-scale user behavior data, optimizing enterprise customer revenue and driving Monetai’s long-term success.대규모 사용자 행동 데이터를 기반으로 구매 가능성 예측 모델을 주도적으로 개발하며, 이를 통해 엔터프라이즈 고객의 수익을 최적화하고 Monetai의 장기적인 성과를 만들어 갑니다.• Validate model performance through offline evaluations, and measure revenue impact via online evaluation in production environments.오프라인 평가를 통해 모델의 성능을 검증하고, 실제 프로덕션 환경에서의 온라인 평가를 통해 모델이 매출에 미치는 영향을 측정합니다.• Deploy models in production-ready form and operate scalable inference environments to deliver real-time value to customers.모델을 서비스에 통합 가능한 형태로 안정적으로 배포하고, 확장 가능한 추론 환경을 운영하여 고객이 실시간으로 가치를 얻을 수 있도록 합니다.• Monitor data quality and build **feedback loops** to continuously improve model performance and reliability.데이터 품질을 모니터링하고 **피드백 루프를 구축**하여 모델의 성능과 신뢰성을 지속적으로 높입니다.• Support customer adoption and integration, while clearly explaining and demonstrating solutions to both technical and non-technical stakeholders.고객사의 도입과 통합을 지원하며, 이 과정에서 기술적 및 비기술적 이해관계자 모두에게 솔루션을 명확하고 설득력 있게 설명하고 시연합니다.• Contribute to product roadmap and technical strategy, creating long-term business impact for Monetai.제품 로드맵과 기술 전략 수립에 참여하여 Monetai의 장기적인 비즈니스 임팩트를 만들어 갑니다.","• AI Product Development Experience: Experience building end-to-end products using ML/AI, from prototypes to production. Ability to approach development with a whole-product perspective, from initial design through deployment and user experience.AI 제품 구축 경험: ML/AI 기술을 활용해 프로토타입부터 제품까지 만들어본 경험. 부분 기능이 아니라 제품 전체의 관점을 가지고, 초기 설계부터 실제 배포와 사용자 경험에 이르기까지 전 과정을 이해하며 개발해본 경험이 있는 분• MLOps and Production Experience: Hands-on experience deploying and operating models in production environments, including automation, monitoring, performance maintenance, and iteration.MLOps 및 프로덕션 운영 경험: 모델을 실제 서비스 환경에 배포하고 운영해본 경험. 단순히 모델을 만드는 데 그치지 않고, 배포 자동화·모니터링·성능 유지·개선까지 경험해본 분.• Large-Scale Data Processing: Experience handling and processing large-scale data for model training and evaluation. Skilled in SQL and large-scale queries, with experience using databases like Postgres and BigQuery. Experience designing and operating data pipelines is a strong plus.대규모 데이터 처리 경험: 방대한 데이터를 효율적으로 가공·분석해 모델 학습과 평가에 활용한 경험. SQL 작성 및 대규모 데이터 쿼리 능력을 갖추고 Postgres·BigQuery 등 데이터베이스 활용 경험이 있는 분. 또한, 데이터 파이프라인을 직접 설계·운영해본 경험이 있는 분.• User and Impact-Oriented Mindset: Ability to critically evaluate how products affect both customer success and user experience, balancing speed, quality, and cost with accountability.사용자와 임팩트 중심 사고: 제품을 설계할 때 단순히 기술적 완성도가 아니라, 실제 사용자의 삶과 고객사의 성과에 어떤 영향을 줄지를 비판적으로 사고할 수 있는 분. 속도·완성도·비용 간 균형을 이해하고 책임감을 갖고 결정할 수 있는 분.","• Business Metrics Interpretation: Experience working with key business metrics such as ARPU, conversion rate, LTV, and retention, and connecting model performance to revenue impact.비즈니스 지표 해석 경험: ARPU, 전환율, LTV, 리텐션 등 핵심 매출 지표를 이해하고, 모델 성능을 실제 매출 임팩트와 연결해 해석·개선해본 경험.• Cloud-Based Data Infrastructure: Experience building and operating large-scale data pipelines in cloud environments such as GCP, BigQuery, Vertex AI, and Dataflow.클라우드 기반 데이터 인프라 경험: GCP, Bigquery, Vertex AI, Dataflow 등 클라우드 환경에서 대규모 데이터 파이프라인을 구축·운영해본 경험.• Multi-Tenant SaaS Experience: Experience designing and operating systems, data, and models that serve multiple customers simultaneously in a SaaS environment.멀티 테넌트 환경 경험: 다수의 고객사를 동시에 지원하는 SaaS 구조에서 데이터, 모델, 시스템을 설계·운영해본 경험.• Global Collaboration: Experience working with international customers across diverse cultural and language backgrounds, operating global SaaS products.해외 고객사 협업 경험: 다양한 문화적·언어적 배경을 가진 고객사와 협업하며, 글로벌 SaaS 제품을 운영해본 경험."
팀블랙버드(CryptoQuant),"• 고객이 필요로하는 데이터를 리서치합니다. 1) Web3 생태계 및 시장을 조사하면서 니즈가 있는 데이터를 발굴합니다. 2) CQ의 고객을 분석하고, CQ의 제품 및 비슷한 온체인 데이터 제품을 분석합니다.2. 고객이 필요로하는 데이터를 기획하고 평가합니다. 1) 아이디어 형태의 데이터를 실제 metric, mart, dashboard 형태로 구체화합니다. 2) 블록체인 로우 데이터, 스마트 컨트렉트, Web3 프로젝트 구조/백서 등을 깊이 있게 분석하여 만들고자 하는 데이터를 구체화하고 문서화합니다. 3) 필요하면 통계적인 방법론을 이용해 데이터를 평가합니다.3. 고객이 필요로하는 데이터 제품을 만듭니다. (아래는 예시입니다.) 1) 각 블록체인 별 KPI 대시보드를 구축합니다. 2) 각 프로젝트의 성과를 projection할 수 있는 토큰 별 valuation metrics 및 risk management metrics를 만듭니다. 3) 트레이딩에 활용할 수 있는 indicator를 만듭니다. 4) 고객이 필요로하는 index 상품을 제작합니다.해당 업무를 진행하면서 다음과 같은 성장을 기대할 수 있습니다.1. 고객이 필요로하는 데이터를 리서치하면서, 블록체인 및 Web3의 전반적인 생태계를 넓고 깊게 공부/이해하면서 블록체인 산업군에 대한 이해도를 높일 수 있습니다.2. 고객이 필요로하는 데이터를 구체화하면서, 블록체인 로우 데이터 및 스마트 컨트렉트 등을 누구보다 깊은 수준으로 공부하며, 블록체인 및 Web3 분야에 대한 기술적 이해도를 높일 수 있습니다.3. 여러 글로벌 금융 기관들 및 파트너사들과 긴밀하게 협업하면서 금융에 대한 이해도를 높일 수 있습니다.4. 데이터 엔지니어와 긴밀하게 협업하며 SQL을 매우 높은 수준으로 훈련할 수 있습니다. 쿼리의 효율을 고민하며 기술적인 쿼리 최적화 작업도 진행합니다.5. 데이터 제품을 PO와 함께 제작하면서 제품 오너십을 가지고 여러 시도를 해볼 수 있습니다.","• 한 개 이상의 블록체인 프로토콜(Layer1 혹은 Layer2)의 구조를 깊이 이해하고, 해당 체인의 로우 데이터(ex. block, transaction, state 등)를 직접 탐색하거나 분석해본 경험이 있는 분• 예: Ethereum의 Beacon Chain에서 totalSupply 계산 로직을 따라가 본 경험, Tron의 Bandwidth / Energy 소비 구조를 기반으로 TX 수수료 분석한 경험, TON의 shardchain 구조를 이해하고 masterchain 블록을 추적한 경험 등2. 데이터 엔지니어와의 협업을 통해, 온체인 데이터 기반의 내부 지표 시스템이나 BI 대시보드를 설계/구축해본 분• 예: 특정 체인의 토큰 보유 분포, 고래 주소 활동, 활성 사용자 수 등 목적 중심(예: 비즈니스 모니터링/투자 인사이트 도출)으로 기획된 대시보드 3. SQL, Python, 또는 AI Code Assistant 등을 활용해, 트랜잭션 단위의 온체인 데이터를 가공하고, 비즈니스 인사이트를 추출할 수 있는 분• 예: Ethereum 지갑 그룹의 netflow 계산, XRP의 월별 거래소 이동 추이, TON staking reward 비율 계산 등 4. Web3 산업의 빠른 진화 속도를 따라갈 수 있는 학습 능력과 도메인 적응력을 갖춘 분• 예: 이더리움 Dencun 업그레이드나 Solana 지갑 구조 변화 같은 트렌드 변화에 빠르게 적응하고 설명할 수 있는 수준.","• 블록체인(e.g. Bitcoin, Ethereum) 데이터 기반의 분석 프로젝트를 경험해보신 분• 퀀트 투자를 경험해보신 분• 암호화폐, 거시 경제, 트레이딩에 관심이 많고, 트렌드를 빠르게 파악할 수 있으신 분• 영어로 능숙하게 소통할 수 있는 분• 크립토퀀트의 기업문화와 잘 맞는 분 (https://bit.ly/3r4TH1v)."
빅밸류,• 데이터 거버넌스 구축• 데이터 표준화 및 품질 관리 방안 기획 및 개발• 데이터 아키텍처 설계 및 모델링• 데이터 처리 성능 최적화 방안 설계 및 구축• 온톨로지 설계/구축• 데이터 리터러시 증대를 위한 연구• 전사 데이터 교육• 데이터 상품 QA/QC 기준 수립 연구• 데이터 상품 고도화 기획.,"• 경력: 무관• 공간 데이터, 빅데이터, 인공지능 기술 전반에 대해 관심이 있는 분• 해외 출장에 결격 사유가 없는 분※ 전문연구요원 지원 가능.","• DAP 소지자• 데이터 아키텍처, 소프트웨어 아키텍처 석사 이상 전공자• 통계학 및 데이터 분석 관련 지식 보유자• 분석계 모델링 경험자• 온톨로지 설계 및 구축 경험자• 다양한 직군의 이해관계자들과 효과적으로 소통하고 협업할 수 있는 커뮤니케이션 능력이 있는 분기술 스택• Postgresql, Airflow, Grafana, Python, OWL, RDFS, DSL, GraphDB."
토스뱅크,"[합류하면 함께할 업무예요]• 복잡한 은행 시스템을 빠르고 간결한 구조로 고객에게 제공할 수 있는 방법에 대해 고민하고 실행해요.• 고객에게 좋은 경험을 제공할 수 있도록 빠르고 유연하며, 확장이 용이한 시스템을 개발해요.• 혁신적인 Data Product 를 위한 아이디어를 먼저 제안하고, 실제 서비스를 설계부터 개발까지 할 수 있어요.","[이런 분과 함께하고 싶어요]• 데이터 어플리케이션 개발을 위한 소프트웨어 개발 역량(Java, Kotlin, Python 등)을 갖춘 분이 필요해요.• 대용량 분산 시스템(Hadoop, Spark 등) 활용 경험이 있는 분이 필요해요.• Kotlin으로 Spring Framework 기반의 서비스를 개발한 경험이 있는 분이 필요해요.• 사내에서 Frontend / Backend 기술을 이용하여 데이터 관련 툴을 개발해보신 분이 필요해요.• Data Warehouse, Mart에 대한 이해와 Airflow 기반 workflow를 개발한 경험이 있으면 좋아요.• k8s 환경에서 Application 개발을 경험하신분이면 좋아요.• Data Engineering의 다양한 업무를 경험하신 All-Rounder이신 분이 좋아요. 하지만 All-Rounder가 아니더라도 본인의 업무에 대해 깊이 있는 지식을 갖춘 분, 다양한 영역에서의 업무 확장을 하고 싶으신 분도 좋아요.","[이력서는 이렇게 작성하시는 걸 추천해요]• 그동안 해오신 업무 중 임팩트 있었던 프로젝트를 구체적으로 적어주세요.• 데이터 Product를 만들어본 경험을 제작 동기부터 과정, 결과까지 구체적으로 적어주시면 좋아요.• 실제 서비스에 적용하여 개선한 경험이 있다면 결과를 수치로 나타내주면 좋아요.(외부 공개가 민감한 사항일 경우, 해당 부분은 제외해 주세요.)• 단순히 구축과 개발에서 끝나는 경험이 아닌 트러블슈팅 및 운영, 성과를 적어주시면 좋아요."
토스뱅크,"[합류하면 함께할 업무예요]• 서버/서비스/앱 로그 등 대용량 메시지 처리를 위한 Kafka, Kafka Connect Cluster 를 운영해요.• Mysql, Mongo, Oracle CDC 기술을 활용해 실시간 파이프라인을 개발해요.• Flink 기술을 활용해 데이터 처리 앱을 개발하고 파이프라인을 구축&운영해요.• 대용량 로그 데이터를 설계하고, 파이프라인을 구축하여 분석에 사용될 수 있도록 데이터를 최적화해요.• Iceberg 를 활용해 대용량 로그 데이터와 실시간 데이터를 저장하고 유지보수해요.","[이런 분과 함께하고 싶어요]• Kafka 구축과 운영 과정을 서비스에 맞게 튜닝하고, 문제해결을 위해 코드를 직접 분석하거나 수정해 본 경험이 필요해요.• Kafka Connect, Flink, CDC 등의 기술을 활용하여 실시간으로 데이터를 처리&운영해 본 경험이 필요해요.• k8s 환경에서 spring 기반 백엔드 개발이나, python fastapi 백엔드 개발 경험이 있으신 분이면 더 좋아요.• Hadoop, Spark 등의 분산처리 시스템에 대한 경험이 있으신 분이면 더 좋아요.• 많은 운영요소들을 자동화하여 체계적인 시스템을 만들어 오신 분이면 더 좋아요.• 데이터를 분석하고, 검증해본 경험이 있으면 좋아요.","[이력서는 이렇게 작성하시는 걸 추천해요]• 그동안 해오신 업무 중 임팩트 있었던 프로젝트를 구체적으로 적어주세요. 특히 Kafka 중심의 실시간 데이터 파이프라인을 • 이해하고 이를 활용해 본 경험을 구체적으로 적어주시면 좋아요.• 분산처리 시스템에 대한 이해를 바탕으로한 Data Engineering 경험을 구체적으로 적어주세요.• 실제 서비스에 적용하여 개선한 경험이 있다면 결과를 수치로 나타내주면 좋아요.(외부 공개가 민감한 사항일 경우, 해당 부분은 제외해 주세요.)• 단순히 구축과 개발에서 끝나는 경험이 아닌 트러블슈팅 및 운영, 성과를 적어주시면 좋아요."
미소(miso),"[미소에서 하게 될 업무는요]• 다양한 데이터 소스로부터 데이터 수집과 분석을 통해 중요한 인사이트를 얻고, 빠르게 제품과 서비스에 반영하여 고객에게 행복한 순간을 더욱 많이 제공하기 위해 노력합니다.• 데이터 파이프라인과 데이터 플랫폼을 구축하고 유지하며, 다양한 이해관계를 가진 팀들에 일관된 데이터 흐름 및 주요 사업 지표를 제공합니다.• 데이터에 기반한 서비스를 개발하고 배포하는 데 있어 응용 프로그램 개발자와 협업하며 주도적인 역할을 수행합니다. 여기에는 데이터 과학자들이 만든 새로운 데이터 모델 및 알고리듬의 실험과 최적화, 퍼포먼스 측정 등을 통해 지속적으로 서비스를 향상시키기 위한 노력들이 포함됩니다.","[이런 분과 함께하고 싶습니다]• 데이터 주도 결정(DDD)을 기반으로 제품의 문제점을 파악하고 향상시키려는 열정을 가진 분• 다양한 종류의 Relational/NoSQL 데이터베이스를 사용해본 경험• 전문적인 통계지식과 인사이트를 보유하고, 가설 수립 및 검증, 인과 분석을 실행할 수 있는 분[미소의 기술 스택]• Mobile Frontend - Typescript, React Native, TanStack Query, Zustand, Redux, Firebase, Hot Updater, Jest, RTL, Zod, Fastlane• Web Frontend - Typescript, Next.js, React, TanStack Query, Zustand, Tailwind CSS, Shadcn, Emotion, Jest, RTL, Zod, Strapi• Backend - NestJS, Serverless Framework, Fastify• Infrastructure - AWS, Nginx, Terraform, Kubernetes(EKS), Redis, Kafka• Observability - Grafana, Prometheus, Loki stack• Database - PostgresSQL, DynamoDB, Hasura• Data Warehouse - AWS Athena, Redshift, Airbyte, Airflow, Redash• Data Science - Python• Analytics, CRM - Amplitude, Branch, Facebook, Firebase, CleverTap• CI/CD Pipeline - Github Actions, ArgoCD, Helm• Design Tool - Figma, Adobe.","[우대 사항]• AWS 클라우드 인프라스트럭처에 익숙하거나 쉽게 적응 가능하신 분• 클라우드 환경에서 ETL 또는 스트리밍 데이터 파이프라인을 이해하고 구축할 수 있는 분• 마이크로서비스 아키텍처를 이해하고, 클라우드 환경에서 컨테이너/서버리스 기반 CI/CD 경험."
페이타랩(패스오더),"• 마케팅 또는 프로덕트 성과 측정을 위해 데이터 추출·가공·시각화까지 이어지는 데이터 파이프라인을 설계 및 구축해요.• KPI 및 연관 지표들을 명확히 정의하고, 전사적인 지표 관리 체계를 확립해요.• 사용자 행동 데이터 분석을 통해 심층적인 인사이트를 도출하고, 이를 바탕으로 패스오더 퍼널 전환율을 개선해요.• 데이터 분석 결과를 기반으로 도출한 솔루션의 기대효과를 예측하고, A/B 테스트와 후속 성과 측정을 통해 실제 비즈니스 임팩트를 측정해요.• 구성원이 데이터를 기반으로 심층적인 인사이트를 도출하고 의사 결정할 수 있도록 Data-Driven 환경을 만들어요.","• 비즈니스 목적에 맞는 데이터 파이프라인(ELT/ETL)을 설계 및 구축한 경험이 있는 분• SQL과 Python을 활용해 대용량 데이터를 추출• 정제• 가공• 분석할 수 있는 분• 모바일 서비스의 고객 행동 분석(Retention, Cohort, 세그먼트)과 마케팅 효율 지표(CAC, ROAS, ROI) 분석에 대한 이해가 있는 분• 문제정의 ＞ 가설수립 ＞ 실험설계(A/B 테스트) ＞ 성과측정 ＞ 개선으로 이어지는 실험 사이클을 직접 수행한 경험이 있는 분.","• 2년 이상의 마케팅/프로덕트 데이터 분석 혹은 데이터 엔지니어링 실무 경력이 있는 분• 빠르게 성장하는 IT 스타트업 환경, 특히 O2O·모바일 앱·식음료 도메인에서 근무한 경험이 있 분• BigQuery 등 클라우드 기반의 대용량 분석 환경에서 데이터 마트를 설계한 경험이 있는 분• 머신러닝 모델 학습 및 서빙을 위해 데이터 파이프라인을 구축 및 자동화한 경험이 있는 분• AI 툴을 활용해 리서치, 코드 생성, 리포팅 자동화 등 업무를 효율화한 경험이 있는 분• 조직 내 Data-Driven 문화 확산 및 데이터 리터러시 증대에 기여한 경험이 있는 분."
로민,"• 사내 데이터 관리 및 데이터 생애주기 관리 시스템 구축• 데이터 레이크 및 가공 파이프라인 설계·구축·운영• 데이터 형태 및 가공 방식에 대한 정책 정의 및 개선• 데이터 수집, 전처리, 변환, 배포 자동화• 데이터 조사, 검색 및 크롤링 자동화 도구 개발• 데이터 관리 시스템 개발 및 고도화• 데이터셋 통계 분석 및 특성 도출• 데이터 라벨링 시스템 구축 및 성과 분석• 학습 모델 기반 pseudo annotation 생성 및 품질 개선• 주요 언어 및 프레임워크: Python, Pandas, boto3• 데이터베이스 및 인프라 : Airflow, PostgreSQL, MinIO, AWS S3• 기타 : Docker, AWS.",• 데이터 엔지니어 또는 백엔드 개발 관련 2년 이상의 경력 또는 이에 준하는 역량을 보유하신 분• 데이터 및 통계에 대한 기본적인 이해가 있으신 분• 업무 진행 및 개발 결과를 체계적으로 문서화할 수 있는 분.• 팀원들과 원활한 협업 및 커뮤니케이션 능력을 보유하신 분.,• ETL 및 데이터 인프라 구축 경험이 있으신 분• 데이터 라벨링 시스템 개발/운영 경험이 있으신 분• 머신러닝 학습 데이터 구축 및 파이프라인 운영 경험이 있으신 분• 관련 분야 석사 이상의 학위 소지하고 계신 분.
로민,"이번에 모집하는 “ML 엔지니어” 는 이미지, 텍스트 등 다양한 데이터 유형을 활용하여 문서 인식 모델을 연구·개발하고, AI 엔진 성능 최적화 및 모델 서빙 효율화를 통해 실제 서비스에서 활용 가능한 고성능 AI 모델을 구축하는 핵심 역할을 담당하실 분을 찾고 있습니다. 최근에는 VLM 및 AI 에이전트 개발 및 연구도 진행 하고 있습니다.• 정형/비정형 문서의 인식 모델 및 VLM 연구 및 개발• 딥러닝 모델 serving을 위한 변환 및 최적화• 특정 산업 도메인용 AI 에이전트 연구 및 개발• 모델 성능 개선 및 관리• 주요 언어 및 프레임워크 : Python, FastAPI• 주요 딥러닝 프레임워크 : Pytorch, TensorFlow• 주요 라이브러리 및 툴 : OpenCV, HuggingFace, Triton.","• 머신러닝 관련 개발 경력 2년 이상 또는 그에 준하는 역량을 보유하신 분. - 단, 전문연구요원(병역특례) 지원자의 경우, 해당 경력 요건과 무관하게 지원 및 채용 절차 진행이 가능합니다.• 아래 내용에 대한 지식, 논문 작성 경험 및 논문 구현 능력이 있는 분 - 멀티모달 (컴퓨터비전, 자연어처리) - 딥러닝 / 머신러닝 - LLM 기반 응용 기술 및 에이전트 구조 설계• 본인이 구현한 코드, 업무의 진행 상황 및 결과 등을 정확하고 체계적으로 문서화할 수 있는 능력이 있는 분• 이공계(전공 무관) 학사 이상이신 분.","• 아래 연구 분야에 대한 지식 및 경험이 있는 분 - Object Detection / Recognition / Segmentation - Multi modality (Image, Text 등) - Sequence labeling - Text segmentation - Multi modality(Image, Text 등) 기반 머신러닝 알고리즘 - VLM (Vision Language Model)• 아래 내용에 대한 경험이 있으신 분 - SW 개발 리딩 경험 - SaaS 서비스 또는 자체 프로덕트 개발 사이클 전반의 경험• AI / 머신러닝 관련 대회 참가 경험이 있는 분• AI / 머신러닝 관련 국제학술대회에 논문을 게재한 경험이 있는 분• 관련 분야 석사, 박사학위 이상을 소지하신 분."
한국신용데이터(KCD),"액션 카탈로그·마케팅 카탈로그 등 RAG 파이프라인 고도화 및 튜닝을 통한 지식 기반 확장AI 비서 ‘캐시니’의 후평가 및 효율적 개선을 위한 데이터 구조 설계 및 구현캐시노트 내 사업장 데이터를 활용한 패턴 분석 및 인사이트 도출, 이를 AI 모델과연동하는 데이터 파이프라인 개발데이터 기반의 에이전트 행동 구조 설계 및 개선을 위한 실험적 데이터 엔지니어링 수행데이터 품질, 처리 효율, 추론 속도 향상을 위한 ETL/ELT, 캐시, 인덱싱 구조 최적화.","데이터 기반 서비스 또는 AI 서비스의 데이터 파이프라인을 설계·구축한 경험Python, SQL, Spark, Airflow, dbt 등 데이터 엔지니어링 스택에 대한 숙련RAG, LLM 파이프라인 또는 Embedding/VectorStore 구조 설계 경험비즈니스 데이터를 활용한 지표화, 패턴 탐지, 추천 시스템 설계 경험다양한 팀(AI/ML, 백엔드, 프로덕트 등)과 협업하며 데이터 중심으로 문제를 정의하고 해결할 수 있는 역량.","ML 모델 서빙, LLM 기반 Retrieval 및 후처리 파이프라인 구축 경험LangGraph, OpenSearch 등 AI 및 RAG 프레임워크 실무 경험대화형 에이전트(Conversational AI) 또는 AI 비서 서비스의 데이터 구조 설계·운영 경험실험 속도가 빠른 스타트업 환경에서 데이터 기반 의사결정 및 AI 프로덕트 개선을 주도한경험서비스 및 데이터와 프로덕 사이의 영역의 경험."
다이닝브랜즈그룹,"• * 어떤 일을 하게 될까요? 다이닝브랜즈그룹은 그룹 전체의 정보보호 수준을 한 단계 강화하기 위해 전담 DBA 인력을 충원합니다.현재 DBMS·서버·네트워크를 겸임하는 구조에서 벗어나 DB 보안·운영·성능관리에 전문적으로 집중할 수 있는 체계를 만들고자 합니다. 특히 F&B·E-Commerce 환경은 주문·결제·고객DB 등 데이터의 특성상 실시간 안정성과 보안성이 핵심이기 때문에, 해당 도메인 경험 보유자의 경우 즉시 기여가 가능하여 현업에서도 강하게 선호하고 있습니다. DBA로서 합류하시면, 다이닝브랜즈그룹 전 계열사 DB 운영 전반을 담당하며 DB 안정성 확보·보안정책 수립·ISMS 대응 등 조직의 핵심 기반을 책임지게 됩니다. [주요업무]1) 데이터베이스 운영 및 관리• RDBMS (MSSQL, Aurora MySQL, PostgreSQL 등) 운영·백업/복구• DB 계정 및 권한 관리 정책 수립·운영• 장애 발생 시 원인 분석 및 복구, 장애 재발 방지 대책 수립2) DB 성능 및 안정성 관리• SQL 튜닝, 인덱스 관리, 실행계획 분석 등 성능 최적화• 모니터링 도구(예: Whatap, NewRelic 등) 기반 DB 상태 점검• 백업정책 및 복구 테스트 주기적 수행3) 보안 및 감사 대응• DB 접근통제·감사 로그 관리 정책 수립 및 이행• ISMS, 개인정보보호법 등 관련 보안기준 충족을 위한 기술적 보호조치 수행4) 시스템 및 인프라 협업• 서버·스토리지·네트워크팀과 협업하여 데이터 흐름 및 시스템 연계 관리• IT부서 및 외부업체와 협업하여 DB 구조 설계, 데이터 모델링, 마이그레이션 지원5) 프로젝트 및 내부통제 지원• 신규 시스템 구축 시 DB 설계·성능검토 참여• ISMS 심사 및 보안감사 대응 자료 작성 및 기술 지원6) POS·매장 데이터 운영• POS 시스템 기능 개선 및 장애 대응, 매장 데이터 연동 관리.",‍** 이런 분을 찾고 있어요• 학력 : 대졸 이상 (전산·컴퓨터공학·정보시스템 등 관련 전공)• 경력 : 유관 경력 10년 내외 (과장급)• DB 운영 및 SQL 성능 개선 실무 경험자• POS 개발 또는 매장 시스템 운영 경험.,"• * 이런 분이면 더 좋아요• 외식프랜차이즈/이커머스(F&B,리테일) 업계 IT 경험자• AWS RDS, Aurora 등 클라우드 DB 경험자• OCP, SQLP 등 관련 자격증 보유자• ISMS 또는 ISO27001 인증 대응 경험자."
현대오토에버,• 대규모 인프라 환경에서의 구성 관리 도구를 활용한 서버 자동화 및 관리• 모니터링 가능한 웹 기반 플랫폼 개발을 통한 인프라 관리 솔루션 구축.,"• Linux 환경에서 시스템 개발/운영 경험• 운영체제 (Linux, Windows) 및 네트워크 관련 지식• 플랫폼 운영 자동화, 모니터링 도구 개발, CI/CD환경 구축/운영 경험• Java, Go, Python등 개발 언어를 한 가지 이상 능숙하게 활용 가능하신 분• 구성 관리 도구 (예: SaltStack, Ansible, Puppet 등)에 대한 이해• 웹 개발 및 프론트엔드 기술에 대한 경험• 팀 내외에서의 원활한 커뮤니케이션 및 협업 능력• 문제 해결 및 새로운 기술에 대한 지속적인 학습 의지.","• RDBMS, NoSQL DB에 대한 이해 : MySQL, PostgreSQL, MongoDB 등• 대규모 인프라 관리 및 자동화 경험• 보안 및 규정 준수에 대한 이해• 대용량 로그 데이터 처리 및 분석 경험."
현대오토에버,• 국내/해외 경로탐색 서비스 모듈화를 통한 공용 라이브러리 개발• 프로젝트 전반의 사항들에 대하여 이해관계자들 간의 원활한 커뮤니케이션 진행.,"• C/C++ 개발• 리눅스 OS 상, 어플리케이션 모듈 개발.","• 내비게이션 길안내 서비스 또는 GIS 관련 개발 업무 진행 경험• 프로토콜 검토, 설계, 개발, 업무 수행 경험• C++ 객체지향 프로그래밍으로 양산 프로젝트 수행 경험• 리눅스 서버 환경에서 메모리, fileI/O 등 전반에 걸친 리소스 모니터링 가능자• 리눅스 서버 환경에서 동작하는 어플리케이션 라이브러리 개발 경험자 우대• 컴퓨터, SW 등 IT 관련 전공자."
큐빅,"• Python & FastAPI 기반 백엔드 서버 설계 및 개발• PostgreSQL/MySQL 등 관계형 데이터베이스의 스키마 설계 및 SQL 성능 최적화 수행• Redis, RabbitMQ 기반의 비동기 메시징/캐시 시스템 아키텍처 구축• RESTful API를 설계하고 문서화하며, 프론트엔드·AI팀과 연동 및 협업• 서비스 성능 개선, 장애 대응, 코드 품질 관리를 통해 안정적인 운영• Docker, Git, CI/CD 환경에서의 지속적인 배포 및 버전 관리 체계 운영.","• 서버 개발 경력 5년 이상, Python 기반 웹 서비스 운영 경험• FastAPI 프레임워크를 활용한 API 서버 설계 및 개발 경험• PostgreSQL, MySQL 등 RDBMS에 대한 깊은 이해와 SQL 최적화 능력• Redis, RabbitMQ 등 캐시 및 메시징 시스템을 활용한 비동기 처리 경험• Git 기반의 협업 및 코드 리뷰 경험• 기술 트렌드에 관심이 많고, 문제 해결에 적극적으로 임할 수 있는 분.","• SQLAlchemy ORM 기반 모델링 및 성능 최적화 경험이 있으신 분• AI 모델 서빙 환경 구성 또는 AI 서비스와의 연동 경험이 있으신 분• 대규모 트래픽 환경에서의 시스템 아키텍처 확장 및 운영 경험이 있으신 분• 단위 테스트/통합 테스트 코드 작성 및 자동화 테스트 환경(CI) 구축 경험이 있으신 분• 개인 프로젝트 운영, 오픈소스 기여 등 기술 커뮤니티 참여 경험이 있으신 분."
레브잇,"• 확장 가능한 MLOps 파이프라인을 구축하고 유지보수하는 것을 담당합니다.• MLflow, Airflow, Kubeflow 등 사내 ML 플랫폼을 구축하고 운영합니다.• Feature Store 운영 및 고도화를 수행합니다.• Milvus 기반의 Vector DB 운영 및 고도화를 수행합니다.• ML 플랫폼 전용의 Kubernetes 클러스터를 직접 운영합니다.• 필요 시 Python, Go, Java 언어 기반의 ML 애플리케이션 성능을 최적화 합니다.• MLOps 인프라의 SLA를 맞추기 위해 새로운 오픈소스나 솔루션을 검토하고 구축합니다.• DevOps/Data/DevsecOps Engineer 와 협업하여 MLOps 인프라 성능을 모니터링하고 최적화합니다.","• Kubernetes 위에서 서비스를 개발, 배포하고 운영해보신 분이 필요합니다.• 머신러닝에 대한 기본적인 지식이 있거나 Scikit-learn, Tensorflow, Pytorch 등과 같은 ML 관련 프레임워크를 사용해보신 분이 필요합니다.• Python, Go, Java 등 하나 이상의 프로그래밍 언어 활용 능력 및 소프트웨어 개발 역량이 있으신 분이 필요합니다.• Spark 등과 같은 기술을 이용해 데이터 배치 파이프라인의 구축, 개발 경험이 있으신 분이 필요합니다.• 탄탄한 CS(Computer Science) 기초 역량이 있으신 분이 필요합니다.[기술 스택]• Data Storage : S3, Iceberg, Kafka, Schema Registry, Elasticsearch• Database : Redis, Milvus, PostgreSQL, Scylla DB• Data Processing & Transformation : Spark, Flink, Kafka Streams, dbt• Application : Python(FastAPI), Go• CI/CD : Github Actions, ArgoCD• Orchestration : Kubernetes, Docker, Airflow, Kubeflow• Monitoring : Datadog, Grafana, Prometheus, Cloud Watch• AI 개발 툴 : Claude Code, Cursor, Copilot, ChatGPT 등.","• MLOps 관련 기술(MLflow, Airflow, Kubeflow 등)을 경험하고 실무에 적용해보신 경험이 있으신 분을 선호합니다.• Vector DB를 사용하거나 운영해보신 경험이 있으신 분을 선호합니다.• GPU를 사용하는 프레임워크를 이용해 개발해보신 경험이 있으신 분을 선호합니다.• 데이터 엔지니어링 또는 DevOps 또는 백엔드 개발 업무를 경험해 보신 분을 선호합니다.• AWS 기반의 인프라 구축, 개발 경험이 있으신 분을 선호합니다.• 대규모 트래픽 처리 경험이 있으신 분을 선호합니다.• AI 개발 툴 활용능력이 높은 분을 선호합니다."
패션앤스타일컴퍼니,"• 추천 시스템 백엔드 서비스 설계 및 개발• 서비스 및 인프라의 안정성, 확장성, 효율성 개선 및 유지/보수 업무 진행.","• 유관 업무 경험 5년 이상이신 분• Python / Java / Spring framework(Spring Boot) 개발 가능하신 분• Vector DB / RDBMS(MySQL 등) 쿼리 개발 가능하신 분• RESTful API 이해와 개발 경험이 있으신 분• Git/GitHub, Figma 등을 통한 협업 업무 경험이 있으신 분• 원활하게 협업할 수 있는 커뮤니케이션 역량을 보유하신 분• 코딩하는 것을 좋아하고 기술 향상을 위해 끊임없이 노력하시는 분.",• Vector 디비 및 LLM을 활용한 AI 서비스 개발 경험자 우대.
메이븐클라우드서비스,"• 고객사 DB구축 (Data Mart, Data Warehouse 등)• 데이터 모델링 및 추출• 솔루션 개발을 위한 아키텍쳐링• 프로세스 및 기능 컨설팅.",• Data flow Architecture 설계가 가능하신 분• ETL 파이프라인 구축 경험이 있으신 분• SQL Query 작성 및 Index 최적화가 가능하신 분• Stored Procedure in SQL Server 작성이 가능하신 분.,"• 정형/비정형 데이터 처리 경험이 있으신 분• Data Mart, Data Warehouse, Data Lake 구축/운영을 해보신 분• 데이터 표준화 및 품질관리 업무를 경험해 보신 분• Power BI 활용 경험이 있으신 분• R, Python, Pyspark Programming 경험이 있으신 분• 프로젝트 리딩(PM/PL) 경험이 있으신 분• Databricks, MS Fabric /Copilot / AI Foundry 유경험자• Azure 데이터 분석 및 통합 플랫폼 활용 경험자• Databricks 레이크하우스 플랫폼 활용 경험자• 클라우드 기반 데이터 엔지니어링 및 BI 플랫폼 활용 경험자• 프로젝트 요건 파악, 개발구축을 위한 업무 분석 등 경험이 있으신 분."
에이치에너지,"● OLAP 데이터 모델링: 다차원 데이터 분석을 위한 OLAP 스키마 설계 및 구축, 데이터 가공 처리● 데이터분석 및 보고서 작성: OLAP 데이터를 기반으로 분석 쿼리 작성, ML 분석, 분석 보고서 작성● 핵심 메타데이터 관리: 주요 메타데이터를 정의하고 관리 시스템을 구축 및 운영● 분석 서비스 개발: 데이터 분석 결과에 대한 서비스 개발.","• 대학교졸업(4년)이상• 관련 경력 3년 이상• 데이터베이스관련 전공 이수자• 데이터 거버넌스 이해: 데이터 표준화 및 메타데이터 관리의 중요성을 깊이 이해하고 있으며, 실제 적용 경험• 데이터베이스 시스템 이해: OLTP, OLAP 개념 이해 및 관련 시스템 활용 경험• OLTP 활용 경험: RDBMS, NoSQL, NewSQL 등 OLTP용 데이터 시스템의 이해 및 활용 경• OLAP 활용 경험: OLAP 개념 이해 및 관련 시스템 운영 경험, 데이터 분석용 스키마 작성 경험.","• 머신러닝 분석 경험: OLTP, OLAP 데이터로 부터 머신 러닝을 활용한 데이터 분석 경험• 클라우드 OLAP 시스템 경험: Google BigQuery, Snowflake 등 클라우드 시스템에서 OLAP 스키마 설계 및 구축 경험• Python 개발 경험: Python을 이용한 ETL 개발, Backend Service 개발 경험 • 클라우드 플랫폼 활용 경험: Google Cloud Platform, Amazon Web Service 등 클라우드 플랫폼을 활용하여 Serverless 개발, Backend 개발, Kubernetes 환경 사용 경험＜기술스택＞• 데이터베이스: MySQL,Google BigQuery• 운영체제: Linux• 부가 기술: Python Programming, Google Cloud Platform."
커넥트웨이브,"• 그룹사 전반의 Kafka 기반 실시간 데이터 스트리밍 플랫폼 구축 및 운영• 대용량 데이터 전송을 위한 Kafka 클러스터 설계 및 최적화• Kafka Connect, Kafka Streams 등을 활용한 CDC 파이프라인 개발• 전사 이벤트 기반 아키텍처 설계 및 구현• Kafka 모니터링 및 장애 대응, 데이터 유실 방지 체계 구축.","• 실시간 / 배치 파이프라인 설계 및 운영 경험• 데이터 품질 관리(DQ), 데이터 검증 및 모니터링 자동화 경험• Kafka 클러스터 설계 및 운영 경험• Kafka 기반 데이터 파이프라인 구축 및 최적화 경험• Kafka Connect, Streams, Schema Registry 활용 능력• 분산 시스템 및 컨테이너 환경(Docker, Kubernetes)에 대한 이해• Hadoop 기반 HDFS, Hive, Iceberg 등과 같은 데이터 레이크 구성 경험• Spark, Flink 등 분산 처리 프레임워크 활용 경험• Apache Airflow 등 Workflow 스케줄러 경험• 기술 공유와 협업을 중시하시는 분.","• 대용량 트래픽 환경 또는 대기업 Kafka 운영 경험 (3년 이상)• Kafka MirrorMaker, Schema Registry, Kafka Bridge 운영 경험• Apache Flink, Storm 등 스트리밍 처리 프레임워크 경험• Avro, JSON Schema 기반 스키마 설계 및 관리 경험• Elastic Stack, Prometheus, Grafana를 이용한 모니터링 경험• 데이터 거버넌스 및 품질 관리 시스템 설계 경험."
나무기술,"• OpenShift 기반 PaaS 설계 및 구축• OpenShift 솔루션 기술 지원(POC, BMT, 수주/제안 지원).","• 컨테이너, 쿠버네티스 관련 프로젝트 설계/구축 경험• 클라우드 서비스 구축/운영 경험• 경력 8년 ~ 12년 (과/차장급).","• OpenShift 관련 자격증(OpenShift Administrator 등) 보유자• 쿠버네티스 관련 자격증 (CKA, CKAD 등) 보유자• CI/CD(Jenkins, argoCD 등) 사용 경험."
비에이치에스엔,• Contract Lifecycle Management (CLM) / Business Agent 등 자사 서비스에 필요한 다양한 ML/AI 데이터 파이프라인 기능 개발 및 구축• 데이터 수집 및 정제를 위한 데이터 처리 기능 개발• ML/AI 서비스 로그 데이터 처리 기능 개발.,"• Python 개발 실무 경력 3년 이상 이거나 그에 준하는 역량을 보유하신 분• 웹 크롤러에 대한 이해 및 활용 경험이 있으신 분• 데이터 수집부터 서비스 적용까지 과정을 경험해 보신 분• MySQL / MongoDB 등 데이터베이스 활용에 익숙하신 분• Git, Docker 등을 이용한 코드 관리 및 배포에 익숙하신 분• GCP, AWS 등 클라우드 환경에서 데이터 파이프라인을 구축 및 운영해보신 분.",• 대용량 데이터 기반 서비스를 구축해보신 분• ElasticSearch 등 검색엔진에 관한 이해가 있으신 분• ML/AI 관련 프로젝트를 상용 서비스에 배포해보신 분• Kubernetes 상에서 인프라를 효율적으로 운영한 경험이 있는 분• MLOps 파이프라인 설계 경험이 있으신 분• 오픈소스에 기여해본 경험이 있으신 분.
비지트,• 회사 비전과 목표에 부합하는 기술 로드맵 설계 및 실행• 360 콘텐츠 활용 데이터 개발 및 최적화• 기업부설연구소 agile 기반 개발 프로세스 구축• 기술 협력 업체 및 파트너사 협업 관리.,"• 컴퓨터공학, SW엔지니어링 관련 석사 이상(Image Processing, Vision, 3D, AI 관련• AI 기반 영상처리 관련 개발 경력 및 높은 기술 이해• 데이터 처리와 분석에 대한 이해 및 활용• 360 콘텐츠 또는 AI 서비스 관련 데이터 처리와 시각화 경험• 실무자 간 원활한 소통과 협업 능력.",• 스타트업에서 개발 조직 리딩 • 팀 빌딩• 서비스 관련 운영.
쏘카(SOCAR),"[담당하시게 될 업무를 소개합니다]• Data ​Architecture ​환경 구축 - ERD, ​Data Profiling, ​MetaData ​관리방안 수립을 통한 ​표준 데이터 ​관리 체계 구축• 리버스 모델링 (쏘카 데이터 자산을 ERD를 통해 구조화) - 주요 시스템 리버스 모델링 데이터 표준 구축 전사 데이터 표준 수립 - Data Profiling ＞ 주요 속성 Value를 구조화• 데이터 표준 구축 및 메타데이터 관리 - 데이터 표준 구축 및 메타데이터 관리 체계 구축 및 운영 - AI/ML을 위한 비정형 데이터 표준화 및 관리 방안 수립• 데이터 모델링 및 DB 설계 표준 제공 - 주요 시스템별 DB 설계 표준 및 가이드 제공 - 서비스 구축/개편 시 데이터 표준화 작업 및 데이터 모델링(논리/물리) - 전사 개념 데이터 모델(데이터 맵) 구축.","[이런 분과 함께 성장하고 싶습니다]• 데이터 아키텍처 또는 데이터 모델링 실무 경력 (7년 이상)• 데이터 모델 현행화(리버스 모델링) 유 경험자(모빌리티, 커머스 경험 우대)• 데이터 품질관리, 표준화, 메타데이터 관리에 대한 이해 및 운영 경험 있으신분 • 적극적인 커뮤케이션과 데이터 Tracking등을 통해 주도적인 헙업이 가능한 분.","[이런 분이면 더욱 좋습니다]• DAP 등 데이터 아키텍쳐 관련 공인 자격 소지자• DA 솔루션(DA# 등) 운영 경험자• AWS 등 클라우드 기반 DA 설계 경력자[동료의 한마디]‍ • ""모빌리티 서비스를 데이터 관점에서 분석하고 개선해 볼수 있어요.""‍ • ""AX 전환을 위한 데이터 표준화 작업을 통하여 서비스내 AI 적용까지 경험해 볼수 있어요.""‍ • ""클라우드 업무 환경 기반으로 데이터 생성부터 추출, 활용의 전 분야에 대해 협업하고 성장할 수 있어요.""."
씨제이대한통운(CJ대한통운),"• AI/ML 플랫폼 인프라 구축 및 운영• AI/ML 분석 워크플로우 및 GenAI 인프라 중심의 AI 플랫폼 설계 및 구축• AWS 기반 클라우드 인프라의 설계, 구축 및 최적화• 운영 자동화 및 효율화• Infrastructure as Code(IaC) 기반의 운영 자동화 • 시스템 성능 분석 및 장애 예측을 위한 AIOps 전략 수립 및 실행.","• 클라우드 환경(AWS)에서 AI/ML 플랫폼을 구축 및 운영한 경험• 컨테이너 오케스트레이션(Kubernetes, EKS) 운영 및 최적화 경험.",• AIOps 및 운영 효율화를 위한 데이터 분석 경험• 대규모 트래픽을 처리하는 AI 플랫폼 운영 경험.
블루개러지(Blue Garage),"""Software Engineer -Full Stack"" 은 AI 아티스트와 팬들이 상호작용할 수 있는 신규 모바일 서비스의 개발을 담당하여, 프론트엔드와 백엔드의 설계, 구현, 배포 및 유지보수까지 모든 과정에 참여합니다. 다양한 팀과 협력하여 AI 모델과 데이터 분석 시스템을 긴밀히 통합하고, 서비스의 안정성과 성능을 지속적으로 개선합니다.• 크로스 플랫폼 모바일 어플리케이션의 프론트엔드 설계 및 구현 • 고성능, 고가용성의 백엔드 시스템 설계 및 개발• AI 모델 및 데이터 분석 시스템과의 효율적이고 안정적인 통합• 서비스의 품질과 성능을 지속적으로 모니터링하고 최적화.","• 3년 이상의 개발 경력, 또는 컴퓨터 공학 연관 전공 학위• 클라우드 환경(AWS, GCP 등) 기반 크로스 플랫폼 모바일 앱 개발/운영 경험• 확장 가능하고 유지보수가 용이한 DB 모델링 및 쿼리 최적화 경험• 트래픽 증가에 대응한 성능/비용 최적화 경험.","• AI/ML 기술이 포함된 제품 개발 경험• 엔터테인먼트/콘텐츠/SNS/게임 도메인의 제품 경험• 글로벌 서비스 개발 및 운영 경험• 제품 초기 기획부터 참여하여 구축, 운영, 모니터링까지 참여한 경험• 수동적 업무 수행보다는 항상 '왜?'에 대해 고민하고, 고품질의 코드를 위해 끊임없이 노력하시는 분."
메디컬에이아이,• 최신 생체신호 관련 AI 기술 논문 서베이를 통한 연구 동향 파악2. 생체신호 데이터를 활용한 질병 진단 AI 모델 개발 및 분석3. 논문 투고 및 학회 발표를 통한 사내 기술 역량 고도화· Deep Learning 을 활용한 ECG Delineation 연구 및 서비스 개발· Rule based & Deep Learning 을 활용한 ECG Digitization 연구 및 서비스 개발4. LLM 을 활용한 ECG 판독 서비스 설계 및 개발.,• PyTorch 등 딥러닝 프레임워크에 익숙하신 분2. 논리적 사고와 자유로운 의견 교류가 가능한 분3. 문제 해결을 위한 도전적인 태도를 지닌 분4. 협업과 원활한 커뮤니케이션을 중시하시는 분.,• 생체신호(Time-series) 데이터를 활용한 연구 또는 서비스 개발 경험2. LLM을 활용한 심전도 관련 연구 또는 서비스 개발 경험3. SCI급 저널 및 주요 국제 학회 논문 게재 경험4. 컴퓨터공학등 관련 분야 석사 이상 학위 보유자.
제논,"• 대용량 트래픽을 효율적이고 강건하게 처리할 수 있는 AI 서비스 배포• AI 서비스의 상태나 사용량을 모니터링 할 수 있는 시스템 개발• 멀티노드 환경에서 효율적으로 학습할 수 있는 파이프라인 구축• vLLM, SGLang, DeepSpeed, Triton 등의 오픈소스 프레임워크 지속 비교 및 활용• 데이터를 효율적으로 저장하고 가용성과 품질을 보장할 수 있도록 관리• ML 워크플로우 개선을 위한 도구 및 라이브러리 개발.","• LLM의 기본 동작 원리를 알고 기술 발전 흐름 설명 가능자• vLLM, SGLang, Triton, TensorRT, LightLLM 등 서빙 F/W 중 일부의 특징과 성능 비교 분석 경험• DeepSpeed, Megatron-LM, PyTorch Lightning, Horovod 등 학습 F/W 중 하나 이상을 전문적으로 사용해 본 경험• 자료구조, 네트워크에 대한 기본 지식 보유.","• 프로덕션 환경에서의 A/B 테스트 및 모델 검증 경험이• RAG 등 LLM 워크플로우 구성 경험• Docker, Kubernetes 등 컨테이너 기술을 전문적으로 활용한 경험 보유• 분산 시스템 및 대용량 데이터 처리 경험• 클라우드 환경에서의 AI 서비스 구축 및 운영 경험• MLOps 파이프라인 구축 경험• GPU 클러스터 관리 및 활용 경험• 다양한 오픈소스를 활용하거나 외부 서비스와의 연동 개발 경험."
코너스톤파트너스디지털,"[Job Description]• 데이터 분석가와 Business 컨설턴트로 이루어진 팀 단위 프로젝트 수행• 고객/매출 및 제조/공정 등 고객사 현황 분석을 통한 인사이트 도출 및 문제정의• Business 및 데이터 분석 인사이트 기반 문제 해결 (프로세스 개선, 경영진/현업 의사결정 지원) • 분석 결과 활용, 고객 업무 Digital Transformation 위한 Process Re-design• 고객사 업무 적용 위한 분석 모델 설계 및 개발.","• Python 기반 머신러닝 / 딥러닝 모델 개발 가능한 분• SQL / Phython 기반 데이터 모델링 / 엔지니어링 가능한 분• Cloud 환경 (AWS, MS AZURE 등) 활용이 원활한 분• 논리적 사고 및 분석력 보유한 분• Full-time 근무 가능한 분• 지방 및 해외 출장 가능한 분.","• 제조업 및 SCM 오퍼레이션 관련 경험/ 이해 역량 보유한 분• 통계, ML/DL 이해 및 모델 설계 경험• Microsoft office 활용 역량 보유한 분."
미리디,"""미리디에서 이런 일들을 함께 하고 싶어요""• 미리디의 다양한 포멧의 원천 데이터를 효율적으로 수집할 수 있는 확장성 있는 배치 및 실시간 데이터 파이프라인을 구축합니다.• 미리디의 데이터 거버넌스 시스템을 구축하고, 정책을 정의하여 운영합니다.• 미리디의 모든 서비스와 프로세스에서 생성되는 기술 및 비지니스 메타데이터를 중앙화하고, 제공하는 환경을 구축합니다.• 신뢰도 높은 데이터 인프라와 데이터 품질을 보장하기 위한 검증도구를 개발합니다.• 데이터를 활용하는 모든 미리디 서비스의 고객 가치를 향상시키기 위한 데이터 서비스를 설계하고 개발합니다.","""이런 분이라면 목표 달성에 확신을 얻을 것 같아요""• 경력 5년 ~ 10년 사이의 유관 경력 혹은 이에 준하는 역량을 갖추고 계신 분• 자료구조, 알고리즘, OS, 네트워크, 데이터 베이스에 대한 충분한 CS 지식과 이해를 갖고 계신 분• 데이터 수집, 변환, 저장을 위한 데이터 파이프라인을 직접 개발하고 운영한 경험을 갖고 계신 분• Python, SQL 및 Java/Kotiln/Scala 등 JVM 기반 개발 언어 활용이 가능하신 분• Hadoop과 RDBMS를 포함한 다양한 데이터 스토리지에 대한 기본적인 이해가 있으신 분• AWS 클라우드 환경 내의 데이터 인프라 구축과 운영을 위한 기본적인 지식과 이해를 갖고 계신 분.","""이런 분이라면 장기적으로 서로에게 더 긍정적일 것 같아요!""• Databricks 기반 데이터 플랫폼을 직접 운영하고 적극 활용한 경험이 있으신 분• Delta Lake, Iceberg, Hudi와 같은 Lakehouse 스토리지 기술에 대한 경험이 있으신 분• 카프카를 활용한 실시간 스트리밍 어플리케이션 개발 경험이 있으신 분• DBT 기반의 데이터 트랜스폼 환경에 대한 구축, 개발, 운영 경험을 갖고 계신 분• Kubernetes 클러스터 기반으로 데이터 플랫폼과 인프라 운영을 해보신 경험이 있으신 분• 데이터 관련 최신 도구와 다양한 개발 언어에 대해서 적극적으로 학습하며, 실무 도입과 활용에 적극적이신 분 | 미리디 DE팀 활용 기술 스택• Python, SQL, Java• Databricks, Athena, AWS MSK• Apache Airflow, Apache Spark, DBT • Datahub."
앰버로드,• 제조분야 모델 관리 솔루션 개발• 고객사 솔루션 적용 및 기술 영업 지원• SaaS 기반 Product Release.,• 5년 이상 경력 및 그에 준하는 실력이신 분을 원해요.• python3.8 이상/FastAPI 기반 개발 경험을 보유하신 분을 원해요.* MLOps 개발 (MLFlow 등) 경험을 보유하신 분을 원해요.• REST API 및 RDBMS 기반의 웹애플리케이션 설계/개발/운영 경험을 보유하신 분을 원해요.• 제조업의 새로운 기술적 변화와 혁신을 초기단계부터 함께 이끌어나고 싶으신 분을 원해요.• 다른 직군과 함께 문제를 정의하고 해결책을 찾을 수 있는 분• 남성의 경우 군필.,"• Micro Service Architecture를 이해하고 있고 서비스 설계 및 운영 경험을 보유하신 분이면 좋아요.• Redis, Kafka 등을 활용한 개발/운영 경험이 있으신 분이면 좋아요.* k8s, AWS 등의 인프라 환경에서 개발/운영 경험이 있으신 분이면 좋아요.* 데이터 파이프라인 개발 (Airflow 등) 경험 경험이 있으면 좋아요.* 모니터링 시스템 개발 (Grafana 등) 경험이 있으면 좋아요.• Agile / Scrum team 에서의 개발 경험이 있으신 분이면 좋아요.• CI/CD 기반 제품 Release 경험이 있으면 좋아요.• 제조업에서 기술혁신을 주도한 경험이 있으신 분이면 좋아요."
쿠팡,"• Andon 채널별 KPI 달성률 포함 전체 데이터 품질을 관리하고, 정확한 데이터 기반 운영 보장• Andon Performance Metrics 분석을 통해 인사이트 도출 및 실행 가능한 액션 아이템 제안• 정의된 비즈니스 문제를 데이터 기반 문제로 전환하고, 분석을 통해 해결 방안 제시• 복잡한 데이터를 시각화 도구로 표현하고, 분석 결과를 이해관계자에게 명확히 전달• 내부 이해관계자 및 주니어 분석가와의 협업을 통해 전략적 의사결정을 지원하는 데이터 인사이트 제공• 효율적인 쿼리 작성 및 데이터 변환 로직 구현을 통해 안정적인 데이터 운영 지원• Presto, Airflow 등 도구를 활용한 대규모 데이터 파이프라인 설계 및 최적화.","• SQL 및 데이터 엔지니어링 경력 7년 이상을 보유하고, SQL을 비롯한 데이터 처리 기술 숙련도가 높아 효율적인 쿼리 및 변환 로직 작성이 가능한 분• 데이터 시각화 도구 및 기법에 대한 이해를 보유하고 복잡한 데이터를 효과적으로 표현 가능한 분• 데이터 검증 역량을 기반으로 데이터 결함 식별 및 품질 이슈 해결이 가능한 분• 비정형 문제에 대한 비판적 사고 및 문제 해결 능력을 보유하고 불완전하거나 모호한 요구사항 처리가 가능한 분• 빠르게 변화하는 환경에서 독립적으로 업무 수행이 가능하며 책임감 있고 판단력 있는 태도를 보유한 분.","• 컴퓨터공학, 통계학, 산업공학 등 관련 분야 학사 또는 석사 학위를 보유한 분• Python, R 등 데이터 처리 도구 실무 경험, 자동화 스크립트 및 분석 도구 활용이 원만한 분• 이커머스 또는 물류 산업 경험, 고객 경험 관련 비즈니스 프로세스 및 과제 이해도가 높은 분• 단순 구현을 넘어 비즈니스적 의미를 해석할 수 있는 데이터 분석 역량을 보유한 분• 애자일 개발 환경 경험, 우선순위 및 요구사항 변화에 유연하게 대응 가능한 분."
코넥시오에이치,"• *AI 기반 온톨로지 생성 시스템 개발 (핵심 업무)**• Legacy 비구조화/반구조화 데이터베이스를 온톨로지로 자동 변환하는 AI 파이프라인 구축**온톨로지 설계 및 구축**• AI가 생성한 온톨로지의 검증 및 품질 개선 시스템 구축• 자동 생성된 엔티티 관계의 정확성 검증 및 보정**지식 그래프 엔지니어링**• Neo4j, Amazon Neptune, Apache Jena 등 그래프 데이터베이스 운영• 그래프 쿼리 최적화 (SPARQL, Cypher)**LLM 통합 및 최적화**• LLM 학습 데이터를 위한 구조화된 지식 변환• RAG(Retrieval-Augmented Generation) 시스템용 벡터 임베딩 최적화**데이터 파이프라인 개발**• LLM 기반 텍스트에서 지식 구조 자동 추출 시스템 구축.","• *학력 및 경력**• 컴퓨터공학, 데이터사이언스, 정보학 관련 석사 혹은 박사 이상(전문연 요건)• 온톨로지 엔지니어링 또는 지식 그래프 관련 경험• LLM/NLP 프로젝트 경험 **기술 역량**• AI/ML 모델링: 온톨로지 생성을 위한 Transformer, Graph Neural Networks, 지식 그래프 임베딩 모델 활용• 자동화 기술: LLM 기반 엔티티 추출, 관계 식별, 온톨로지 추론 시스템 구축 능력• 시맨틱 웹 기술• 그래프 데이터베이스: Neo4j, Amazon Neptune, ArangoDB 운영 경험• 프로그래밍: Python, Java, Scala 중 2개 이상 + TensorFlow/PyTorch 활용.",• *학력**• 박사 학위 소지자 우대**인증 및 자격**• 관련 분야 논문 발표 또는 오픈소스 기여 경험.
현대오토에버,"• 클라우드 마이그레이션 표준 거버넌스 수립• 자산관리 표준화 : 자산관리대장 표준화, 비용관리 표준화• 분석관리 표준화 : 마이그레이션 Assessment 표준 방법론• 전환관리 표준화 : 마이그레이션 전략 및 방법론 표준화• 인력산정 표준화 : 마이그레이션 투입 공수 표준화 (※ Mig 물량에 따라 투입되는 인력산정)• 아키텍처 표준화 : 마이그레이션 아키텍처의 표준화• 클라우드 마이그레이션 전환 리딩• 클라우드 마이그레이션 Assessment• 클라우드 마이그레이션 전환 리딩.",• 클라우드 업무 경력 5년 이상• 서비스 아키텍처의 이해 및 아키텍처 작성 능력• 클라우드 마이그레이션 수행경험 보유• 클라우드 및 표준화에 대한 거버넌스 문서작성 능력• 타 업무 부서와의 원할한 의사소통 능력• 클라우드 마이그레이션 방법론에 대한 이해.,"• 클라우드(퍼블릭, 프라이빗) 연관 자격증• AWS 관련된 Certi 보유."
현대오토에버,• 현대차(울산) 스마트태그 운영시스템 개발 및 운영• * 스마트태그 : 차량 및 설비(공구)의 실시간 위치 추적 및 품질 데이터 통신으로 스마트팩토리의 기반 데이터 마련.,"• 응용프로그램 개발(Java Spring 또는 C#) 경험• RDBMS(Oracle/Tibero/MySQL 중 1개 이상) 경험• 센서/RFID 연동 시스템 개발/운영• 설비, 단말, 시스템 간 인터페이스 경험(PLC통신, Socket통신, EAI통신 등).","• 제조 비즈니스에 대한 이해• 컴퓨터, SW 등 IT관련 전공자• Unity 3D 기반 서비스 개발 경험• MES 및 제조 관련 IT 시스템 개발/운영 경험."
씨드로닉스,"• 인공지능 학습용 카메라 데이터 관리 : 카메라 이미지 기반 학습용 BBox 가공 데이터셋의 전반적인 생성 및 관리 : 데이터 가공 전략 수립 및 실행, 가공 작업 실행 및 품질 관리.","• Bbox 가공 및 관리 경험 최소 2년 이상 경력 필수· 데이터 가공 프로젝트의 전체 프로세스 경험(일정,예산,품질관리)· python 코드를 활용한 가공 툴 또는 json 산출물 관리 경험.",(우대) 인공지능용 학습데이터의 흐름에 대한 이해를 바탕으로 작업 및 관리할 수 있는 분(우대) 다양한 데이터를 응용하여 논리적인 결론을 도출해낼 수 있는 분(우대) 주도적으로 탐구하여 업무를 진행할 수 있는 분.
인포유앤컴퍼니,• Power BI를 이용한 분석 보고서 개발• 데이터의 기본 이해를 통한 모델 설계 및 개발• 고객사 상주 운영 업무 또는 프로젝트 수행.,"• Tableau, Power BI 등 시각화 개발 2년차• 데이터에 대한 이해도.",• Public Cloud 경험이 있으신 분• ERP System 개발/운용 경험이 있으신 분.
인포유앤컴퍼니,"• 고객사 요구사항 기반 AI/LLM 솔루션 설계 및 개발 • Azure OpenAI, LangGraph 등을 활용한 백엔드 개발 • 클라우드 서비스(Azure, AWS, GCP 등)를 활용한 아키텍처 설계.","• 백엔드 개발 경력 5년 이상 • FastAPI 또는 Django를 활용한 Production 레벨 API 설계, 개발 및 운영 경험 • PostgreSQL, MSSQL, MongoDB 등 데이터베이스 설계 및 연동 경험 • 상용 LLM 서비스(Claude, OpenAI 등) 기반 AI 에이전트 시스템 연동 경험 • AWS, GCP, Azure 중 1개 이상의 클라우드 아키텍처 구성 및 운영 경험 • Git 기반 협업 및 코드 리뷰 경험 • AI Coding Assistant(Claude Code, Cursor 등) 실무 활용 경험 • 요구사항을 기술 문서로 구체화하고 효과적으로 커뮤니케이션하는 능력.","• AI Coding Assistant의 한계를 이해하고 적절히 활용할 수 있는 분 • 확장 가능하고 유지보수 용이한 코드 구조 설계 능력 • RAG, Vector DB, Embedding 최적화 경험 • CI/CD 파이프라인 구축 및 운영 경험 • 컴퓨터 공학 혹은 그에 준하는 관련 분야 전공자 • 프로젝트 리딩 또는 주니어 개발자 멘토링 경험."
휴머스온,"• 빅데이터(Hadoop) 플랫폼 구축 및 데이터 파이프라인 설계·운영ㄴ대용량 데이터 처리를 위한 ETL 프로세스 개발 및 효율화• 회사 내부 데이터 수집 및 빅쿼리(BigQuery) 기반 데이터 관리 ㄴ데이터 전처리, 적재, 추출 프로세스 관리 및 최적화• 데이터 품질 관리 및 데이터 소스 안정성 향상 ㄴ데이터 기반 서비스 제공을 위한 데이터 인프라 운영 관리.","• 데이터 엔지니어링 관련 업무 경력 3년 이상• Hadoop 기반의 대용량 데이터 플랫폼 구축 및 운영 경험 필수• BigQuery 사용 경험 및 데이터 파이프라인 설계·운영 역량 필수• Spark, Hive, Impala를 이용한 실시간 데이터 처리 경험• Kafka, Redis, ELK Stack 등 데이터 파이프라인 구축 및 운영 경험• ETL 프로세스 개발 및 관리 경험 필수.","• ML-Ops 환경(Kubernetes, Kubeflow) 관리 및 운영 경험자• Python 기반의 데이터 모델 개발 경험이 있는 분• 머신러닝 분야에 대한 경험 및 관심이 높은 분• Airflow 등 데이터 워크플로 플랫폼 구축·운영 경험자[이런 분과 함께하고 싶습니다]• 책임감 있고 능동적으로 데이터 문제를 해결하는 분• 데이터 기술에 대한 지속적인 학습과 자기 계발 의지가 강한 분• 커뮤니케이션 능력이 뛰어나며 동료와의 협업을 중요시하는 분• 복잡한 문제에 대해 창의적이고 주도적인 해결책을 제시하는 분."
럭스로보(LUXROBO),"• 부품 스펙, 회로도, PCB Gerber/ODB++ 등 EDA 데이터베이스 설계·운영• 다양한 포맷(Altium, OrCAD, PADS, KiCAD 등) 데이터 정규화 자동화• 부품 데이터시트, 회로, PCB 데이터 세트 신뢰도 검증, 품질 관리, 메타데이터 정책 수립• 데이터 파이프라인 배포·DB Admin Web 개발 및 버전 관리.","• 데이터/소프트웨어 엔지니어 경력 5년 이상• 전기/전자 공학 관련 학업 경력(학사 이상)• Python 기반 Web 개발(Flask, FestAPI 등) 경험• RDB·NoSQL 설계 및 대용량 파이프라인 구축 경험• 복잡한 도메인 데이터를 정형·비정형으로 모델링한 경험.",• EDA 파일 구조 이해 또는 CAD-CAM 데이터 경험• BOM·PLM 시스템 구축 경험• 전자·컴퓨터공학 석·박사 학위 또는 관련 논문·특허 보유.
디셈버앤컴퍼니(핀트),"[다음의 업무를 통해 함께 변화와 혁신을 이끌어갑니다.]• 고객 데이터 및 서비스 현황을 분석해요. - 로그 베이스 환경에서의 사용자 데이터 정제 및 수학/통계 또는 AI/ML 기반 분석 모델링 - 고객/서비스 현황 기술, 상관 분석, 계량 모델링 및 시각화 - 전사 주요 지표 정의 및 비즈니스 대시보드 제작 • 서비스 기획 및 전략에 참여해요 - 핀트 서비스/마케팅 성과 및 효과 분석 (Causal Inference, Regression Test) - 협력 부서의 전략적 의사결정을 위한 데이터 기반 인사이트 도출 - 서비스 내 Pain point 분석 및 개선안 제시.","[다음의 경험이 있는 분을 찾습니다.]• DBMS 환경에서의 SQL(HiveSQL, MySQL 등) 등 추출 언어를 능숙하게 사용 가능하신 분이면 좋겠어요.• R, Python (Pandas, Numpy, statsmodels, Scikit-learn) 등의 데이터 분석 언어를 1개 이상 능숙하게 사용 가능하신 분이면 좋겠어요.• 금융 소비자의 입장과 불편함을 잘 이해하고 적극적으로 개선하려는 의지를 가진 분• 주도적으로 자신의 일을 찾아 문제를 해결 및 개선할 수 있는 분이면 좋겠어요.• 논리적인 사고 능력 및 뛰어난 의사소통 능력이 있으신 분이면 좋겠어요.• 회사에 기여하려는 마음가짐이 있으신 분을 찾고 있습니다.• 수학적/통계적 지식과 높은 수준의 논리적 사고 및 문제 해결 능력이 있으신 분이면 좋겠어요.• 실질적인 action, 의사결정을 위한 구체적인 인사이트를 제공할 수 있는 비즈니스/서비스 관련 통찰력과 분석 능력이 있으신 분이면 좋겠어요.","[다음의 경험이 있으면 더 좋습니다. (앞으로 이런 업무를 통해 성장할 수 있습니다)]• Tableau, Google Data Studio, Redash 등 Business Intelligence 툴 활용 경험이 있으신 분이면 더 좋아요.• Hadoop, Spark 환경에서 대용량 데이터 분석 경험이 있으신 분이면 더 좋아요.• 통계, 머신 러닝, 딥 러닝 관련 분야 (통계학, 컴퓨터공학, 수학, 산업공학, 계량경제학 등) 석사 이상 학위 또는 그에 준하는 경험을 가지고 계신 분이면 더 좋아요.• 핀테크, 앱 서비스에 대한 경험 및 머신러닝/딥러닝 관련 업무 경험을 가지고 계신 분이면 더 좋아요.• Causal inference 관점에서 RCT 및 quasi-experiment 경험을 가지고 계신 분이면 더 좋아요.• 경제학, 예측 모델링, 머신러닝 관련 논문을 이해하고 직접 구현 및 적용해 본 경험이 있으면 더 좋아요.• 이력서 작성 시, 그동안 진행했던 프로젝트 중 임팩트 있었던 내용을 구체적으로 포함시키는 것을 추천해요. - AI/ML 또는 통계 기반으로 문제를 해결했다면, 문제 정의부터 적용 및 검증 과정을 적어주시면 좋겠어요. - A/B 테스트를 진행했다면, 실험 설계 및 검증-결과의 활용 과정이 드러나면 좋겠어요."
워트인텔리전스,글로벌 특허 검색엔진을 운영하고 있는 키워트(keywert) 서비스의 검색엔진 설계/개발/운영 업무를 담당합니다.• 검색 레거시 시스템 고도화• 검색엔진 설계/개발/운영• 신규 서비스의 검색 기능을 요구하는 프로젝트 참여.,"• ElasticSearch, OpenSearch, 또는 Solr 운영 경험을 보유하신 분• 대용량 검색 시스템에 대한 경험이 있으신 분• 한국어 및 다국어 형태소 분석기 개발/운영 경험이 있으신 분• 형태소 분석 오류 탐지 및 교정, 형태소 사전 운영에 대한 경험을 보유하신 분• Python, Java 에 능숙하신 분.",• 검색 파라미터를 벤치마크 및 데이터에 근거하여 최적화한 경험을 보유하신 분• 대규모 레거시 시스템을 리팩토링하여 개선한 경험이 있으신 분• Heavy 검색 쿼리 및 대규모 쿼리의 최적화 경험을 보유하신 분.
클럼엘,"데이터 소프트웨어, 즉 AI 엔진이 데이터를 분석할 수 있도록 데이터 플랫폼을 만들고, 데이터 분석 결과를 추가적으로 처리하여 고객에게 전달할 수 있도록 하는 것이 프로덕트 소프트웨어 엔지니어의 몫입니다. 프로덕트 엔지니어는 주로 백 엔드를 다루지만 프론트 엔드도 일정 부분 관여할 수 있습니다. 백 엔드 개발자가 프론트 엔드에도 어느 정도 기여함으로써 백 엔드의 문제 해결을 신속하게 프론트 엔드에 반영할 수 있다면 금상첨화입니다.클럼엘의 시니어 프로덕트 소프트웨어 엔지니어는 고객이 원하는 기능이 무엇인지를 이해하는 것부터 출발합니다. 철저히 사용자 관점에서 소프트웨어를 이해해야 하는데, 이를 위해서 회사 내의 여러 부서와 소통하게 됩니다. 고객의 목소리를 청취할 수도 있습니다. 기능에 대한 아이디어가 정립되면 이를 어떤 순서로 구현할 것인지 판단해야 합니다. 고객과 시장이 원하는 바를 만족시키면서 개발진의 수고도 덜 수 있는 묘안이 필요할 것입니다.프로덕트 소프트웨어 엔지니어의 업무 목록입니다.[빅데이터 플랫폼]• 빅데이터 수집 - 네트워크과 단말로부터 쏟아지는 대용량 데이터로부터 AI 머신러닝에 적합한 피처(feature)를 고성능으로 추출하는 모듈의 고도화• 빅데이터 저장 및 검색 - 하루 수 억에서 수 십억 건, 크기로는 수 TB에서 수 십 TB에 이르는 방대한 이벤트들을 실시간으로 저장하고 관리하는 NOSQL 기반 데이터베이스의 성능 고도화[AI 머신러닝 결과 처리]• 다양한 근거 제공 - AI 머신러닝의 결과를 사람이 쉽게 인지할 수 있도록 다양한 형태의 원천 데이터의 부대 정보와 통계 정보를 가공하는 기능 개발 - 다양한 외부 정보와 연동하는 기능 개발• Triage (선별) - AI 머신러닝 결과를 다양한 관점에서 신뢰도 평가하고 우선 순위에 따라 사용자에게 선별 제시하는 기능 개발 - 사용자 맞춤 선별 정책 설정 기능 개발[SaaS 서비스 개발]• AI 기반 보안의 SaaS 서비스 런칭 - 현재 On-premises로 구성되어 있는 제품 환경을 SaaS 환경으로 이식 - 피처 추출은 On-premises에서, AI 분석은 Cloud에서 구동되도록 플랫폼 전면 개발• SaaS 서비스를 위한 개발환경 및 운영환경 구축.","• 3년 이상의 업무경험을 보유하신 분• C++, C#, Java, Rust 중 1개 이상 코딩 경험이 있으신 분• 머신러닝 데이터 분석 경험이 있으신 분• Git 버전 관리 시스템 사용 경험이 있으신 분• RESTful 또는 GraphQL API를 활용한 프론트엔드 개발 경험이 있으신 분.",• Rust 개발 경험이 있으신 분• 보안 솔루션 기업 혹은 네트워크 보안 기업 경력을 보유하신 분• 클라우드 환경에서 업무 경험이 있으신 분• 컴퓨터 공학 및 유관학과 학사 이상의 학위를 소지하신 분.
디어유,"• 데이터베이스 아키텍쳐 수립 및 구축/운영• 데이터베이스 관리 및 모니터링• 데이터베이스 모델링, 품질, 표준 운영/관리• 데이터베이스 성능 관리 및 장애 대응 관리• AWS Aurora 운영 및 기술지원 담당.","• 5년 이상의 DBA 업무 경험• 대용량 트랜잭션 처리를 위한 DB 설계, 구축, 운영 경험 보유하신 분• MySQL(RDBMS) 운영 경험이 있으신 분• AWS Aurora(Cloud DB기술) 운영 경험이 있으신 분• 데이터베이스 Performance Tuning / SQL Tuning 가능하신 분• 데이터베이스 운영을 위한 자동화 스크립트(언어) 개발이 가능하신 분• 데이터베이스 Trouble shooting 가능하신 분.","• 플랫폼 서비스 DBA 경험이 있으신 분• Java, Python 등 프로그램 개발 가능하신 분• NoSQL 포함 다양한 데이터베이스 운영이 가능하신 분• 대량 트랜잭션 처리 경험이 있으신 분."
슈어소프트테크,• 자연어 기반 데이터 정규화 시스템 개발• python 기반 Multi-Agent 시스템 설계 및 구현• 자연어 데이터 분석 및 규칙/패턴 탐색• 정규화 결과의 DB화 및 RAG 파이프라인 설계.,• 관련분야 학사 학위 이상 취득자 (CS)• 경력 2년 이상 Python 개발 경력.,"• 복잡한 규모의 SW 설계/개발 경험• OpenSource SLM(sLLM) 활용 경험 (RAG, Agent)."
플랜바이테크놀로지스,"• Stable Diffusion 모델 기반의 이미지 생성형 AI 시스템 개발 및 최적화• B2B 엔터프라이즈를 대상으로 한 모델 파인튜닝, 커스터마이징• AI 모델의 성능 분석 및 개선• 최신 AI 기술 연구 및 빠른 적용.","[Education]• 학사 이상 (컴퓨터 공학, 전산학, AI 관련 분야 우대)[Experiences]• 이미지 생성형 AI 및 Stable Diffusion 모델 활용 경험• Python 및 딥러닝 프레임워크(TensorFlow, PyTorch) 사용 능력• AI 모델 파인튜닝 및 최적화 경험• 최신 AI 기술 트렌드를 빠르게 학습하고 적용할 수 있는 역량[Skill/ Knowledge]• 최신 기술을 빠르게 습득하고 적용하는 능력• AI 모델 개발 및 성능 최적화 역량• LLM을 활용한 다양한 프로젝트 경험• 문제 해결 능력과 원활한 커뮤니케이션 능력.",• 3D Gen-AI 관련 경험• LLM(대규모 언어 모델) 활용 경험• 연구 결과를 효과적으로 문서화하고 공유할 수 있는 능력• 창의적인 접근을 통해 문제를 해결할 수 있는 분.
핀다(FINDA),"핀다 DBA는 아키텍처를 구성하고 Database를 안정적으로 운영합니다.• 데이터베이스 분석, 설계, 구축, 운영• 데이터베이스 최적화(Tuning) 및 스키마 관리• 데이터베이스 성능 모니터링 및 장애에 대한 조치 시행• 데이터웨어하우스 설계 및 구축, 운영[핀다 DBA에서 사용하고 있는 기술]• AWS RDS, Aurora MySQL, RDS for MySQL, MongoDB.","• MYSQL DB 운영 경험이 있는 분• DB 성능 모니터링 및 개선에 대한 이해가 높으신 분• DB 보안, 백업에 대한 이해도가 높으신 분• DB Migration 경험 있으신 분• 여러 동료들과 적극적으로 소통하며 협업할 수 있는 분.","• 서비스 DB 설계 및 구축 경험 있는 분• 플랫폼 DB 운영, 아카이브 서비스 경험이 있는 분• AWS 환경에서 DB 운영 경험이 있는 분• SQL 튜닝을 경험해 보신 분• DB 장애 및 성능 이슈에 대응하고 해결할 수 있는 분• DB 모델링(논리, 물리, 표준화)을 경험해 보신 분."
웨이커,• 글로벌 증권 투자 의사결정에 필요한 정형/비정형/대체 데이터 수집 및 가공• Kafka + Python 기반 실시간/배치 데이터 파이프라인 설계·개발·운영• Python 기반 머신러닝 학습–서빙 End-to-End DataOps 파이프라인 구축 및 운영• 데이터 거버넌스 및 품질 관리 체계·플랫폼 개발.,"• Python을 장기간 메인 언어로 활용해온 경험- Kafka, Redis, PostgreSQL 등과 연계된 대규모 데이터 파이프라인 설계·개발 경험- 분산·병렬 처리 환경에서 Python을 활용한 최적화 경험• 리눅스 기반 환경에서 서비스 개발 및 운영 경험• 관련 분야 실무 경력 5년 이상• 해외 출장에 결격 사유가 없는 분.","• Kubernetes(k8s) 기반 Python 서비스 운영 경험• 증권 및 금융 데이터에 대한 이해와 관심• Docker 기반 운영 경험• 운영 중 발생한 장애를 Python으로 직접 분석·해결한 경험• Airflow, Jenkins 등으로 워크플로우 자동화 및 CI/CD 구축 경험• 실시간 고가용성 데이터 아키텍처를 Python으로 설계·적용한 경험."
휴이노,"• 서비스 데이터의 ETL(추출, 가공, 저장) 및 탐색적 데이터 분석(EDA) 업무, 이를 위한 시스템 도입 및 운영• MLOps 기반 모델 배포 시스템 및 대시보드 제작• HUINNO MEMO AI 서비스 개선점 도출, 데이터 활용 방안 논의[이런 분이 필요합니다.] • Data Literacy 역량을 갖추신 분• 협업과 설득에 능하고, 논리적으로 소통하며 경청하실 줄 아시는 분• 주도적으로 문제를 파악하고 질문·제안·해결에 적극적으로 파고드실 수 있는 분• 데이터를 꼼꼼히 다루며 신뢰도를 유지하는 데 신경 쓰시는 분• 작업 내용을 문서화하고 공유하는 데 익숙하신 분• 의료기기 인허가, 요양 급여(수가, 신의료기술)까지 의료기기 개발 전주기를 경험하고 싶으신 분.","• 컴퓨터공학, 전자공학 등 Data & Signal Processing 관련 분야 학위 또는 그에 준하는 경험과 지식을 갖추신 분• 데이터 과학, 데이터 엔지니어링, ML/DL 등 관련 분야 경력이 5년 이상이신 분• Python 활용 능력 및 Data science 관련 패키지 활용 능력을 갖추신 분• 데이터 파이프라인 도구를 활용해본 경험이 있으신 분.","• 데이터 또는 AI 관련 팀을 이끌어본 경험이 있거나, 팀을 동기부여 할 수 있으신 분• 심전도 및 바이오 센서 데이터 관련 프로젝트를 리딩 해본 경험이 있으신 분• 데이터 파이프라인을 직접 구축해본 경험이 있으신 분• 의료 통계 지식을 가지고 계신 분• 의학, 의과학, 의공학 등 의료 도메인 지식을 가지고 계신 분."
인터엑스,"• C#, .NET을 활용한 Windows 및 Web 소프트웨어 아키텍처 설계 및 구현 • Safety AI, Inspection AI 등 다양한 제조 AI Kit 기능 개발 및 유지보수 • 실시간 품질 관리 및 데이터 처리 시스템 개발 • PLC, Sensor, DB 데이터 수집 시스템 개발.","• C#, Winforms, WPF, ASP.NET, .NET Blazor 기반 소프트웨어 개발 경험이 풍부한 분 (5년 이상) • RDB, NoSQL 등 데이터베이스 경험이 풍부한 분 (5년 이상) • HTML, javascript, css 가능한 분 • 객체지향 프로그래밍(OOP)에 대한 깊은 이해가 있는 분 • 소프트웨어 설계 및 최적화 능력을 보유한 분 • 제조업 또는 산업용 소프트웨어 개발 경험이 있는 분 • 리눅스 사용, Docker 배포 경험이 있는 분.",• 제조업 관련 프로젝트 경험이 풍부한 분 • AI/머신러닝 관련 소프트웨어 개발 경험이 있는 분 • Python 개발 경험이 있는 분 • 실시간 데이터 처리 시스템 및 시각화 개발 경험이 있는 분.
이투스에듀,• 이투스에듀 전사 데이터베이스(DB) 운영 및 구축• 데이터베이스 운영 및 성능 관리• 데이터베이스 모니터링 및 장애 대응.,"• 학력: 무관• 경력: 3년 ~ 7년• RDBMS(MSSQL, PostgreSQL, MySQL 등) 중 1개 이상 운영 경험이 있으신 분 • RDBMS 운영에 대한 전반적인 지식.",• MSSQL 운영 경력 • 클라우드 환경(AWS 등)에서의 DB 운영 • SQL 튜닝 및 성능 개선 • 이기종 DB 간 데이터 이관 또는 연동 처리• 교육 플랫폼의 데이터 처리• 협업과 소통이 원활하신 분.
에이아이파크,"[AiVATAR 핵심 모델 개발 및 최적화]• 영상 및 음성 생성 모델 고도화, 최적화• Azure 환경에서 모델 학습 및 배포 인프라 구축• 영상 및 음성 생성 관련 최신 AI 기술 동향 분석 및 평가[신규 서비스 AI 기술 도입]• 서비스 혁신을 위한 신규 기술 검증 및 도입 지원• 언어모델(LLM)을 활용한 프롬프트 엔지니어링 및 최적화.","[자격요건]• 머신러닝 리서처 또는 엔지니어로 3년 이상 경력을 가진 분• 생성형 AI 모델(AI 영상, 음성 등)의 데이터 수집·전처리부터 모델 학습, 평가 및 서비스 배포까지 전체 사이클 경험하신 분[기술 스택]• 프로그래밍 언어: Python• 머신러닝 프레임워크: PyTorch, TensorFlow• 클라우드 환경: Microsoft Azure• 컨테이너 기술: Docker• 형상 관리: Git, GitHub.","• 머신러닝, 딥러닝 및 컴퓨터 비전에 관련된 논문을 빠르게 이해하고 적용해본 분• 컴퓨터 관련 전공자 수준의 개발 역량을 갖추신 분• 인공지능, 컴퓨터, 수학 등 관련 전공 석사 이상의 학위를 가진 분• 관련 분야 주요 학회 논문을 발표하신 분."
토스뱅크,[합류하면 함께할 업무예요]• 빠르게 성장하는 애자일조직에서의 효율적인 DW 환경을 경험하고 함께 만들어요.• 오픈소스솔루션 기반에서 DW Data Workflow를 개발하고 자동화 업무를 수행해요.• 메타데이터 자동수집과 같이 효율적이고 편리한 데이터 통합검색 Application 을 구축 & 운영해요.• 데이터 선후행 영향도 파악을 위한 Data Lineage Application 을 구축 & 운영해요.,"[이런 분과 함께하고 싶어요]• Hadoop-Ecosystem, Database, Data Warehouse 에 대한 기본적인 이해가 있으신 분이 필요해요.• SQL과 Python 에 대해 중급 이상의 기술역량을 보유하신 분이 필요해요.• 검색 용도 ElasticSearch나 OpenSearch 를 개발, 운영해본 경험이 있으면 좋아요• Backend 또는 Frontend 관련 개발 경험이 있으면 좋아요.• Data Governance, Data Catalog 관련 개발경험이 있으면 좋아요.• 데이터마트를 주도적으로 설계, 구축하고 운영한 경험이 있으면 좋아요.• Spark을 이용하여 빅데이터를 효율적으로 처리한 경험이 풍부하신 분을 기대해요.• Tableau 운영 및 트러블슈팅이 가능하신 분이면 좋아요.","[이력서는 이렇게 작성하시는 걸 추천해요]• 그동안 해오신 업무 중 임팩트 있었던 프로젝트를 구체적으로 적어주세요.• 특히 데이터마트를 주도적으로 설계 및 구축했던 경험을 구체적으로 적어주시면 좋아요.• 실제 서비스에 적용하여 개선한 경험이 있다면 결과를 수치로 나타내주면 좋아요.(외부 공개가 민감한 사항일 경우, 해당 부분은 제외해 주세요.)단순히 구축과 개발에서 끝나는 경험이 아닌 트러블슈팅 및 운영, 성과를 적어주시면 좋아요."
티웨이브,"• 데이터 파이프라인 구축 및 운영• ETL/ELT 설계·구현(DMS, Glue, Kafka, Kinesis), 데이터 품질 검증 및 모니터링 자동화• Redshift Serverless/Athena 기반 DWH 설계·최적화, S3 레이크 아키텍처 및 파티셔닝 전략• Airflow/EventBridge 오케스트레이션, Lambda/n8n 기반 자동화 워크플로우 구현• 데이터 모델링 및 변환• 비즈니스 요구사항 반영 분석용 데이터 마트 설계• dbt 또는 SQL 기반 변환 로직 개발, 쿼리 튜닝 및 성능 최적화• 데이터 계보(Lineage) 및 영향도 분석 체계 구축• 데이터 거버넌스 및 품질 관리• 데이터 정합성 검증(중복·누락·이상치), 품질 SLA 정의 및 모니터링• 데이터 카탈로그·메타데이터 관리, 표준·네이밍 컨벤션 정의• 정산 모니터링 및 이상 탐지 자동화 시스템 구축• 비즈니스 분석 및 인사이트 도출• 회원·거래·행동 데이터 기반 핵심 KPI 정의·분석, 정기 리포팅 자동화• 코호트·리텐션·퍼널 분석, 시계열 분석 및 트렌드 예측• 정산/채권, 리스크, 마케팅, 운영 도메인별 데이터 분석 및 의사결정 지원• BI 대시보드 구축 및 운영• QuickSight/Athena 기반 인터랙티브 대시보드 설계·구현• 부서별 맞춤형 대시보드 개발, 실시간/준실시간 대시보드 구축• 셀프서비스 분석 환경 구축, 분석 템플릿 및 표준 쿼리 라이브러리 제공• 데이터 문화 확산• SQL 기반 분석 표준 프레임워크 개발• 전사 데이터 리터러시 향상 프로그램 기획·운영, 가이드 문서 작성.","• 데이터 파이프라인 및 인프라• ETL/ELT 설계·구축·운영, SQL 고급 활용(복잡한 쿼리, 최적화, 튜닝)• Python 데이터 처리 및 자동화, AWS 데이터 스택(S3, Glue, DMS, Redshift, Athena)• 데이터 모델링(Star Schema, Snowflake Schema, Data Vault)2. 데이터 분석 및 인사이트• 비즈니스 데이터 분석 및 인사이트 도출, BI 툴 활용(QuickSight, Tableau, Power BI)• 통계적 사고력, 데이터 기반 의사결정 지원, 비즈니스 문제를 데이터 문제로 번역3. 비즈니스 역량• 명확한 데이터 구조 디자인 및 비즈니스 개념 정의• 다양한 이해관계자(비즈니스, 개발, 운영)와 원활한 커뮤니케이션• 분석 결과를 비전문가에게 명확히 전달, 프로젝트 우선순위 설정4. 기본 자격• 학력: 통계학, 데이터사이언스, 컴퓨터공학, 산업공학 등 학사 이상(전공 무관, 실무 경험 우대)• 기술 문서 읽기 및 작성 가능한 영어 능력• 데이터 엔지니어링 또는 분석 실무 7년 이상(석/박사 3년 이상)• 이 중 데이터 엔지니어링(DE)과 데이터 분석(DA) 업무를 모두 수행한 경험 필수.","• 핀테크/금융 도메인-정산·채권·대사(Reconciliation) 프로세스 이해-신용평가, 리스크 관리, 사기 탐지 경험-디지털뱅킹/마켓플레이스 등 대규모 트랜잭션 환경 경험2.고급 기술 스택-R 프로그래밍(dplyr, data.table), dbt(data build tool)-Kafka/Kinesis 실시간 스트리밍, Airflow/Prefect 오케스트레이션-IaC(Terraform, CloudFormation), Neptune/Neo4j 그래프 DB3.고급 분석 역량-A/B 테스트 설계 및 인과추론 분석(CUPED, Diff-in-Diff, Uplift Modeling)-코호트·리텐션·퍼널 분석 고급 기법, 시계열 분석·예측 모델링-데이터 시각화 및 스토리텔링4.마이그레이션 및 자동화-DB 마이그레이션(MySQL→클라우드 네이티브), 대규모 정합성 검증·회복 자동화-데이터 거버넌스 체계 수립·운영, 분석 표준 프레임워크 개발·배포5.문서화 및 표준화-기술 문서 작성 및 데이터 거버넌스 체계 수립-데이터 카탈로그·메타데이터 관리 시스템 구축."
에스씨솔루션글로벌,• 데이터 보안 및 시스템 관리• 대외 기술 협의 및 교류• IoT 센서로부터 수집된 데이터 분석• 오픈소스를 활용한 머신러닝 모델 개발.,• 나이/ 성별: 무관• 경력: 1년이상 우대 (신입 가능)• 학력: 대졸 이상.,• 관련 직종 유경험자• 전지/ 전자 관련 전공자 우대• 1년이상 경력자 우대.
페이타랩(패스오더),"• 마케팅 또는 프로덕트 성과 측정을 위해 데이터 추출·가공·시각화까지 이어지는 데이터 파이프라인을 설계 및 구축해요.• KPI 및 연관 지표들을 명확히 정의하고, 전사적인 지표 관리 체계를 확립해요.• 사용자 행동 데이터 분석을 통해 심층적인 인사이트를 도출하고, 이를 바탕으로 패스오더 퍼널 전환율을 개선해요.• 데이터 분석 결과를 기반으로 도출한 솔루션의 기대효과를 예측하고, A/B 테스트와 후속 성과 측정을 통해 실제 비즈니스 임팩트를 측정해요.• 구성원이 데이터를 기반으로 심층적인 인사이트를 도출하고 의사 결정할 수 있도록 Data-Driven 환경을 만들어요.","• 비즈니스 목적에 맞는 데이터 파이프라인(ELT/ETL)을 설계 및 구축한 경험이 있는 분• SQL과 Python을 활용해 대용량 데이터를 추출• 정제• 가공• 분석할 수 있는 분• 모바일 서비스의 고객 행동 분석(Retention, Cohort, 세그먼트)과 마케팅 효율 지표(CAC, ROAS, ROI) 분석에 대한 이해가 있는 분• 문제정의 ＞ 가설수립 ＞ 실험설계(A/B 테스트) ＞ 성과측정 ＞ 개선으로 이어지는 실험 사이클을 직접 수행한 경험이 있는 분.","• 2년 이상의 마케팅/프로덕트 데이터 분석 혹은 데이터 엔지니어링 실무 경력이 있는 분• 빠르게 성장하는 IT 스타트업 환경, 특히 O2O·모바일 앱·식음료 도메인에서 근무한 경험이 있 분• BigQuery 등 클라우드 기반의 대용량 분석 환경에서 데이터 마트를 설계한 경험이 있는 분• 머신러닝 모델 학습 및 서빙을 위해 데이터 파이프라인을 구축 및 자동화한 경험이 있는 분• AI 툴을 활용해 리서치, 코드 생성, 리포팅 자동화 등 업무를 효율화한 경험이 있는 분• 조직 내 Data-Driven 문화 확산 및 데이터 리터러시 증대에 기여한 경험이 있는 분."
앰버로드,• 제조분야 분석 솔루션 적용• 영업 지원 및 Pre-Sales• 프로젝트 관리• 고객 요구사항 분석 및 솔루션 커스터마이징.,"• PM/PL 경험, • 제품 개발 및 고객사 적용 경험• 데이터 분석 솔루션 개발 경험• MLOps 구축 경험 및 Python • 다른 직군과 함께 문제를 정의하고 해결책을 찾을 수 있는 분• 남성의 경우 군필.",• 5년 이상 경력 및 그에 준하는 실력• Agile / Scrum team 에서의 개발 경험• CI/CD 기반 제품 Release 경험• 제조업 데이터 활용 경험.
무신사,• 데이터 운영 효율성을 고려한 데이터 모델링 작업을 수행합니다.• 전사에서 사용할 공통 데이터 마트 및 핵심 지표를 설계하고 관리합니다.• 공통 데이터 마트와 핵심 지표 테이블의 데이터 품질을 점검하고 관리합니다.• 데이터 디스커버리 플랫폼을 개발 및 운영하며 전사의 데이터 접근성을 높입니다.,"• SQL, Python을 활용하여 복잡한 데이터를 추출하고 가공하는 데 능숙하신 분• 데이터 모델링에 대한 깊은 이해와 실제 프로젝트 적용 및 운영 경험이 있으신 분• 전사 공통으로 사용할 데이터 마트 및 핵심 지표 테이블을 설계, 구축, 유지보수한 경험이 있으신 분• Workflow manager(Airflow) 운영 경험이 있으신 분• Google Tag Manager(GTM), Google Analytics, Bigquery, Looker studio 활용 역량을 보유하신 분.","• 데이터 분석 실무 경험이 10년 이상 또는 그에 준하는 역량을 가지신 분• 로그 데이터를 설계부터 분석까지 로그데이터 관리한 경험이 있으신 분• Databricks 기반 데이터 웨어하우스 환경에서의 개발 경험이 있으신 분• Quicksight 등 BI Tool에 대한 이해도가 있으신 분• 데이터 디스커버리 플랫폼(Openmetadata, Datahub, Amundsen 등) 중 1개 이상의 운영 경험이 있으신 분• 데이터 파이프라인 구축 및 운영 경험이 있으신 분• 확장성과 안정성을 고려한 시스템 설계·고도화 경험이 있으신 분• 단위 테스트 코드를 작성하며 코드 품질을 높이는 데 관심이 있으신 분."
이노션,• 데이터 기반 프로젝트 기획 / 성과 분석 및 보고 / 관리• 데이터 분석 및 제언 • (Media - Web - CRM 연계 분석 및 비즈니스 액션 플랜 도출 )• 고객사 및 협업사와의 프로젝트 진행을 위한 커뮤니케이션 및 관리.,"• 전문학사 이상• 총 경력 1년 이상• 데이터 솔루션과 다양한 데이터소스의 결합 분석 경험이 있으신 분 • Google Analytics 4, Salesforce Marketing Cloud, Mobile Attribution Solution, etc• 분석 기획 및 결과 인사이트를 논리적으로 정리하고 전달할 수 있는 문서 작성 역량을 갖추신 분• 디지털 마케팅 기반의 데이터 프로젝트 경험(구축, 분석 등)이 있으신 분• 최종합격 후, 지정 입사일에 입사 가능하신 분• 해외 출장에 결격 사유가 없는 분 (남성의 경우, 회사가 지정한 입사일까지 병역을 마쳤거나 면제되신 분).","• 디지털 플랫폼(Web/App) 및 디지털 캠페인(퍼포먼스 광고 등)에 대한 이해도가 있으신 분• 데이터 기반 비즈니스 가치 정의 및 성과 도출 경험이 있으신 분• 고객사 및 다양한 협업 부서와 커뮤니케이션 한 경험이 있으신 분• 데이터 분석 툴 활용 경험이 있으신 분 (R, Python 등)• 데이터로 가설을 세우고 분석을 진행한 경험이 있으신 분."
한샘,"• DBMS((MYSQL, Oracle) 구축 및 운영• DB성능 모니터링 및 최적화• 장애 대응 및 문제 해결• DB 보안 관리 및 접근 제어.","• DBMS(MYSQL, Oracle) 운영 3년 이상 경험이 있으신 분• DB 성능 최적화(SQL, Index, Table 구조 개선) 경험이 있으신 분• OS 운영 경험 및 서버, 스토리지에 대한 지식을 보유하신 분• 팀 내외 협업 및 커뮤니케이션 능력이 뛰어나신 분* 경력기술서 제출 필수[공통사항]• 입사지원 후 3개월 내 입사 가능한 자• 병역 필 또는 면제자로 해외 여행에 결격 사유가 없는 자.",• AWS 등 클라우드 기반 DB 구축 및 운영 경험이 있으신 분• 이기종 DB Migration 경험이 있으신 분• 고가용성 시스템 구축에 대한 경험이 있거나 이해가 높으신 분• DB 접근 제어 솔루션 관리 경험이 있으신 분• 정보보호(개인정보) 관리체계 인증(ISMS) 경험이 있으신 분• 새로운 기술에 대한 도전적 마인드를 갖춘 분.
씨드앤,"[기술 스택]• AWS(EKS, ECS, EC2)• GitHub Actions, Jenkins, ArgoCD, Helm, Terraform• Prometheus, Grafana, Alloy, Loki, Tempo• MySQL, MongoDB, Redis, DynamoDB, MSK[주요 업무]• AWS 환경(EKS, ECS, EC2)에서 서비스를 구축, 운영 및 고도화• Prometheus, Loki, Tempo, Grafana를 통한 모니터링/로깅 시스템 구축, 운영 및 고도화• GitHub Actions/Jenkins, ArgoCD를 활용한 CI/CD 배포 파이프라인 구축, 운영 및 고도화• Infrastructure as Code 기반(Terraform)의 인프라 구성• 서비스 요건에 맞는 모니터링 및 장애 대응.",• 5년 이상의 DevOps 엔지니어 경력을 보유하신 분• AWS 기반의 인프라(EKS) 구성 및 서비스 운영 경험을 보유하신 분• IaC 및 CI/CD 솔루션 도입 및 운영 경험을 보유하신 분.,"• IoT 기반의 서비스 운영 경험을 보유하신 분• AWS Multi Account 환경에서의 운영 경험을 보유하신 분• MySQL, Redis, MongoDB 운영 경험을 보유하신 분• Istio를 활용한 네트워크 트래픽 모니터링 경험을 보유하신 분• On-premise 환경에서의 서비스 운영 경험을 보유하신 분• Python, Shell Script 등을 활용한 자동화 개발 경험을 보유하신 분• Sonarqube를 활용한 CI 파이프라인에서의 정적 코드 분석 경험을 보유하신 분• 최소 한 가지 이상의 프로그래밍 언어에 대한 기본적인 이해 및 경험을 보유하신 분• 새로운 기술 도입에 대한 거부감이 없으신 분."
앰버로드,• 제조분야 모델 관리 솔루션 개발• 고객사 솔루션 적용 및 기술 영업 지원• SaaS 기반 Product Release.,• 5년 이상 경력 및 그에 준하는 실력이신 분을 원해요.• python3.8 이상/FastAPI 기반 개발 경험을 보유하신 분을 원해요.* MLOps 개발 (MLFlow 등) 경험을 보유하신 분을 원해요.• REST API 및 RDBMS 기반의 웹애플리케이션 설계/개발/운영 경험을 보유하신 분을 원해요.• 제조업의 새로운 기술적 변화와 혁신을 초기단계부터 함께 이끌어나고 싶으신 분을 원해요.• 남성의 경우 군필.,"• Micro Service Architecture를 이해하고 있고 서비스 설계 및 운영 경험을 보유하신 분이면 좋아요.• Redis, Kafka 등을 활용한 개발/운영 경험이 있으신 분이면 좋아요.* k8s, AWS 등의 인프라 환경에서 개발/운영 경험이 있으신 분이면 좋아요.* 데이터 파이프라인 개발 (Airflow 등) 경험 경험이 있으면 좋아요.* 모니터링 시스템 개발 (Grafana 등) 경험이 있으면 좋아요.• Agile / Scrum team 에서의 개발 경험이 있으신 분이면 좋아요.• CI/CD 기반 제품 Release 경험이 있으면 좋아요.• 제조업에서 기술혁신을 주도한 경험이 있으신분이면 좋아요."
엑심베이,"• 클라우드 인프라 운영 및 자동화• AWS 기반 인프라 운영 및 구성 관리(EC2, RDS, S3, CloudFront 등)• Terraform/CloudFormation 등 IaC 도구를 활용한 배포 자동화• CI/CD 파이프라인 구축 및 운영 (GitLab Runner)• DataDog, ELK 등 모니터링/로깅 시스템 구축 및 운영2. 클라우드 보안 및 비용 최적화• AWS IAM, SCP, KMS 등 보안 정책 관리• 비용 분석 및 최적화 전략 수립.","• 라우드 인프라 운영 또는 DevOps 경력 7~15년• AWS 전반에 대한 이해 및 운영 경험자• IaC 도구 (Terraform, CloudFormation 등) 사용 경험자• CI/CD 및 자동화 파이프라인 구축 경험이 있는 분• 문제 해결력 및 커뮤니케이션 역량 보유자[전체 직무 공통 자격요건]• AI 업무 활용 필수• 데이터 분석 역량 필수.","• AWS 자격증 보유자 (예 : Solutions Architect, DevOps Engineer 등)• Kubernetes 및 ArgoCD 운영 경험자• 운영 및 인프라 구성 문서 등 문서 작성 능력이 우수한 분."
밀버스,"• Salesforce Data Cloud 기반 고객 데이터 통합 및 운영• 데이터 모델 설계 및 데이터 매핑, 품질 관리• 외부 채널/솔루션과의 데이터 연동 설계 및 운영• Salesforce 솔루션을 통한 CRM 비즈니스 서포트• Prep Builder 및 Python-Apache Airflow 기반 데이터 파이프라인 설계 · 구축 · 운영과 레거시 데이터 소스 연동을 위한 중계 서버 설계 및 운영.","• 유관 경력 3년 이상• Salesforce Data Cloud 프로젝트 수행 및 운영 경험이 있으신 분• SQL 활용 능력 및 데이터 처리/분석 역량을 보유하신 분- 데이터 모델링, 데이터 정합성 관리 및 대규모 데이터 처리 경험이 있으신 분• 마케팅, 세일즈, 서비스 등 Salesforce 솔루션과의 연계 이해도가 높으신 분• 원활한 커뮤니케이션 및 협업 역량을 보유하신 분.","• Salesforce 자격증을 보유하신 분• 데이터 관련 Tool 사용 경험을 보유하신 분(SQL, Python, Tableau 등)• CRM, DMP, CDP 등 고객 데이터 플랫폼 관련 실무 경험이 있으신 분• Prep Builder 및 Python-Apache Airflow를 활용한 데이터 파이프라인 구축/운영 및 레거시 데이터 소스 연동 경험이 있으신 분."
인포유앤컴퍼니,"• 요구사항 정의/범위 관리: 비즈니스 요구 수집·분석, PoC 범위 및 성공지표(acceptance criteria) 정의, 변경관리• 아키텍처·설계 리딩: Azure OpenAI, Azure AI Search, 데이터 소스(RDB/Blob/SharePoint), 보안/네트워크 정책을 반영한 RAG/Agent 아키텍처 수립• 프로젝트 관리: 일정/예산/리소스/리스크/이슈 관리, 대내외 커뮤니케이션, 벤더/파트너 협업(예: Microsoft)• 프리세일즈 지원: 제안서/데모/PoC 리드, ROI 산정, 라이선스/용량/비용 모델 설계• 운영 전환 및 고도화: 운영 Runbook, 모니터링(사용량·비용·정확도), A/B 테스트, 개선 백로그 관리.",• AI/데이터/소프트웨어 프로젝트 PM 경력 3년 이상 또는 대형 IT 프로젝트 PM 5년 이상(LLM·RAG 과업 포함)• 엔터프라이즈 환경에서의 요구사항 정의–WBS–일정/리스크 관리–UAT–운영전환 실무 경험• LLM/RAG 기본 원리와 프롬프트·에이전트·도구(툴) 실행 체계에 대한 이해• 클라우드(Azure 선호) 기반 API/백엔드/데이터 연동 이해 및 협업 능력• 명확한 커뮤니케이션/문서화/이해관계자 조율 능력.,"• Azure OpenAI/Azure AI Search/Azure Functions/DevOps 파이프라인 운영 경험• LangChain, Semantic Kernel, MCP, function/tool calling, Agents 이해 및 경험• RAG 품질개선(Hybrid Search, chunking/embedding 전략, reranking, grounding) 사례 보유• 보안·컴플라이언스(PII, DLP, 접근제어, 로그/Audit) 정책 설계/운영 경험."
오케스트로,"[IaaS 파트 업무]Expert팀 IaaS파트는 OpenStack 기반 클라우드 인프라를 설계·구축·운영하며, 기업 고객이 대규모 환경에서도 안정적이고 유연하게 서비스를 제공할 수 있도록 지원합니다.• 사내 클라우드 솔루션(Contrabass)의 기능과 성능 개선• Compute,Network,Storage 전반의 아키텍처 설계 및 운영• VM, 네트워크, 스토리지 관련 기능 테스트 및 성능 검증• OpenStack 신규 기능 및 구성 요소 PoC 수행 및 기술 검토• Ansible, Terraform을 활용한 설치·배포·운영 자동화• 장애 원인 분석 및 성능 개선을 통한 운영 안정성 확보[주요 업무]Expert팀 IaaS파트는 단순히 시스템을 운영하는 수준을 넘어, 클라우드 인프라의 구조와 성능을 개선하고 새로운 기술을 실무에 적용하는 역할을 맡습니다.• OpenStack 기반 사내 클라우드 솔루션의 기능·성능 고도화• Nova, Neutron, Cinder 등 주요 컴포넌트 설계 및 개선• 서버 및 네트워크 구조 설계, VM 및 볼륨 운영 정책 수립• 기술 검증(PoC) 환경 구축 및 결과 분석• 자동화 도구(Ansible, Terraform/OpenTofu)를 통한 효율적 배포 체계 구축• 내부 프로젝트 및 고객사 대상 기술 시연·성능 검증 지원.","• 리눅스 및 가상화 솔루션 사용 경험 3년 이상• OpenStack 설치, 운영 경험 1년 이상• 네트워크 및 성능 분석 기본 역량• 장애 원인 분석 및 로그 기반 문제 해결 능력• Ansible, Terraform 등 자동화 도구 활용 경험.","• Ceph, Kubernetes 등 클라우드 연동 기술 경험• 대규모 프라이빗 클라우드 운영 경험• Prometheus, Grafana를 이용한 모니터링 구성 경험• 고객 PoC, BMT, 시연 지원 등 기술 커뮤니케이션 경험• 멀티 존, 멀티클러스터 환경 설계 또는 운영 경험."
럭스로보(LUXROBO),"• PCB 자동 배치·배선(Placement & Routing) 알고리즘 연구·개발(Rule-based, Deep Learning, Reinforcement Learning)• PCB 설계 분석하여 전문가 설계와 비교, 개선점 도출• 설계 결과 시뮬레이션, 모델 경량화·최적화 및 성능 검증.",• 관련 경력 5년 이상 (석·박사 학업 기간 인정)• 전기/전자 공학 관련 학업 경력(학사 이상)• Python / PyTorch 프로젝트 경험• 머신러닝·딥러닝·강화학습 이론 및 실무 경험• 복잡도 높은 알고리즘·시스템 최적화 프로젝트 수행 경험.,"• PCB 설계(Altium, PADS, OrCAD 등) 또는 하드웨어 제품 개발 경험• Ansys, PSpice 사용 경험• 전자캐드기능사·전자기사 자격증• 관련 논문·특허 또는 RL 응용 프로젝트 경험."
플러그링크,"• 실시간으로 발생하는 전기차 충전 데이터 파이프라인의 아키텍처 설계 및 구축• 비즈니스 요구사항에 맞는 분석용 데이터 모델을 설계하고 개발• 다양한 소스로부터 수집된 원본 데이터를 표준화된 스키마(예: ECS)로 정제하고 변환• 수집된 원본(Raw) 데이터를 분석 및 시각화에 최적화된 데이터 마트 및 요약(Summary) 데이터로 가공하고 적재• 데이터 품질과 안정성을 확보하기 위해 데이터 파이프라인을 모니터링하고 지속적으로 최적화• 데이터 분석가, 기획자 등 유관 부서와 긴밀하게 협업하여 데이터 요구사항을 정의하고 해결.","• 3년 이상의 데이터 엔지니어링 관련 경력을 보유한 분• Python, Java, Scala 등 하나 이상의 프로그래밍 언어에 능숙한 분• SQL 활용 능력이 뛰어나며, 데이터 집계, 그룹핑, 조인 등 데이터 처리에 대한 깊은 이해를 갖춘 분• ETL/ELT 데이터 파이프라인을 설계, 구축, 운영해 본 경험이 있는 분• 데이터 모델링(정규화, 비정규화 등)에 대한 기본 지식과 경험을 갖춘 분.","• Elasticsearch Ingest Pipeline 또는 Logstash를 이용한 데이터 변환/가공 경험• Elastic Common Schema(ECS)에 대한 이해 또는 유사한 데이터 스키마 표준화 프로젝트 경험• Grok, Dissect 패턴을 활용한 로그 파싱 경험• Painless 스크립트 등 데이터 처리용 스크립트 작성 경험• Apache Spark, Flink 등 대용량 데이터 분산 처리 시스템 경험• 클라우드 환경(AWS, GCP, Azure 등)에서의 데이터 파이프라인 구축 및 운영 경험• 전기차 충전 인프라 또는 IoT 기기의 시계열 데이터 분석 프로젝트에 참여한 경험."
메이크스타,"[합류하시면 이렇게 일해요!]• Data Analyst는 메이크스타의 제품 조직인 스쿼드(Squad)에 속합니다.• 스쿼드는 PO/UX 디자이너/개발자/데이터 분석가 등 2~8명의 직군으로 구성됩니다.• 각 스쿼드는 작은 스타트업처럼 자율성과 책임을 갖고 일합니다.• 빠른 실행을 통해 가설을 검증하며, 점진적으로 큰 변화를 만듭니다.• 데이터에 기반한 의사결정을 통해 제품을 만들고, 그에 대한 성과를 측정하고 학습/공유합니다.[이런 것을 경험할 수 있어요!]• 전사에서 Data-Driven 의사 결정을 할 수 있도록 전사의 북극성 지표 (North Star Metric)지표들을 설정하고 각 스쿼드 OKR 설계를 도울 수 있습니다.• 스쿼드의 가설을 함께 세우고, 실험 설계, 실험, 분석할 수 있습니다.• 동료들의 신뢰를 받고, 제품과 사업의 필요한 지표의 우선순위를 정할 수 있습니다.• 글로벌 시장에서 빠르게 성장하는 K-pop 시장의 변화를 주도할 수 있습니다.","[이런 분과 함께하고 싶어요!]• 데이터 분석 경력 5년 이상이며, 데이터를 활용해 실제 제품을 개선해 본 경험이 있는 분• 서비스 데이터 분석 방법(Funnel Analysis, Retention, Cohort Analysis, Customer Lifetime Value 등)에 대한 깊은 이해가 있는 분• SQL을 사용하여 직접 데이터를 가공하고 추출할 수 있는 분• BI/시각화 도구(Tableau, Grafana, Redash, Superset 등)를 활용한 대시보드를 구축해본 분• 데이터의 결과에 대해 다양한 부서 동료들과 효과적인 커뮤니케이션이 가능한 분[이런 기술을 활용해요!]• Google BigQuery, Google Cloud Storage• Google Cloud SQL for PostgreSQL• Amazon Aurora MySQL• Google Analytics 4, Google Tag Manager• Apache Airflow• Redash, Grafana.","[이런 분이면 더 좋아요!]• 전체 서비스 관점에서 필요한 분석을 경영진과 이야기하면서 주도적으로 찾고 실행할 수 있는 분• 팀 전체가 데이터를 어떻게하면 더 잘 볼 수 있을까 고민하는 분• 프로그래밍 언어(Python, R 등)를 이용해 데이터 분석 및 관련 프로젝트를 진행한 분."
디스펙터,"∙ 로봇 군단의 중앙 서버 구축 (Backend) 다수의 로봇과 센서 데이터를 실시간으로 수집(Logging)하고, 안정적으로 통신하는 고성능 관제 서버를 개발∙ 직관적인 지휘 통제 시스템 구현∙ 로봇과 서버의 완벽한 연결 (Robotics Communication) ROS, WebRTC 등 다양한 통신 프로토콜을 활용하여 로봇과 관제 서버 간의 완벽하고 지연 없는 데이터 파이프라인을 설계.","∙ 경력 5년 이상 또는 그에 준하는 탁월한 실무 역량을 갖춘 분 ∙ 백엔드 로봇 통신 프로토콜까지, GCS 등 SW 개발에 필요한 Back-end 역량을 보유하신 분.","∙ 로봇/GCS 제어 및 통신 시스템 개발 경험∙ 3D 시각화, GIS, 지도 기반 UI 구현 경험∙ 보안/인증/멀티 클라이언트 구조 설계 경험∙ ROS, WebRTC, MQTT, DDS, CAN 등 로봇/통신 프로토콜에 대한 깊은 이해∙ Docker, Git, CI/CD 환경 경험."
웨이커,"• 글로벌 증권 투자 및 리서치를 위한 데이터 아키텍처 총괄 설계 및 고도화• Python 중심의 분산·병렬 데이터 파이프라인 설계 및 최적화• 머신러닝/딥러닝 학습–서빙 End-to-End DataOps 인프라 구축·운영• 데이터 거버넌스, 보안, 품질 관리 체계 수립 및 조직 내 확산• 주니어/미들 엔지니어 기술 리드 및 멘토링• 신규 데이터 기술·툴 PoC 및 인프라 혁신 주도.","• Python을 메인 언어로 9년 이상 활용한 경력• 대용량 데이터 처리 및 분산 시스템 아키텍처 설계·개발 경험• Kafka, Redis, PostgreSQL, S3 기반 대규모 Python 파이프라인 아키텍처 운영 경험• Kubernetes, Docker 등 클라우드 네이티브 환경에서 Python 서비스 운영 경험• 데이터 거버넌스·보안·품질 관리 체계 설계 경험• 투자/금융 데이터 및 증권 시장 데이터 처리 경험• 글로벌 프로젝트 수행 및 협업 경험• 해외출장에 결격사유가 없으신 분.","• Hadoop Ecosystem, Spark 등 대규모 데이터 플랫폼 운영 경험• 실시간 고가용성 아키텍처를 Python 기반으로 서비스에 도입한 경험• Airflow, Jenkins 등으로 Python 중심의 CI/CD 파이프라인 구축 경험• MLOps, DataOps 환경 구축·운영 경험• 조직 내 데이터 엔지니어링 문화 및 프로세스 개선 경험• 영어 등 글로벌 협업 환경에서 원활한 커뮤니케이션 능력."
제논,"• Elastic Search 또는 Open Search 플랫폼 구축, 운영 및 관리• NoSQL 데이터베이스 설계 및 최적화 업무• GraphDB 설계 및 운영 업무.","• Elastic Search 운영 경험 2년 이상• ELK 스택, 카프카 클러스터 구축 운영 경험 보유• NoSQL 데이터베이스, GraphDB 사용 가능자• Docker/Kubernetes 기반 지식 및 서비스 유경험자.",• 하기 사항에 대한 구축 및 사용 경험 - Open Search 플랫폼 - Weaviate Vector DB 클러스터 - AWS 기반 서비스• 대규모 데이터 처리 및 분석 경험 및 데이터 보안 및 암호화에 대한 이해.
티맥스티베로,"[[티맥스티베로 연구본부 업무 소개]]DBMS Engine 연구원은 아래와 같은 업무를 하고 있으며, 입사하게 되면 아래 나열된 업무 중 일부를 맡게 될 예정입니다.1. 새로운 SQL 기능과 전반적인 SQL 성능 향상에 대한 연구 1) 같은 SQL이더라도 어떤 동작을 선택하느냐에 따라 성능이 천차만별이기 때문에 더 나은 수행 방법이 있을지 고민합니다. 2) 수행 중에도 높은 성능을 유지하면서 안정적인 운영이 가능한 방법을 찾고, 효과적인 알고리즘과 자료구조 선택을 기반으로 높은 성능을 보장하는 방법을 연구합니다. 3) DB의 테이블과 인덱스 등의 오브젝트 메타 정보를 관리하고, SQL 처리 중 메타 정보를 정확하고 빠르게 열람 가능하도록 지원합니다. 4) PL/SQL을 통해 일반적인 프로그래밍 언어의 기능과 SQL 기능을 함께 사용할 수 있습니다. PL/SQL의 기능을 추가하고, 성능 향상을 위해 연구하고 개발합니다. 5) XML, JSON, Geometry 데이터와 같은 비정형 데이터를 데이터베이스에서 편하게 사용할 수 있도록 연구합니다.2. DB 트랜잭션을 위해 필요한 핵심 Backend 파트 연구 개발 1) 동시성 향상을 고려한 데이터 수정, 접근 제어 및 및 분산 락을 이용한 고성능의 트랜잭션 수행을 연구합니다. 2) Cluster 환경에서 분산 캐시를 관리하고, 성능을 높이기 위한 다양한 연구를 진행합니다. 3) 데이터 보안 및 서버 프로세스의 자원 관리, 병렬 처리를 위한 framework를 만들고 연구합니다. 4) 안정적인 DB 운영과 효율적인 백업과 빠른 복구를 위해 연구합니다.3. 대용량 데이터 저장과 처리 향상을 위한 분산 시스템 연구 1) 대용량 데이터 저장을 위한 분산 Storage 및 분산 처리 시스템을 개발합니다. 2) 대용량 데이터를 고속으로 처리하기 위해 RDMA와 NVMe 기반의 효율적인 아키텍처를 연구하고 개발합니다. 3) 분산 데이터베이스의 정합성을 위해 클러스터 구성과 네트워크 연결성, 노드 상태를 종합적으로 관리하며 안정적인 운영을 보장하는 개발을 진행합니다.4. Tibero DBMS용 JDBC/ODBC 드라이버 등 클라이언트 컴포넌트 개발 다양한 애플리케이션이 DBMS에 안전하고 빠르게 접근할 수 있도록 아래 업무를 수행합니다. 1) 각 프로그래밍 언어별 데이터베이스와의 통신을 담당하는 client driver를 개발합니다. 2) Tibero DBMS와 여러 Framework (ORM 등)와의 연동을 위한 개발합니다. 3) OpenSource Platform과 Tibero를 연동하기 위한 연구 개발을 진행합니다.[[티맥스티베로 연구본부 사용 Language]]Language : C, C++, Java, Python ※ 온라인 코딩테스트 전형 시 Python을 제외한 상기 사용 언어로만 응시 가능합니다. Tibero에서 실제 사용하는 개발 언어에 제한이 있어 위와 같이 운영하는 점 너른 양해 부탁드립니다.",• 4년제 정규 대학 졸업자 및 졸업예정자로 학사 학위 이상 소지자· C/C++ 프로그래밍 가능하신 분· 컴퓨터공학 전공 혹은 관련 업계 종사한 이력을 보유하신 분· 해외여행에 결격 사유가 없으신 분.,• 컴퓨터 공학 계열 석사 이상 수료 혹은 수료 예정자· DBMS 개발 경험 있으신 분· UNIX/LINUX 기반 시스템 프로그래밍 경험 있으신 분· SQL에 대한 높은 지식이 있으신 분 (SQLP 자격증 등)· 분산 시스템 관련 개발 경험 보유하신 분· 클라우드 환경에 특화된 개발 경험이 있으신 분장애인 및 보훈 대상자.
지엠컴,사내 플랫폼 개발• 사내 플랫폼 ( 내부 솔루션 및 그룹웨어 ) + LLM 연동 개발• 외주 개발시 프로젝트 기술 관리 ( 외부 ERP 연동 관리 필수 )• 외주 개발 결과물에 대한 기술적 검토 및 품질 검증• 외주 협력사 및 내부 유관 부서와의 원활한 커뮤니케이션 및 프로젝트 리딩.,"컴퓨터공학 및 유관학과(소프트웨어공학, DS, AI, 빅데이터 등) 전공자• 관련 업무(개발 또는 PM) 경력 3년 이상• 개발 경험 필수: Java, Python, DB ( RDB, NoSQL 등등)• 개발 경험 우대: React, Spring Boot, Vue, PHP, Node.js (Next.js) 중 하나 이상 경험자• A2A, MCP, RAG, LLM, SLM, SLLM, 프롬프트 엔지니어링 등 AI의 기본 개념과 응용에 대한 이해도• 실무에서 AI 기술 적용을 적극적으로 추진할 수 있는 분.","IT 프로젝트 기술PM 또는 엔지니어 경력자• DX, AX 프로젝트 수행 경험자• R&D 국책과제 또는 국가 지원사업 경험자• 협력사 및 사내 부서 간 원활한 협업 및 리더십 보유자• 기술 문서 작성 및 커뮤니케이션 능력이 뛰어난 분."
지엠컴,"AI 기반 사내 플랫폼 개발• MCP/ A2A 를 활용한 MVP 버전의 agentic AI 서비스 개발• 다양한 AI 기술(SLLM, RAG 등)을 접목한 신규 서비스 개발• 외주 개발 프로젝트 기술 관리 ( 외주 개발시 )• 외주 개발 결과물에 대한 기술적 검토 및 품질 검증• 외주 협력사 및 내부 유관 부서와의 원활한 커뮤니케이션 및 프로젝트 리딩.","컴퓨터공학 및 유관학과(소프트웨어공학, DS, AI, 빅데이터 등) 전공자• 관련 업무(개발 또는 PM) 경력 3년 이상• 개발 경험 필수: Java, Python, DB ( RDB, NoSQL 등등)• 개발 경험 우대: React, Spring Boot, Vue, PHP, Node.js (Next.js) 중 하나 이상 경험자• AI 기술 이해 및 활용 능력 필수• A2A, MCP, RAG, LLM, SLM, SLLM, 프롬프트 엔지니어링 등 AI의 기본 개념과 응용에 대한 이해• 실무에서 AI 기술 적용을 적극적으로 추진할 수 있는 분.","IT 프로젝트 기술PM 또는 엔지니어 경력자• DX, AX 프로젝트 수행 경험자• R&D 국책과제 또는 국가 지원사업 경험자• 협력사 및 사내 부서 간 원활한 협업 및 리더십 보유자• 기술 문서 작성 및 커뮤니케이션 능력이 뛰어난 분."
피앤디솔루션,"• CoE Team의 일원으로, Dataiku 솔루션의 Specialist 역할을 담당하게 됩니다.• CoE Team 은 크게 4가지 목표로 운영됩니다. - 사내 분야별 기술 전문가 팀으로서의 전문성 확보 - 사내/외 전파 교육 및 컨설팅 제공 - 고객사에 대한 솔루션 제안 및 Demo 지원, 프로젝트 인수인계 및 기술 전수• Dataiku Specialist 는 아래 역할을 수행합니다. - Dataiku DSS 솔루션의 Technical Architecture 설계 및 기술 컨설팅 수행 - MLOps 솔루션 기반 Technical Architect 역할 수행 - Dataiku DSS 설치 및 구축 (Linux 환경 단독 설치, Docker/Kubernetes 기반 설치 자동화 포함) - Design/Automation/API/Govern Node 구성 및 환경 설정 - 사용자·그룹·권한·프로젝트·플러그인·코드 환경 등 기본 설정 및 운영 지원 - REST API, Kafka, DB, Object Storage 등과의 연동 구축 - 대규모 데이터셋 처리 성능 분석 및 최적화 - 고객사 대상 요구사항 분석, 기술 프레젠테이션, PoC 및 구현 가이드 제공.",• IT 시스템 구축 또는 데이터 플랫폼 관련 경력 5~10년• Linux 기반 시스템 설치 및 운영 경험• Docker 및 Kubernetes 환경 이해 및 실무 경험• RESTful API 및 데이터 통신 구조 이해• 데이터 분석·AI·ML에 대한 기본 개념 이해• 적극적이고 원활한 커뮤니케이션 능력*• 동료에 대한 상호 존중 및 배려의 태도*• 해외여행에 결격사유가 없는 분*##모든 기술을 완벽하게 갖추기보다는 위 기술 중 2~3개 이상의 강점을 가진 분을 찾고 있습니다.,"• 고객사 기술 대응과 구축 프로젝트에 직접 참여하는 기술 중심 포지션입니다.• DevOps, AI 플랫폼, 엔터프라이즈 데이터 파이프라인 분야에 관심이 많은 분을 환영합니다."
인터엑스,• Vision Camera 드라이버 개발• AI Vision System 개발 및 구축.,"• 관련된 학사 이상 보유하신 분 • Vision System 구축 경험 - 카메라, 렌즈, 조명등 Vision System 관련 H/W 지식을 보유하신 분 • Cognex, MIL 등 머신비전 구축 경험이 있으신 분 • C++, .NET 개발 경험이 있으신 분 • OpenCV 등 이미지처리 라이브러리 사용 경험이 있으신 분 • RDB, NoSQL 등 데이터베이스 경험이 있으신 분.","• Vision System 구축 경험이 풍부하신 분 • 다양한 카메라, 렌즈, 조명등 구축 경험이 풍부하신 분 • Cognex, MIL 등 라이브러리 사용 경험이 풍부하신 분 • OpenCV 등 이미지처리 라이브러리 사용 경험이 풍부하신 분."
퓨쳐위즈(Futurewiz),"• 데이터베이스 구축, 운영 및 기술 지원• 데이터베이스 성능 및 Query 튜닝• 데이터베이스 성능 모니터링 및 장애 조치• 데이터베이스 보안 및 컴플라이언스 대응.","• AWS 기반의 데이터베이스 아키텍쳐 설계 및 구축, 운영을 3년이상 경험하신 분• SQL 튜닝 및 검수 능력을 보유하고 계신 분• 데이터베이스 모니터링 계획 수립 및 운영경험이 있는 분• DB 운영을 위한 자동화 스크립트 개발 가능한 분.","• Aurora RDS 외 데이터베이스 운영 경험이 있는 분 (MySQL, MS-SQL, PostgreSQL 등)• MongoDB 및 ElasticSearch등 NoSQL 경험을 가지고 계신 분• DB Major 버전 업그레이드 경험이 있으신 분• 퍼블릭 클라우드상의 보안 위협에 대한 높은 이해도를 보유하신 분• ISMS/ISMS-P 인증 심사 대응 경험이 있는 분• 문제해결 능력과 커뮤니케이션 능력이 뛰어나신 분• 백엔드 개발 경험 또는 이해도가 높으신 분."
래딩랩스,"• 1인 개발자로서 인프라, 프론트, 백엔드의 구분 없이 주요 기능을 AI 툴을 활용하여 직접 설계 및 구현• 개발자로서 문제 해결 중심 사고 기반의 AI 개발 환경 구축• 사용자 피드백, 데이터 분석 등을 통해 우선 순위 설정.","• 크로스플랫폼, 백엔드, 인프라 중 최소 한 분야에 숙련도가 있으며, 풀스택 영역에 대한 학습 의지 및 기본 이해를 갖추신 분• 기능, 기술 중심이 아닌 제품 중심의 사고• 모바일 앱 출시 경험 1회 이상(앱 스토어 기준)• 설립 7년 미만의 기업에서 동일 직무로 1년 이상 경험을 보유한 분• 협업과 커뮤니케이션을 중요하게 생각하며, 이해 관계자들과 원활한 의견을 나누고 실행할 수 있는 분.","• 모바일 앱 출시 경험 3회 이상(앱 스토어 기준)• 빅데이터 기반의 앱 런칭 경험• 영어 커뮤니케이션에 능숙하며, 글로벌 버전을 만들고 싶은 분• 데이터 시각화(Tableau, Power BI, Superset, Kibana 등)에 익숙하신 분• 문제 해결을 위해 기술 스택이나 도구에 구애 받지 않고 다양한 시도를 즐겨하시는 분• 컴퓨터 공학 또는 관련 분야 학사 학위 이상 소지자."
인텔렉투스,"• 웹 어플리케이션 서버(API) 설계 및 구현• 온프레미스 / AWS(클라우드) 환경에서 서버 시스템 구축• RDBMS 및 NoSQL 설계 및 개발• 백엔드 개발 프레임워크를 활용(NestJS, SpringBoot 및 관련 생산성 도구 등)• WebSocket, MQTT, AMQP를 활용한 스트리밍 서버 개발.","• RESTful API에 대한 이해가 있고 활용이 가능하신 분• 스트리밍 어플리케이션에 대한 이해와 구현이 가능하신 분• 데이터베이스(MySql, MongoDB 등)에 대한 개발 경험이 있으신 분• 전문연구요원 지원 희망자 (산업기능요원 불가능).","• NestJS / Typescript 기반 설계 및 개발 경험• 메시지 미들웨어 연동 경험자 MQTT broker, Apache Kafka• Network, IT Security 관련 지식 보유자• 데이터 분석 시스템 프로젝트(데이터 파이프라인, 데이터 카탈로그, 메타데이터 관리) 설정• Docker, Kubernetes 사용 경험."
데브시스터즈(Devsisters),"[주요 기술/데이터 스택]Databricks, Delta Lake, Spark SQL, Airflow, AWS, Tableau, Kibana, Quicksight, Cloud DW Modeling[담당업무]• 데이터 기반 의사결정을 위한 데이터 웨어하우스를 설계하고 구축하며, 정확하고 신속한 지표 제공을 위해 데이터 파이프라인을 안정적으로 관리합니다.• 다양한 제품에서 발생하는 원천 데이터를 목적에 맞게 가공하고, 효율적인 운영을 위해 지속적으로 시스템을 고도화합니다.• 모든 데브시스터즈 구성원이 데이터를 쉽게 활용할 수 있도록 전사 데이터 포털을 관리하고, 더 나은 활용 방안을 모색합니다.• 새로운 게임 출시 전, 개발팀과 협력하여 분석 로그를 설계하고 필요한 데이터 웨어하우스 및 지표를 개발합니다. 경우에 따라 제품팀의 데이터 관련 업무를 지원하기도 합니다.• 게임 데이터는 물론, 마켓, 정산, 기술 비용, 마케팅 등 다양한 영역의 전사 데이터를 폭넓게 다룹니다.","• SQL을 능숙하게 활용하여 복잡한 데이터 문제를 해결할 수 있어야 합니다. 쿼리 성능을 개선하거나 최적화한 경험이 있다면 더욱 좋습니다.• 주도적으로 데이터 마트를 설계하고 구축한 경험이 있어야 합니다. 변화가 잦은 데이터 환경에서도 안정적으로 운영한 사례가 있다면 더욱 좋습니다.• 때로는 완벽함보다 실용적인 관점에서 빠르게 문제를 해결하는 유연함이 있어야 합니다.• 자신의 역할에만 머무르지 않고, 업무 영역을 능동적으로 확장해 나가며 새로운 기술이나 도구를 배우고 적용하는 데 거리낌이 없어야 합니다.","• 데이터 품질 관리 시스템 운영 경험• 셀프 서비스 BI 시스템 운영 경험• 데이터 거버넌스 관리 경험• BI 툴(QuickSight, Tableau 등)을 활용한 대시보드 제작 경험• 비정형 데이터를 다뤄본 경험• 게임 데이터를 다뤄본 경험[공통 지원자격]• 한국어 비즈니스 의사 소통 능력• 해외 여행에 결격 사유가 없으신 분[제출서류] *PDF 제출• (필수) 자유 양식의 이력서[고용 형태]정규직3개월 수습기간 부여 (수습기간 동안 급여 100%지급)[소속회사]데브시스터즈(주)."
테크핀레이팅스,• 회계 및 ERP 데이터를 활용한 AI 모델 설계 및 개발 (AI 및 머신러닝 모델 협업)• 인공지능 기술을 이용한 중소기업/소상공인에 필요한 다양한 서비스의 제공 • 맞춤형 핀테크 솔루션 제공 및 데이터 기반 의사결정 수행.,"• 관련 업무 경력 5년 이상인 자• 머신러닝/딥러닝 모델 설계 및 구현 경험 보유자• 머신러닝 프레임워크 활용 능력 보유자 (TensorFlow, PyTorch, Scikit-learn 등)• Python, R 또는 기타 프로그래밍 언어를 활용한 AI/ML 모델 개발이 가능한 자.","• CB사 및 금융기관 경력자• 통계학/컴퓨터 공학/데이어 사이언스 또는 관련 전공자• 금융데이터와 AI를 융합한 모델 개발 경험 보유자 (예: 신용 점수 예측, 금융 리스크 관리 등)• 금융/회계 분야 및 ERP 시스템 데이터에 대한 이해도 보유자."
토스뱅크,"[합류하면 함께할 업무예요]• 재무ALM 현업 팀과 긴밀한 커뮤니케이션을 통해 ALM시스템을 개발하고 운영해요.• ALM 마트, 재무시뮬레이션 등 설계 및 구축하고 운영을 하실 예정이에요.",[이런 분과 함께하고 싶어요]• 금융권에서 리스크 ALM 산출 시스템 관리의 업무 경험이 있는 분이 필요해요.• Python or Java의 언어로 주어진 비즈니스 로직을 구현할 수 있는 분이 필요해요.• SQL의 언어를 자유롭게 다룰 수 있는 분이 필요해요.• 리스크 마트 설계 / 배치 스케줄링을 구축하고 운영하신 분이 필요해요.• Frontend / Backend 기술을 활용해 리스크관리 시스템 개발이 가능하신 분이 필요해요.• Hadoop-Ecosystem 환경의 데이터처리 기술 활용 경험이 있으면 더 좋아요.,"[이력서는 이렇게 작성하시는 걸 추천해요]지원서에는 아래 3가지 사항 중 2가지 이상 포함해주세요. 서류전형 검토의 중요한 자료로 활용됩니다.• 업무에서 반복적으로 발생하는 문제를 해결하기 위해 자동화했거나, 기존과 다른 방식으로 문제를 해결한 사례를 하나만 작성해 주세요.• 최근 개발한 코드 중 기억에 남는 사례를 하나만 작성해 주세요. (난이도, 복잡도 높은 프로그램 위주로 소개)• 최근 새로운 기술에 대해 깊이 있게 학습한 경험을 작성해 주세요."
라플라스테크놀로지스,"• Spark, Trino를 활용한 ELT 프로세스 개발• 3rd Party API를 이용한 데이터 소싱 및 통합• SQL 기반 통계 분석• AWS Lambda, API Gateway를 사용하여 Serverless 백엔드 구축 (REST API)• Fast API를 활용하여 Serverful 백엔드 구축.","• 시드 ~ 시리즈 A 라운드 스타트업 경험• 데이터 엔지니어 경력 (데이터 파이프라인 개발 경험)• 실서비스 운영 경험 (게임, 앱 등)• k8s에 대한 이해• 국내외 유수의 대학에서 정량적, 분석적 분야와 관련된 전공 (예. 수학, 컴퓨터공학, 물리학, 산업공학, 금융공학 등)으로 학사, 석사 혹은 박사학위를 취득하신 분• 컴퓨터 공학 전공자 혹은 그에 준하는 전공 지식을 보유한 자.","• B2B SaaS 서비스 운영 경험• 이커머스, 금융 투자 데이터 분석 경험• 오픈소스 프로젝트 활동 경험• OLAP 분석 경험• Kafka 등 데이터 스트리밍 구현 경험• InfluxDB 등 시계열 DB 관련 경험• ML, DL 관련 프로젝트 경험• VC, Growth hacking에 대한 경험• 영어회화 가능자."
해긴,"게임의 지표를 정의하고 데이터 웨어하우스(DW) 설계 및 관리데이터를 직관적으로 이해할 수 있도록 대시보드 개발• 게임 내 이상 데이터 추적 및 데이터 가공, 통계 개발• 게임별 ETL 프로세스 운영 및 데이터 파이프라인 설계/구축• 데이터 모델 설계 및 최적화를 통해 비즈니스 요구 사항에 맞는 데이터 제공• SQL, Python 등을 활용하여 필요한 데이터 추출 및 가공• 비즈니스 인사이트 도출을 위한 데이터 시각화 및 레포팅 작업• 유관 부서와의 협업 및 데이터 결과 공유를 위한 커뮤니케이션 및 문서화 작업.","• 게임 관련 데이터 가공 및 분석 경험• SQL, Python 등을 이용한 데이터 처리가 능숙하신 분• 데이터 파이프라인 설계/구축 및 ETL 프로세스 운영해 보신 분• 여러 팀과 원활한 협업을 위한 커뮤니케이션 스킬을 갖추신 분.","• 게임업계 경력이 있으신 분• Snowflake, PowerBI 사용 경험이 있으신 분• 통계 및 프로그래밍 관련 전공자이신 분• DB/SQL 쿼리 최적화 경험이 있으신 분• 머신러닝 및 AI에 대한 기본적인 이해가 있으신 분• 사업 분석 및 의사결정에 필요한 데이터 분석 능력이 있으신 분• 데이터베이스 관리 및 데이터 모델링에 대한 심화 지식이 있으신 분• 데이터베이스 관리 및 데이터 모델링에 대한 심화 지식이 있으신 분."
뉴로퓨전,"• 금융 공시 데이터 수집 및 가공 파이프라인 구축• 다양한 형태(HTML, PDF, API 등)로 존재하는 공시 원문 데이터를 안정적으로 수집합니다.• 복잡한 비정형 데이터를 파싱하고 정제하여, 분석 및 활용이 용이한 정형 데이터로 변환하는 전체 파이프라인을 구축하고 운영합니다.• LLM을 활용한 정보 추출 시스템 고도화• LLM 기술을 활용하여 비정형 텍스트에서 정밀하게 정보를 추출하는 시스템을 구축하고 운영합니다.• 데이터 거버넌스 및 품질 관리 시스템 구축• 데이터의 정합성과 신뢰도를 보장하기 위한 품질 관리 정책을 수립하고, 이를 시스템으로 구현하여 파이프라인 운영의 완전 자동화 및 고도화를 책임집니다.","• 석사졸업이상, 졸업 예정자 지원가능• Python, SQL 등 데이터 처리 언어에 대한 전문성 및 데이터 모델링, 분석 능력• 다양한 데이터 저장소(RDBMS, NoSQL, S3)의 특성과 트레이드오프를 명확히 이해하고, 이를 데이터 모델링 및 아키텍처 설계에 적용할 수 있는 전문성• 금융 데이터에 대한 기본적인 특성을 이해하고 이를 데이터 파이프라인 설계에 반영할 수 있는 능력이 있으신 분.","• 가격, 재무, 거래, 공시, 지표 등 금융 데이터 특성과 구조에 대한 깊이 있는 도메인 전문성을 가지신 분• 공시 또는 시계열 데이터의 정합성 및 결측 보정, 분할/병합 등의 금융 이벤트를 데이터 파이프라인에 반영하여 성공적으로 운영한 경험• LLM 기반의 데이터 처리 파이프라인을 직접 구축해봤거나, 프롬프트 엔지니어링에 대한 경험과 이해도가 높으신 분• 데이터 파이프라인, API 서버, 스케줄링 시스템 등 백엔드 시스템을 설계/개발하고, 안정적으로 운영한 경험• 클라우드 기반 환경에서 Kubernetes(EKS), IaC, 모니터링 시스템을 포함한 인프라 설계 및 운영 경험."
몬드리안에이아이,"• AI 알고리즘 연구개발 (데이터 수집/라벨링, 모델 개발/평가/서빙)• LLM 기반 프로젝트 수행• 데이터 분석 프로젝트 수행.","• 관련 분야 석사 이상 학위• 2년 이상의 실무 경험 또는 박사 학위• AI, ML, Big Data에 대한 이해• Python 및 ML 프레임워크 (Pytorch, Tensorflow 등) 기반의 AI 연구 경험• AI 기반 데이터 분석 또는 시스템 구축 경험• 모델 구조 및 코드 해석에 대한 두려움이 없으신 분• 고객 요구사항을 기술적 해결책으로 전환할 수 있는 논리적 사고력을 갖춘 분.","• MLOps 체계 구축 및 운영 경험• LLM 관련 경험(Pre-training, Fine-tuning, 모델 최적화, 서빙 등)• 대규모 상용 ML (Vision, LLM, NLP 등) 제품 개발 경험• Python 기반 AI 모델 및 데이터 분석 경험• 대규모 데이터 처리 및 분산 시스템 개발 경험."
한국딥러닝,"• 문서에서 key-value extraction, table recognition, layout analysis 등을 위한 모델을 설계하여 정량적 지표를 기반으로 모델 정확도를 개선• 최신 SOTA LVLM(Large Vision-Language Models)을 모델링하고, 배포 환경에 적합한 구조로 세팅하여 최적화된 추론 파이프라인 구축 및 성능 튜닝• 학습 없이도 다양한 문서 포맷에 robust하게 대응하기 위한 알고리즘·모델 구조를 고안하고, 성능 검증(PoC) 후 확장• 에러 로깅 및 모니터링 지표를 통해 성능 저하 요인을 파악·분석하고, 최적화(하드웨어 가속, 파라미터 튜닝 등)를 주도• 프로젝트 전개 과정에서 예상 리스크를 사전에 파악하고, 타 부서(AI, FE, BE 등)와 협업해 문제 해결 방안을 제안.","• 딥러닝 프레임워크(PyTorch 등) 및 분산 학습·고성능 컴퓨팅 환경에서 5년 이상 연구·개발 경험• 문서 내 구조적 데이터(Table, Layout 등)에 대한 분석 및 모델링 경험• LayoutLM, Donut, 등 Document Understanding 모델 개발 경험 - FUNSD, SROIE, RVL-CDIP 등과 유사한 형식의 문서 데이터셋을 구축 혹은 활용해본 경험• VLM 기반 멀티 태스크 모델 파이프라인 설계 및 개발 경험.","• 글로벌 학회(NeurIPS, CVPR 등)에 논문 게재(특히 1저자) 또는 특허 등 의미 있는 연구 성과를 보유하신 분• 오픈소스 프로젝트에서 주요 기여자(major contributor)로 활동한 사례• 실험 설계부터 실무 적용까지 균형 있게 수행한 경험• Git, Notion, Jira, DVC 등 협업 툴 활용 및 문서화·프로세스 관리에 능숙한 분."
현대오토에버,• 데이터 모델 진단 및 관리• 데이터 표준화 업무 수행• 데이터 거버넌스 구축 및 관리• PJT 지원 : 데이터 모델링 및 데이터 이관 등 전반적인 PJT 업무 수행.,• 시스템 개발 및 운영 경험• DB모델링 경험• 데이터 품질 진단 경험• 데이터 아키텍처 관련 지식.,"• Opensource RDBMS 및 NoSQL DB에 대한 이해• 데이터 관련 자격증 보유(DAP, DasP, SQLP, SQLD)• 원활한 커뮤니케이션 능력• 데이터 및 도메인 관련 지식."
피엠인터내셔널코리아,"• 데이터 수집 및 정제• 회원 매출, 커미션, 탈퇴, 세미나 정보 등 다양한 출처의 데이터를 수집• 데이터의 정확성과 일관성을 확보하기 위한 데이터 정제 및 전처리 수행2. 데이터베이스 관리• 실무 모델 개발을 위한 SQL/NoSQL 모델 설계 및 구현• 대규모 데이터베이스(SQL 및 NoSQL) 관리 및 최적화• 데이터베이스 보안 유지 및 접근 권한 관리3. 데이터 분석• 수집된 데이터를 분석하여 성공적인 TP(Top Performer)의 행동 패턴 분석• Tableau, Power BI 등의 시각화 도구를 활용한 데이터 분석 결과를 시각적으로 표현 4. AI 모델 개발• 성공적인 TP의 베스트 프랙티스를 도출하기 위한 예측 분석 및 머신러닝 모델 개발 • 세미나 정보 및 커뮤니케이션 내용 분석을 위한 자연어 처리(NLP) 기술 활용5. 보고 및 전략 제안• 분석 결과를 바탕으로 비즈니스 전략 제안• 경영진 및 관련 부서에 분석 결과 보고 및 데이터 기반 의사결정 지원6. 지속적인 개선• 분석 모델의 성능을 주기적으로 모니터링하고 개선• 최신 데이터 분석 및 AI 기술 학습 및 적용.","• 학사 이상의 학력을 소지하신 분• 데이터 분석, 통계학, 컴퓨터 공학 등 관련 분야에서 학사 학위 이상을 소지하신 분• 영어 의사소통 능력이 뛰어나신 분.","• 데이터 분석 및 머신러닝 분야에서 5년 이상의 경력을 보유하신 분• 네트워크 마케팅 또는 유사 분야에서 데이터 분석 경험을 보유하신 분• Python, R 등 데이터 분석 언어에 능숙하신 분• Tableau, Power BI 등 데이터 시각화 도구 사용 경험이 있으신 분• 자연어 처리(NLP), 머신러닝 및 예측 분석 경험이 있으신 분• SQL 등을 활용한 대규모 데이터베이스 구축 및 관리 경험이 있으신분• AWS, Azure 등 클라우드 컴퓨팅 환경에서의 업무 경험이 있으신 분• 우수한 문제 해결 능력과 분석적 사고를 갖추신 분• 원활한 커뮤니케이션 및 협업 능력을 지니신 분• 성과 중심적 및 창의적인 사고와 문제 해결 능력을 갖추신 분• 최신 AI 기술 및 트렌드에 대한 이해를 갖추신 분• 프로젝트 관리 경험을 보유하신 분."
보로노이,"# 유기 화학 합성 실험 자동화 프로세스 내 (약물개발 프로세스 자동화) - 대량의 화학합성 실험 (High Throughtput Experimentation) 자동화 • 대량의 배치 타입 단일반응 실험 실험 자동화 • 대량의 플로우 타입 단일/연속 반응 실험 실동화 - 플로우 타입 Scale Up 생산 자동화 • Workup, 정제과정 자동화 - 각종 실험 자동화를 위한 AI 기반 decision making 모델 개발 • 대량의 단일반응 합성 레시피 디자인 • 합성 경로 예측 (Retrosynthesis Prediction) • 단일반응 결과와 합성조건에 따른 최적의 반응 Pathway 찾기.",• AI관련 전공(화학/수학/물리/컴공/산공) 박사학위 + 3년 이상 경력 또는 석사학위 + 7년 이상 경력• 저분자 화합물 빛 반응경로 설계/분석 능력• Batch/Flow 방식의 합성 자동화 연구 경력• 인공지능에 대한 깊은 이해력 및 AI모델 활용 제품 상업화 경험• 기계 부품 설계/제어 경험• 유창한 영어실력• 자격요건을 미충족할 경우 훌륭한 동기와 실력• Native-level Korean proficiency (for non-Korean applicants)• 자격요건을 미충족할 경우 훌륭한 동기와 실력• Native Korean Speaking Level (for foreign applicants).,• Top Tier 논문• 추천서• 신약개발 관련 경력• Retrosynthesis Prediction 연구경력.
보로노이,"# 유기 화학 합성 실험 자동화 프로세스 내 (약물개발 프로세스 자동화) - 대량의 화학합성 실험 (High Throughtput Experimentation) 자동화 • 대량의 플로우 타입 단일/연속 반응 실험 실동화 - 플로우 타입 Scale Up 생산 자동화 • Workup, 정제과정 자동화 - 합성 반응 경로 설계/평가 • 반응 실험 경로 설계 • 반응 실험 품질 평가.",• 화학/화공 유동화학 관련 박사학위 또는 석사학위 + 4년 이상 경력• Flow 방식의 합성 자동화 연구 경력• 저분자 화합물 빛 반응경로 설계/분석 능력• 유창한 영어실력• 자격요건을 미충족할 경우 훌륭한 동기와 실력• Native-level Korean proficiency (for non-Korean applicants).,• Top Tier 논문• 추천서• 신약개발 관련 경력• Flow 방식 합성 상업화 경험.
가이드웨이 컨설팅,"• AI 모델 연구 및 개발 (추천 알고리즘, 콘텐츠 분석, 매칭 최적화)• 데이터 파이프라인 설계 및 운영 (수집, 정제, 학습, 배포)• 대규모 사용자 데이터를 기반으로 한 머신러닝/딥러닝 모델 개발• SaaS 플랫폼 백엔드와 연동되는 AI 기능 구현 (예: 자동 분류, 유사도 검색, 성과 예측)• 신규 AI 기능 PoC(Proof of Concept) 및 서비스 적용.","• 대학교졸업(4년)이상• 관련 분야 3~5년 이상의 개발 경험 (또는 그에 준하는 프로젝트 경험)• Python, Node.js 등 프로그래밍 언어 능숙• 머신러닝/딥러닝 프레임워크(PyTorch, TensorFlow 등) 활용 경험• 데이터베이스(MongoDB, SQL 등) 및 클라우드 환경(AWS 등) 활용 경험• 원활한 커뮤니케이션 능력 및 문제 해결 능력 보유• 영어 능력 필수 (해외 크리에이터/브랜드와 협업 및 문서 활용 가능 수준).",• SaaS/플랫폼 서비스 개발 또는 운영 경험 우대• 영어 능숙.
보이저,[개발 환경]• MySQL/MariaDB• MSSQL• Redis• MongoDB• SpannerDB• Aurora DSQL.,"• DBA 경력 5년 이상• 게임 데이터베이스 운영 및 관리 경험• 주요 데이터베이스 시스템에 대한 이해와 경험• T-SQL 및 데이터 추출/분석에 필요한 SQL 기술적 역량• 데이터베이스 모델링, 성능 분석 및 최적화 경험• 데이터베이스 관련 문제를 신속하게 진단하고 해결할 수 있는 능력• 데이터 무결성과 보안을 유지하면서 데이터베이스를 최적화할 수 있는 능력• 데이터베이스 관련 요구사항을 명확하게 이해하고 전달할 수 있는 능력• 데이터베이스 스키마 등을 형상관리 가능하고, 적절한 버전으로 업데이트할 수 있는 능력• 데이터베이스를 백업 및 롤백할 수 있는 능력• GCP BigQuery 유 경험자• GCP SpannerDB 유 경험자• Golang 코드 분석, 개발 가능자.","• AWS, Azure, Google Cloud 등 클라우드 환경에서의 데이터베이스 운영 경험• 데이터베이스 모니터링 및 관리 도구 사용 경험• CI/CD 파이프라인을 이해하고 데이터베이스 작업을 통합한 경험• 개발 팀과 원활하게 소통할 수 있는 능력."
위드포인츠,"• 3D Vision 및 Point Cloud 기반 알고리즘 연구 총괄· CAD 매칭, 정합, Feature Extration, AI 기반 인식 기술 개발· 다양한 3D 카메라(Photoneo, Mech-Mind, Zivid 등) 활용 및 SDK 통합· 차세대 비전 인식 기술 고도화 및 제품개발팀 내 연구 방향성 수립.","• 컴퓨터 비전, 로보틱스, AI, 수학/물리 기반 전공 석사 이상 / 박사 우대· 3D Vision, Point Cloud 관련 연구 및 상용화 경험· C++ 기반 알고리즘 구현 능력· 3D 카메라 SDK 및 Point Cloud 데이터 처리 경험.","• AI 기반 3D 객체 인식/ Pose Estimation / Segmentation 연구 경험· PC, Open3D 등 오픈소스 활용경험· 국제 학회/저널 논문 발표, 특허 보유자· 딥러닝 기반 비전 학습 데이터 구축 및 모델링 경험."
윌로그,"""데이터분석 리드로 합류하면, 단순히 리포트를 만드는 것이 아니라 윌로그의 전략과 미래를 결정짓는 인사이트를 발굴하게 됩니다.""• 조직의 데이터 분석 전략을 수립하고 팀을 리딩하여 실질적인 성과 창출• 비즈니스 핵심 지표를 정의하며, 이를 기반으로 데이터 의사결정 주도• 다양한 데이터 모델링과 분석 도구를 직접 설계·운영하여 분석 역량 고도화• 데이터 사이언티스트 및 분석가들과 협업해 전략적 분석 프로젝트 리딩• 도출된 인사이트를 제품·영업·전략팀과 연결해 비즈니스 성과 극대화에 기여.","""우리는 '완벽한' 사람을 찾는 게 아닙니다. 대신 데이터로 세상을 바꾸고 싶은 리더를 기다리고 있습니다.""• 데이터 분석 및 모델링 분야 10년 이상의 경험• SQL, R, Python 등 데이터 분석 언어에 능숙• AI/ML 모델 설계·운영 경험• 팀을 이끌며 성과를 만들어낸 리더십 경험• 다양한 직군과 원활히 소통하며 협업한 경험.","• 대규모 데이터셋 분석 경험• 통계학, 컴퓨터 과학 등 관련 분야 전공• 팀 리딩 및 멤버 성장 코칭 경험• BI/데이터 시각화 도구(Tableau, Power BI 등) 활용 능력• 영어 커뮤니케이션 역량• 물류/운송 도메인 경험 (필수는 아님)."
메이븐클라우드서비스,ㆍ데이터 인사이트 도출을 위한 보고서 자동화 기획 및 설계ㆍ다양한 고객 환경의 데이터 ETL 및 파이프라인 구축 또는 협업ㆍMicrosoft Power BI를 사용한 데이터 시각화(Tableau 등 타 시각화 경험자 가능).,"ㆍ데이터 시각화 기획 및 분석∙설계 가능하신 분ㆍPower BI 또는 Tableau 등 시각화 도구 사용 가능하신 분ㆍSQL 및 프로시저 사용 및 작성 가능하신 분ㆍDAX함수, Power Quary 사용 가능하신 분.","ㆍData Warehouse 및 Data Mart 구축 능숙자 또는 이해가 있으신 분ㆍETL, Data Pipeline 개발 경험이 있으신 분ㆍMicrosoft의 클라우드 서비스 및 Power Platform 전반에 이해도가 높으신 분ㆍBI 보고서 디자인 감각이 있으신 분ㆍ데이터 시각화팀 운영 및 인사관리가 가능하신 분ㆍ관련 분야 교육이 가능하신 분ㆍDatabricks, MS Fabric /Copilot / AI Foundry 유경험자."
나인닷츠컨설팅,• • Power Platform 도입 및 적용을 고려하는 고객사 대상 컨설팅 및 개발• • Power BI : 데이터 시각화 기획 및 설계/구축• • Power Apps : Power Platform 을 이용한 App 개발• • Power Automate : Power Automate 을 이용한 RPA 또는 Workflow 구축• • Copilot Studio : Copilot Studio 기반의 AI Agent 개발.,"• • 경력 3년 이상• • 대학졸업(2,3년)이상• • Power Platform(Power Apps, Power BI, Power Automate) 및 Copilot Studio 에 대한 기본 이해 및 실무 경험이 있으신 분• • Power Platform(Power Apps, Power BI, Power Automate) 프로젝트 유 경험자• • 데이터 기반 사고 및 MS-SQL, Excel 활용 능력을 갖추신 분.",• • MS 기반 비즈니스 클라우드에 대한 이해도가 높으신 분• • 영어가능자 우대.
폴라리스쓰리디(Polaris3D),• Edge(IoT/로봇) ＜-＞ AWS/외부 서버 데이터 중계 서버 개발 및 운영• AWS 상 컨테이너 기반 백엔드 서버 설계·구축·운영• 실시간 스트리밍 + 배치 데이터 파이프라인 설계 및 구현• 내부 모니터링/라벨링/필터링 웹(또는 앱) 과의 API 연동• REST API 설계·버저닝·문서화 및 성능/부하 테스트.,"• 백엔드 개발 및 서비스 운영 3–6년 경험• Python(필수): FastAPI/비동기 기반 서버 개발 및 분산처리 경험• 메시지 브로커/스트리밍 시스템 활용 경험• 데이터 저장소 운영 경험: 관계형 DB + 캐시 + 오브젝트 스토리지• AWS 연계 프로젝트 수행 경험 (IoT Cloud 데이터 수집/중계) 또는 AWS 기반 서비스 배포 경험• API 운영 역량: 인증/인가, 로깅, 헬스체크, 레이트리밋, 리트라이/백오프• 근무지 : 포항[핵심역량]• 엣지–클라우드 데이터 흐름 설계: 지연·손실·대역폭 제약 고려한 안정적 전송• 데이터 모델링·스키마 버저닝: 파티셔닝, TTL/아카이브, 백필 전략• 운영 안정성 확보: 모니터링 지표 기반의 장애 분석 및 점진적 배포• 보안 역량: 최소권한 설계, HTTPS/mTLS, 키/인증서 관리, 감사 가능성• 협업/문서화: OpenAPI 기반 문서화, 코드리뷰, 장애 대응 기록[기술스택]• 언어: Python(필수)• 우대 언어: TypeScript(Node.js), C++, Rust, Go 중 하나 이상 경험• 메시징/스트리밍: Kafka 계열, NATS, Pulsar 등• 프로토콜: REST, gRPC, WebSocket/SSE, MQTT, WebRTC/RTSP(필요 시)• 데이터 저장소: PostgreSQL/MySQL, Redis, S3/MinIO 등• 관측: Prometheus + Grafana, Loki/ELK, OpenTelemetry.","• Docker + 오케스트레이션(Kubernetes/ECS 등 1종) 운영 경험• TypeScript(Node.js), C++, Rust, Go 중 하나 이상 프로덕션 경험• AWS 서비스 확장 활용: SQS/SNS, DynamoDB, API Gateway 등 기본 서비스• 데이터 파이프라인 도구 경험: Airflow, Spark/Flink 중 하나 이상• 보안/컴플라이언스 실무 적용: IAM 최소권한 설계, 비밀 관리, 데이터 암호화, 감사 로그 활용."
서북,"ㆍ사내 서비스 특성에 맞는 데이터베이스 아키텍처 설계·운영·최적화 주도ㆍDB 구조 개선 및 성능 최적화(쿼리 튜닝, 인덱스 관리)를 통한 서비스 안정성 향상ㆍ장애 예측·분석 및 선제적 대응 체계 구축ㆍ통계 데이터 추출 및 리포트 자동화 설계ㆍ운영 효율화를 위한 스크립트·자동화 도구 개발 및 적용ㆍ개발/서비스 팀과 협업하여 비즈니스 요구사항을 반영한 DB 전략 제안.","ㆍ6년 이상의 MySQL 등 RDBMS 운영 경험 보유자ㆍDBA 에코시스템 운영 경험 보유자ㆍSQL 쿼리 최적화 및 성능 개선 경험 보유자ㆍLinux/Unix 환경에서의 DB 운영 경험 보유자ㆍ단순 운영을 넘어, 문제를 발견하고 개선안을 제안·실행 경험 보유자ㆍ데이터베이스 보안 및 접근 제어에 대한 높은 이해도 보유자ㆍ원활한 협업 및 명확한 커뮤니케이션 역량 보유자.","ㆍDB 모델링 및 구조 개선 경험 보유자ㆍIT/콘텐츠 산업군 경력 보유자ㆍ성능 개선(쿼리 튜닝, 인덱스 최적화 등) 실무 경험 보유자ㆍPython, Bash 등 스크립트 언어 활용 경험 보유자ㆍ장애 분석 및 복구 경험 보유자ㆍAWS DMS 등 마이그레이션 도구 사용 경험 (CDC) 보유자ㆍLinux, 네트워크, 클라우드 환경 이해도 보유자ㆍSMS/ISMS-P 인증 심사 대응 경험 보유자ㆍSMS/ISMS-P 인증 심사 대응 경험이 있는 분."
넥스트증권,"- LLM, 멀티모달 모델 ​등을 ​파인튜닝을 통해 개인화된 ​금융 ​컨텐츠를 ​제작하는 AI 모델을 ​개발하고 고도화합니다.- 다양한 ​금융매체에서 ​데이터를 활용하여 ​AI 모델 ​학습, ​모델 평가 및 ​최적화, 모델 ​서빙, 운영까지 AI 플랫폼 구축과 운영을 담당합니다.- 금융 규제(예: KYC, AML) 및 보안 요구사항을 고려한 커스터마이징 파인튜닝 파이프라인 운영합니다.그래프 기반 추천 등 최신 기술을 바탕으로 사용자 행동 패턴을 최적으로 반영한 개인화 추천 시스템을 만들어갑니다.- 대규모 유저 행동 로그를 활용해 실시간 피처 파이프라인을 개발하고 피드백 루프를 만들어 추천 품질을 지속적으로 개산합니다.","- 3년 이상의 AI/ML 엔지니어 경력- 컴퓨터 공학 또는 관련 분야 학사 학위 이상을 보유하신 분- PyTorch, HuggingFace 등 최신 프레임워크 활용 능력이 있으신 분- 유저 행동 로그를 활용해 딥로닝 모델(GraphSAGE, UniTRec/ModernBERT, PinSAGE)을 개발하고 프로덕션 수준으로 서비스한 경험이 있으신 분- LLM, 멀티모달 모델등을 활용한 관련 서비스 개발 경험이 5년 이상이신 분- 피쳐 엔지니어링 경험이 있으신분- Triton / TorchServe / MentoML 과 같은 모델 서빙 기술 경험이 있으신분.",- AI 학술지 논문 저자 또는 관련 오픈소스 기여자이신 분- LLMOps 구축 및 운영 경험이 있으신 분- GPU 프로파일링/튜닝 경험이 있으신 분- 하이브리드 클라우드 아키텍처 환경에서 AI 모델 학습 및 추론 경험이 있으신 분- 기술 리더십 혹은 AI 프로젝트 리딩 경험이 있으신 분- Kubernetes/Docker 기반 배포 및 운영 경험이 있으신 분.
고요에이아이,"• 회사의 LLM 서비스(고인턴, 사내 LLM 모델 등) 기획 및 로드맵 수립• 팀 리딩 및 AI 서비스 전반 아키텍처/모델 전략 수립• 자체 LLM 학습, 파인튜닝, 평가 및 운영 전략 수립 및 실행• RAG, 멀티 에이전트, 하이브리드 검색 등 다양한 LLM 서비스 기술 리드• AI팀 인력 운영, 성과 관리, 기술 방향성 제시.","• 컴퓨터 공학, 전산학 또는 관련 분야 학사 이상 학위 소지자• 자연어 처리 분야에서 최소 5년 이상의 경력• LLM/GenAI 서비스 구축 및 운영 경험• Python 기반 MLOps/AI 서비스 개발 경력• PyTorch, Hugging Face, LangChain/LangGraph, 벡터DB 등 관련 생태계 구축 경험• 대규모 AI 프로젝트를 주도하거나 팀을 리딩한 경험• 문제 해결 능력, 리더십, 커뮤니케이션 역량• 해외여행에 결격사유가 없으신 분.","• AI 관련 석사 또는 박사 학위 소지자• 대규모 모델 파인튜닝, RLHF, 프롬프트 엔지니어링 경험• 문서/멀티모달 AI 파이프라인 경험 (OCR, 문서처리, RAG)• 클라우드 및 온프레미스 환경에서 AI 인프라 운영 경험• 스타트업 또는 빠른 성장 환경에서 팀을 리딩한 경험."
셀렉트스타,"AI R&D Team셀렉트스타 AI R&D팀은 생성형 AI를 포함한 다양한 핵심 기술의 연구와 개발을 수행하고 있습니다. 특히, 생성형 AI의 신뢰성 평가 기술에 집중하여 연구를 이어가고 있으며, 국내 생성형 AI 분야를 선도하는 기업들과 협업하며 지속적인 기술 혁신을 추구하고 있습니다. 저희는 프로젝트 수행을 통해 실제 문제를 해결하고, 이를 다시 연구로 확장할 수 있는 분, 그리고 문제에 맞춘 맞춤형 연구에 강점을 가진 분을 찾고 있습니다.AI 기술의 최전선에서 트렌드를 함께 이끌고, 최신 기술 연구에 참여하고 싶다면 지금 지원해 주세요. [담당 업무]• 성공적인 프로젝트 수행을 위한 AI기반 연구 개발• 아래 업무들을 수행하게 될 예정입니다. - LLM 성능에 대한 객관적인 평가를 위한 연구 및 실험 설계 - LLM 신뢰성 평가를 위한 합성 데이터 생성 방법론 연구 및 실험 설계 - LLM 기반 Red-teaming 방법론 연구 및 실험 설계 - LLM Task 데이터 생산을 위한 semi-automatic labeling 시스템 개발• 고객 문제 정의 및 해결을 위한 가설 설정 및 검증.","• LLM 관련 분야 학사 소지자로서 실무 경력 3년 이상이거나, 석사 학위 이상 • PyTorch, HuggingFace 등 활용한 LLM 구현 경험• 연구 성과를 서비스 관점에서 해석하고 응용할 수 있는 실용적 사고• 다양한 이해관계자와 명확하고 논리적으로 소통할 수 있는 역량.",• RAG system 그리고 LLM Evaluation 등 유관 분야 프로젝트 경험자• 정보처리기사 자격증 취득하신 분• LLM 평가 관련 실무 경험 또는 연구 경험자• LLM 시스템 전체 파이프라인 설계 경험자.
아하랩스,"• 제조 고객사의 AI 및 스마트팩토리 솔루션 도입 프로젝트 전반 관리• 프로젝트의 주요 마일스톤 설정 및 진행 상황 모니터링• 고객의 기술 요구사항 분석 및 솔루션 제안• 개발, 기획디자인 부서 등과 협업하며 프로젝트 요구사항에 대한 솔루션 적용.",• PM 및 소프트웨어 개발 경력 총 5년 이상• 새로운 기술에 빠르게 적응하며 problem-solving 능력이 있으신 분• 고객 및 내부 개발팀과의 명확한 의사소통 능력• 제안서 및 프로젝트 수행에 필요한 문서 작성 능력• 해외 여행에 결격 사유가 없으신 분.,"• Digital transformation (AI, Big data) 관련 프로젝트 경험 3년 이상인 분• 소프트웨어 개발 경력이 있으신 분• 멀티 태스크 매니지먼트에 익숙하신 분."
토르드라이브,ㆍRobotics Simulation Component 개발ㆍAutonomous Mobile Robot Simulation 연구개발ㆍRobot Service 검증을 위한 Digital Twin 구축.,"ㆍ컴퓨터공학, 소프트웨어공학, 메카트로닉스, 로봇공학, 전자공학 전공하신 분ㆍLinux, Docker, Git 활용 능력 보유하신 분ㆍSimulator 활용 경험이 있으신 분ㆍ원활한 의사소통 및 협업 가능하신 분.","ㆍRobot 3D Simulator(NVIDIA Issac Sim 등) 개발 관련 경험이 있으신 분ㆍROS 개발 경험이 있으신 분ㆍ다양한 센서(Camera, LiDAR, IMU) 활용 경험이 있으신 분."
토르드라이브,ㆍSLAM에 대한 전반적인 기술 개발ㆍReal-time으로 작동하는 SLAM 알고리즘 개발ㆍ자율주행 및 ARM 실차 테스트를 통한 알고리즘 검증.,"ㆍROS1, ROS2, linux, Docker, git 활용 능력 보유하신 분ㆍC++ 프로그래밍이 능숙하신 분ㆍ원활한 의사소통 및 협업 가능하신 분.","ㆍLiDAR, Camera, Radar 등의 센서 관련 데이터 경험을 갖추고 있으신 분ㆍSLAM 관련 기술을 보유하신 분."
메인라인,"• 보험 약관(PDF, HWP, DOCX)의 보장 항목 자동 추출을 위한 NLP 파이프라인 설계• LLM 및 RAG 기반 문서 QA 시스템 기획 및 구현• 가입자 정보 기반 보험금 자동 계산 알고리즘 설계 및 룰 기반 추론 시스템 개발• LLM Fine-tuning, sLLM 구축, 프롬포트 체계 설계 등 고도화 업무• 대량의 약관 대상 자동화 시스템(MLOps+파이프라인) 설계 및 운영• 모델 서빙, 인프라 배포(Docker/Kubernetes 기반) 및 성능 개선.","• 5년 이상의 NLP/AI 관련 개발 경력 또는 3년 이상의 LLM 실무 경험• HuggingFace Transfomers, LangChain, LamaIndex 등 활용 경험• 문서 QA, 질의응답 시스템, RAG 기반 검색 구현 경험• 구조화되지 않은 문서 내 정보 추출 및 Rule-based reasoning 구현 경험• GPT 기반 API 사용 및 Prompt Engineering 경험• Python 기반 서비스 백엔드 또는 FastAPI, Streamlit 등 웹 연계 경험.","• 보험/금융/법률 등 전문 도메인 문서 해석 경험• OCR 파이프라인 구성 및 스캔 문서 자동화 경험• VectorDB(FAISS, Qdrant 등) 연동 경험• LLM 미세조정(SFT, DPO, LoRA) 및 sLLM 구축 경험• 비즈니스 Rule Engine 설계(Drools, DurableRules 등)• Azure, GCP, AWS 등에서 MLOps 운영 경험."
미리비트,"• 쿠버네티브 기반 S3 MinIO Storage Cluster의 데이터 관리 및 운영• 데이터 마이그레이션 및 S3 스토리지 성능 평가 및 검증• 데이터 LifeCycle 정책 수립 및 트러블슈팅 대응• 인증, 보안 및 데이터 관리 정책 구성 및 적용• Grafana 등 모니터링 툴을 활용한 데이터 성능 분석.","• 빅데이터 클러스터 시스템엔지니어링 경력• 쿠버네티스 기반 Storage Cluster(예: MinIO, S3 등) 관리 및 운영 경력• 대용량 데이터(Big Data) 관리 및 운영 경험(Hadoop, CDP 등)• Grafana 등의 도구를 활용한 모니터링 및 데이터 성능 분석 가능자.","• 대규모 분산 스토리지 개발 구축, 운영 경험자 우대• AWS, GCP, Azure 등 Cloud 환경에서 Kubernetes 활용 경험 보유 우대• 대용량 스토리지 버킷 구성 및 권한 분류 경험 우대• Linux 및 네트워크 시스템 운영 지식 보유 우대• Ceph, MinIO, S3 등 스토리지 연동 경험 우대• 데이터 접근 권한 및 데이터 관리 정책 설계 경험 우대."
미리비트,"• S3 MinIO 기반 Storage Cluster의 데이터 관리 및 운영• 데이터 마이그레이션 및 S3 스토리지 성능 평가 및 검증• 데이터 LifeCycle 정책 수립 및 트러블슈팅 대응• 인증, 보안 및 데이터 관리 정책 구성 및 적용• Grafana 등 모니터링 툴을 활용한 데이터 성능 분석.","• Storage Cluster(예: MinIO, S3 등) 관리 및 운영 경력 보유자• 대용량 데이터(Big Data) 관리 및 운영 경험자(Hadoop, S3 등)• Grafana 등의 도구를 활용한 모니터링 및 데이터 성능 분석 가능자.","• AWS, GCP, Azure 등 Cloud 환경에서 Kubernetes 활용 경험 보유자• 대용량 스토리지 버킷 구성 및 권한 분류 경험• Linux 및 네트워크 시스템 운영 지식 보유자• Ceph, MinIO, S3 등 스토리지 연동 경험자• 데이터 접근 권한 및 데이터 관리 정책 설계 경험자."
미리비트,"빅데이터 플랫폼의 클라우드 서비스 전환 위한 Kubernetes 표준 환경 구축 및 운영Kubernetes 클러스터 프로비저닝 구성 및 형상 관리Kubernetes 관련 시스템 컴포넌트/오퍼레이터 개발 및 운영 (Go, Python, Java등)Kubernetes 운영을 위한 CI/CD 환경 설계 (GitOps, ArgoCD)Kubernetes 모니터링과 트러블슈팅 및 장애대응k8s 모니터링 및 로깅 시스템 구축 (Prometheus, Grafana, EFK 등)HDFS 기반 스토리지를 MinIO 스토리지로 전환 개발Stateful Application 설계 및 PVC 구성.","관련 경력 5년 이상다양한 오픈소스 기반 솔루션 설계 및 구축 경험Go, Python, Shell 등을 활용한 자동화 구축 경험Linux, Cloud Native 환경에 대한 기본 지식IaC, Gitops를 통한 자동화 시스템 구성 경험.","Kubernetes 오퍼레이터 개발 경험Kubernetes 기반 플랫폼 개발 및 운영 경험Open Source 기반의 Kubernetes 구축, 운영 경험온프렘, 프라이빗 Cloud 기반 devops 경험빅데이터 클러스터 devops 경험DataOps/DevSecOps 아키텍처 구성 경험Linux 및 네트워크 운영 지식Ceph, MinIO, S3 등 스토리지 연동 경험보안 및 네트워크 정책 설계 경험."
넥톤,• SaaS 플랫폼 개발 및 유지보수• 이메일 기반의 커뮤니케이션 솔루션 개발• LLM 기술을 활용한 업무 자동화 솔루션 개발.,• 컴퓨터 공학 또는 관련 분야 학사 학위 이상• SaaS 플랫폼 개발 경험• 이메일 프로토콜 및 관련 기술에 대한 이해.,• LLM 기술에 대한 이해 및 경험• 업무 자동화 솔루션 개발 경험• 팀 협업 및 커뮤니케이션 능력.
심시스글로벌,"LLM 모델을 연구하고, 커스텀 모델을 개발하며, 파인튜닝 적용 • AI 에이전트 시스템을 설계하고, 프레임워크를 활용하여 자동화 기능 구축• 멀티모달 AI 모델(텍스트 + 이미지/음성) 개발 및 다양한 데이터 유형 통합• 초거대 AI 모델을 분산 학습 환경에서 최적화하고 운영• RAG 기반 AI 시스템을 설계하고, 검색 엔진의 정확도 향상• 클라우드 네이티브 AI 서비스를 구축하고, 엔터프라이즈 환경에서 안정적으로 운영• 최신 AI 연구 논문을 분석하고, 실무 프로젝트에 적용.","• Java/Python/Node.js 기반의 대규모 시스템 설계 및 운영 경험• React, Next.js, Vue.js 등의 프론트엔드 프레임워크와 백엔드 API 연동 경험• NoSQL 및 분산 데이터베이스 최적화 및 대용량 데이터 처리 경험- Kubernetes, MLflow, CI/CD 파이프라인을 구축하여 MLOps 자동화• 대규모 시스템 설계 및 데이터 엔지니어링 적용을 통한 AI 서비스 성능 최적화• GPU 클러스터 환경에서 LLM 학습 및 최적화하여 대규모 배포 수행.","• 자율 AI 에이전트(AI Agent) 연구 및 최신 생성형 AI 모델을 실무 프로젝트에 적용한 경험• 논문 출판 및 AI 커뮤니티에서 발표 경험- 멀티모달 AI 및 최신 연구를 기업 환경에서 실용화한 경험• AI 기반의 대형 프로젝트를 리딩하고, 팀을 관리한 경험- 데이터 엔지니어링 및 빅데이터 처리 기술(Spark, Hadoop, Dask)을 활용하여 AI 모델 최적화 경험• 비전 AI(Vision AI) 개발 또는 연구 경험 보유• 문제 해결 능력과 논리적 사고를 갖춘 분• 새로운 기술을 배우는 데 적극적인 태도를 가진 분• 팀 협업 및 커뮤니케이션 능력이 뛰어난 분."
심시스글로벌,"• 데이터 수집 및 정제, AI 모델 학습을 위한 데이터 전처리 및 증강• 멀티 LLM 기반 생성형 AI 맞춤 학습 및 성능 최적화- RAG(Retrieval-Augmented Generation) 요소 기술 및 솔루션 개발• AI 에이전트 서비스 설계 및 개발• 클라우드 환경(AWS, GCP, Azure 등) 기반 AI 서비스 서빙 및 상용화 프로젝트 리딩.","• 대졸 이상(소프트웨어공학, 컴퓨터공학, 전산학 및 관련 전공 또는 AI 개발자 교육 수료자)• Python 및 AI 라이브러리(TensorFlow, PyTorch, Scikit-learn)를 활용한 개발 역량 및 경험• 머신러닝/딥러닝 기반 지능형 모델 학습 및 서비스 연구·개발, 상용화 프로젝트 수행 경험• Java(Spring Boot) 또는 JavaScript(Node.js, Vue.js 등) 프레임워크를 활용한 개발 경험• 클라우드 환경(AWS, GCP, Azure 등)에서 모델 서빙, MLOps 설계 및 파이프라인 구축 경험• 정형/비정형 데이터 분석 및 데이터베이스 설계(SQL, NoSQL, VectorDB, GraphDB) 및 최적화 경험• 새로운 기술 트렌드에 대한 관심이 높으며, 관련 연구·개발에 적극적인 자세를 가진 분.","• 석사 이상 학위 또는 논문 실적 등 연구·개발을 독립적으로 수행한 경험 보유자• 머신러닝/딥러닝 기반 검색·생성·예측·추론·에이전트 관련 연구·개발 프로젝트 PM 수행 경험• LangChain, LlamaIndex를 사용하여 AI 서비스 또는 프로젝트를 개발한 경험• 다양한 언어 모델(LLM/sLLM/sLM) 기반 데이터 구축·학습 및 AI 서비스 개발 프로젝트 리딩 경험• 대용량 데이터 처리 및 분산 처리(Spark, Ray 등), 인프라 자동화(Kubernetes 등) 및 운영 경험• 비전 AI 개발 또는 연구 경험 보유."
빅밸류,• 데이터 거버넌스 구축• 데이터 표준화 및 품질 관리 방안 기획 및 개발• 데이터 아키텍처 설계 및 모델링• 데이터 처리 성능 최적화 방안 설계 및 구축• 온톨로지 설계/구축• 데이터 리터러시 증대를 위한 연구• 전사 데이터 교육• 데이터 상품 QA/QC 기준 수립 연구• 데이터 상품 고도화 기획.,"• 경력: 3년 이상• 공간 데이터, 빅데이터, 인공지능 기술 전반에 대해 관심이 있는 분• 해외 출장에 결격 사유가 없는 분※ 전문연구요원 지원 가능.","• DAP 소지자• 데이터 아키텍처, 소프트웨어 아키텍처 석사 이상 전공자• 통계학 및 데이터 분석 관련 지식 보유자• 분석계 모델링 경험자• 온톨로지 설계 및 구축 경험자• 다양한 직군의 이해관계자들과 효과적으로 소통하고 협업할 수 있는 커뮤니케이션 능력이 있는 분기술 스택• Postgresql, Airflow, Grafana, Python, OWL, RDFS, DSL, GraphDB."
디오에프,• 3D 스캔 데이터 실시간 정합(registration)• 고품질 3D 메쉬 생성 및 정제(refine)• 알고리즘 성능 최적화• 알고리즘 API 개발• API Unit 테스트• API 개발 문서(wiki기반) 작성.,"• 관련 경력 1년 이상 또는 관련 전공 석사 이상 학위 • 3D Point Cloud 및 Mesh 생성 및 정제 관련 개발 경험• C++ 개발 경력• OpenMP, TBB, CUDA 등의 병렬 프로그래밍 경험• 3D geometry에 대한 전반적인 이해.",• 관련 전공의 석/박사 • 광학 기반 3D 스캔 이론 지식• Eigen 등 선형대수 라이브러리 사용 경험• ICP 등 3D 데이터 정합 경험• 수치 데이터 정리 및 분석능력이 뛰어난 자• Git을 이용한 형상 관리 경험• JIRA등 Issue Tracking 시스템 사용 경험.
다이얼로그디자인에이전시,"• AI Solution Lab AI 엔지니어의 미션은 다음과 같습니다. • LLM과 생성형 AI를 상품화를 가로막는 허들이 무엇인지를 발견하고, 이런 허들을 넘기 위한 방법이 무엇인지를 데이터와 모델 관점에서 고민합니다. • LLM 간의 비교를 통해 프로젝트의 특성에 부합하는 최적의 언어 모델을 선정하고 튜닝하는 방법을 고민합니다. 2. AI Solution Lab AI 엔지니어의 주요 업무는 다음과 같습니다.• AI 모델의 학습이나 파인튜닝 등에 필요한 데이터를 기획합니다.• 상용 LLM 및 임베딩 모델 파인튜닝 등을 통해 AI 모델을 개발합니다.• RAG 시스템을 이용한 도메인 기반 언어 솔루션을 연구하고 개발합니다.• AI 응용 서비스, 솔루션에 탑재하는 AI 모델의 성능 평가 지표를 만듭니다.• AI 응용 서비스, 솔루션에 탑재하는 AI 모델의 성능을 평가하고 개선합니다.• AI Solution Lab이 개발하는 AI 응용 서비스, 솔루션에 탑재할 AI 모델의 최적화를 연구합니다.","가장 중요한 자격 요건은 • 실무 경험에서 비롯되는 자연어처리 분야에 대한 깊이 있는 이해와 LLM 분야 기술 동향과 현안을 파악해 실무에 적용하고, 실무 적용에서 발생하는 문제를 해결하는 능력입니다.• ""생성형 AI와 LLM"" 분야의 최신 동향과 기술을 이해하고, dda가 개발하는 서비스에 접목이 가능한지를 검토하고, 실제로 구현할 수 있어야 합니다. • ""생성형 AI"" 기술의 장담점 및 현안을 이해하고, 생성형 AI 기술의 한계를 최소화하여 서비스를 최적화할 수 있는 방법을 모델 관점에서 풀어낼 수 있어야 합니다. ※ 자연어처리와 딥러닝 기반의 언어 모델, LLM 활용 실무 경력은 최우선 자격 요건입니다.※ 관련 경력이 없으신 분은 선발하지 않습니다.이외에 세부적인 자격요건은 아래와 같습니다.• 자연어처리와 딥러닝 관련 실무 개발 경력이 3년 이상이신 분• LLM/RAG 기반의 상용 AI 모델 서빙 경험이 있으신 분• Tensorflow / Pytorch 등의 AI 프레임워크를 능숙하게 다루실 수 있는 분• 트랜스포머 계열의 언어 모델을 활용한 학습, 파인튜닝 등의 연구 개발 경험이 있으신 분• LLM과 RAG, 파인튜닝, 라마인덱스, 랭체인 등을 능숙하게 다룰 수 있으신 분• AI 모델과 엔지니어링 분야에서 주도적으로 문제를 개선하며 업무 진행이 가능하신 분• 비개발자를 포함해 협업하는 사람과 논리적이고 이성적인 커뮤니케이션이 가능하신 분.","• NLP 및 유관 분야의 석사 이상으로 논문 작성 경험이 있으신 분• 서버/백엔드/프론트엔드 개발 경험 또는 이해가 있으신 분(개발 언어, 프레임웍 무관)• ML, 모델 학습, 배포 파이프라인 구축 및 운영 경험이 있으신 분• 대용량 데이터 구축, 처리 및 서비스 경험이 있으신 분• AI 시장에 대한 이해를 바탕으로 제품화를 위한 아이디어가 넘치시는 분• 3인 이상의 팀에서 다른 직무의 사람과 협업해 기획부터 출시까지 경험해 해 보신 분• ChatGPT, PALM2, NAVER Hyper Clova, LLAMA, Mistral 등과 같은 상용 LLM을 활용한 대화형 인터페이스, 응용 언어 서비스 개발 경험이 있으신 분• 사만다, 자비스와 같은 인공지능 에이전트가 등장하는 영화를 흥미있게 보신 분."
바이오리서치에이아이,"• React, TypeScript를 활용한 웹 서비스의 유저 인터페이스 개발 및 개선• 컴포넌트 기반 아키텍처 설계 및 구현을 통한 재사용 가능한 UI 시스템 구축• 웹 성능 최적화 및 크로스 브라우저 호환성 보장을 통한 일관된 유저 경험 제공• 협업을 통한 효율적인 API 연동 및 사용자 경험 향상.","• 1~3년차 웹 프론트엔드 직군 관련 경험 혹은 그에 준하는 실력이 있으신 분 • HTML, CSS, Typescript, Javascript에 대한 이해도가 있으신 분• React.js, Next.js 및 상태 관리 도구를 활용한 프로젝트 개발 경험자• 차트 라이브러리(D3.js, recharts 등)를 다루어본 경험이 있는 분• 전역상태관리, Tanstack-Query 사용 경험이 있으신 분• Styled-Components를 통한 UI 작업 경험자• Git 기반 협업 및 코드 리뷰 문화에 익숙한 분[인재상]• 빠른 페이스의 스타트업 조직에서 비즈니스 목적에 맞는 설계 및 개발이 가능하신 분• 문서 정리를 좋아하시는 분• 주도적인 일정관리에 능하신 분• 새로운 기술에 관심이 많고 꾸준히 스스로 학습하시는 분• 긍정적 사고와 책임감을 바탕으로 원활한 커뮤니케이션을 하시는 분• 개발 지식을 공유하는 것을 좋아하시는 분[기술스택]• Frontend: TypeScript, React, Next.js, Styled-components, Tanstack-Query, D3.js, Recharts, Monorepo (Yarn Berry), GitHub Actions, Playwright, Storybook• Tools: Jira, Confluence.","• 최신 AI 개발 도구를 활용해 생산성을 높이고자 하는 분• 컴포넌트 설계 및 재사용 가능한 UI 구조 설계 경험이 있는 분• 웹 성능 최적화(코드 스플리팅, 렌더링 최적화 등)에 대한 깊은 이해와 경험이 있는 분• 테스트 코드 작성 및 테스트 관련 지식을 보유하신 분• SPA/SSR/SEO에 대한 경험과 이해도가 높으신 분• CI/CD 환경에서 배포 자동화를 구축·운영해본 경험이 있으신 분• 사용자 데이터 분석 도구(GA 등)를 활용한 데이터 기반의 서비스 개선 경험이 있는 분."
슈퍼센트,"• M/L 예측 모델의 오차 원인을 분석하고, 정밀도를 높이기 위한 Feature Engineering을 진행합니다• 마케팅 데이터를 정밀 분석하여 인사이트를 도출하고 전략적 액션 플랜을 제안합니다• 네트워크 알고리즘(예: 광고 네트워크 최적화 로직 등)을 분석해 성과를 극대화할 수 있는 운영 전략을 수립합니다• 광고 채널별 성과를 면밀히 분석하여 실질적인 기여도(Incrementality)를 평가합니다• 수많은 지표와 메트릭 속에서 의미 있는 핵심 지표(KPI)를 발굴하고, 이를 통해 퍼포먼스를 개선합니다• 마케팅 팀, 데이터 사이언티스트 등과 협업하여 주요 프로젝트를 데이터 기반으로 리드합니다.","• 고급 수준의 Python 활용 능력이 있으신 분• SQL을 활용한 데이터 추출 및 전처리에 능숙하신 분• 모바일 퍼포먼스 마케팅 구조와 지표에 대한 높은 이해도를 보유하신 분• 실험 설계 및 A/B 테스트 결과 해석에 익숙하신 분• 논리적인 사고력과 원활한 커뮤니케이션, 협업 역량을 갖추신 분• 응용수학, 통계학, 확률론 등 분석 기반 지식이 탄탄하신 분[이런 기술이 필요해요]• Python, R, SQL 등과 같은 도구를 사용한 통계 데이터 분석, 데이터 시각화 능력.","• 3년 이상의 데이터 분석 또는 머신러닝 모델링 실무 경험을 보유하신 분• 주요 Ensemble 모델 또는 tensorflow 기반 딥러닝 개발 또는 Feature Engineering 경험이 있으신 분• Data Warehouse/Data Mart 등 데이터 엔지니어링 경험이 있으신 분• AWS, GCP 등 Cloud 환경 내에서 MLOps 파이프라인 설계 작업 경험이 있으신 분."
씨메스(CMES),"• 현장 데이터 분석 : 로봇 작업 로그, 센서 신호, 비전 검사 결과 등 다양한 소스 데이터 수집·정제 및 탐색적 분석(EDA)• 인사이트 도출 및 원인 규명 : 통계적 가설 검정, 실험 설계(DOE), 회귀 분석 등을 통한 성능 저하 요인 파악 및 개선 포인트 제시• 시스템 최적화 : 작업 스케줄링, 자원 배치, 경로 계획, 파라미터 튜닝 등 최적화 문제 정의 및 솔루션 개발·검증• 성능 모니터링 체계 구축 : 핵심 지표(성공률, 처리량, 사이클타임, 가동률 등) 정의 및 대시보드/리포트 자동화• 데이터 파이프라인 개발 : 로그 수집 전처리 분석 리포팅 자동화 프로세스 구축 (Python 기반)• 엔지니어링 팀 협업 : 로봇·비전·PLC 팀과 문제 재현 실험 설계, 최적화 솔루션 현장 적용 및 효과 검증.","• 학력 : 관련 전공 학사 이상• 경력 : 데이터 분석 실무 경력 2년 이상 (신입의 경우, 프로젝트 또는 인턴 경험 必)• Python 데이터 분석 스택(Pandas, Numpy, Matplotlib/Seaborn) 활용한 실무 분석 경험이 있는 분• 통계 기초(기술통계, 가설검정, 회귀분석 등) 이해 및 적용 경험이 있는 분• 최적화 문제 정의 및 해결 경험이 있는 분(Gurobi, OR-Tools 등 활용 또는 알고리즘 구현)• 데이터 전처리 및 시계열 데이터 핸들링 경험이 있는 분(결측치, 이상치 처리 등)• 분석 결과를 비전문가에게 명확히 전달하고 실행 가능한 제안으로 변환하는 커뮤니케이션 능력을 갖추신 분.","• 최적화 알고리즘 실무 적용 경험이 있으신 분 (선형/정수계획법, 유전 알고리즘, 시뮬레이티드 어닐링, 베이지안 최적화 등)• 조합 최적화 또는 운영 연구(OR) 배경이 있으신 분 (TSP, VRP, 스케줄링, 패킹 문제 등)• 시뮬레이션 기반 what-if 분석 및 최적화 검증 경험이 있으신 분• SQL 활용 데이터 추출 및 EDA 경험이 있으신 분• 실험 설계(DOE) 및 다변량 분석 경험이 있으신 분• 시계열 분석 및 이상 탐지 경험이 있으신 분• 로봇/자동화/제조/물류 도메인 데이터 분석 경험이 있으신 분• Git 기반 협업 및 코드 버전 관리 경험이 있으신 분• 분석 결과 시각화 도구(Plotly, Dash, Streamlit 등) 활용 경험이 있으신 분• Docker 컨테이너 환경에서의 분석 도구 배포 경험이 있으신 분• scikit-learn 등 머신러닝 라이브러리 활용 예측 모델링 경험이 있으신 분."
오케스트로,"• OpenStack, Kubernetes 기반의 프라이빗 클라우드 플랫폼 구축, 운영 및 자동화• AI 가속기(GPU/NPU) 자원 할당 및 관리를 위한 스케줄링 정책 개발 및 적용• AI/ML 프레임워크가 사전 설치된 VM 및 컨테이너 이미지 패키징 및 관리• Ceph, Lustre 등 분산 파일 시스템 및 고성능 스토리지 구축 및 운영• 플랫폼 모니터링(Prometheus, Grafana), 로깅(ELK Stack) 시스템 구축 및 운영.","• 3년 이상의 Kubernetes, OpenStack 플랫폼 구축 및 운영 경험• Docker, Containerd 등 컨테이너 런타임에 대한 깊은 이해• Python, Go, Shell Script 등 스크립트 언어를 활용한 자동화 개발 능력• Linux 시스템에 대한 깊은 이해 및 운영 경험.","• Kubeflow, MLflow 등 MLOps 플랫폼 구축 또는 사용 경험• CKA(Certified Kubernetes Administrator), COA(Certified OpenStack Administrator) 등 관련 자격증 보유• CSI, CNI 등 Kubernetes 핵심 구성 요소에 대한 개발 또는 기여 경험• CI/CD 파이프라인 구축 및 운영 경험."
쏘카(SOCAR),"[담당하시게 될 업무를 소개합니다]• 카셰어링 혁신을 위한 Computer Vision 및 LLM 솔루션 개발 및 적용 • 차량 관리 자동화 (파손탐지, 세차검증 등)를 위한 Computer Vision 모델 개발 • VLM/LLM을 활용한 Agentic AI 개발 • Computer Vision / Time Series Analysis / Agent 개발 및 배포 표준화를 위한 MLOps 시스템 개발• 데이터를 활용해 고객의 요구를 파악하고 AI 기술을 활용하여 서비스를 최적화• 풍부한 카셰어링 데이터를 활용한 미래 AI 기술 및 최적 솔루션 연구.","[이런 분과 함께 성장하고 싶습니다]• 학사 7년 / 석사 5년 이상의 Computer Vision (classification, object detection, segmentation, recognition) 혹은 NLP (LLM fine-tuning, RAG, Prompt Engineering) 관련 모델 개발 경험이 있으신 분• 모델 아키텍처 설계 및 경량화 경험이 있으신 분• 머신러닝, 딥러닝 모델 혹은 Agentic AI 시스템을 실제 비즈니스에 적용한 경험이 있으신 분• Pytorch와 같은 트레이닝 프레임워크에 능숙하신 분• Python / C언어 및 Github 개발 환경에 익숙하신 분.","[이런 분이면 더욱 좋습니다]• MLOps (데이터 수집-＞ 가공-＞ 학습 -＞ 평가 -＞ 배포 지원 시스템) 개발 경험이 있으신 분• AWS 혹은 GCP등 클라우드 플랫폼 사용 경험이 있으신분 • Multimodal learning, Document Understanding, Scene Understanding관련 경험이 있는 분• 모델 경량화 및 Edge device 배포 경험이 있으신 분• 해외 저명 컨퍼런스 및 저널에 1저자로 CV/LLM 관련 주제의 논문 출판 경험이 있는 분[동료의 한마디]• 쏘카에서는 차량 이미지와 주행 영상, 차량 센서 데이터 등 다양한 모빌리티 데이터를 통해 실제 서비스에 연결되는 AI 모델을 직접 만들고 발전시킬 수 있습니다.• MLOps 기반의 개발 환경에서 문제 정의부터 모델 연구·배포·자동화까지 전 과정을 경험하며, 기술이 실제 비즈니스에 어떤 임팩트를 줄 수 있는지 체감할 수 있어요• 자율주행으로 진화하는 모빌리티 서비스를 함께 만들어가며 성장할 수 있어요."
쏘카(SOCAR),"[담당하시게 될 업무를 소개합니다]• 데이터 엔지니어링 팀의 비전과 전략 수립, 로드맵 기획 및 실행 총괄 • 운영 DB, 서버, 앱/웹 로그, 차량 로그 등 다양한 소스의 데이터를 수집·처리·적재하는 대규모 데이터 파이프라인 설계 및 고도화• GCP 기반 데이터 인프라 및 플랫폼의 아키텍처 설계·운영·비용 최적화 전략 수립• 데이터 품질, 표준화, 메타데이터, 거버넌스 등을 포함한 데이터 운영 체계 수립 및 전사 적용• BI 툴(Tableau, Superset 등)에 대한 이해도를 바탕으로 BigQuery 기반 Data Mart 구축 및 최적화 • 비즈니스·제품 조직, 데이터 분석가와 협업하여 데이터를 중심으로 한 의사결정 기반 마련.","[이런 분과 함께 성장하고 싶습니다]• Data Engineering 분야 실무 경력 7년 이상, 혹은 이에 준하는 기술 리더십 경험이 있는 분• 대규모 데이터 파이프라인 및 데이터 플랫폼(DataLake, DataMart)의 설계·구축·운영 경험이 있으신 분• 데이터 품질, 메타데이터, 표준화, 거버넌스 등 데이터 운영 체계 구축 경험이 있으신 분• 다양한 이해관계자(분석/사이언스/제품/비즈니스)와 소통하며 문제를 정의하고 해결을 주도한 경험이 있으신 분• 새로운 기술을 탐색하고 비즈니스 요구를 기술 전략으로 전환할 수 있는 기술적 의사결정 능력을 갖추신 분.","[이런 분이면 더욱 좋습니다]• 조직 리더 또는 기술 리더(Tech Lead) 로서 팀을 이끌고 목표 달성 경험이 있으신 분• AWS, GCP(Google Cloud Platform) 기반의 Data Platform (BigQuery, Pub/Sub, Dataflow, Cloud Composer/Airflow 등) 설계 및 운영 경험자• Python, Scala, Go, Kotlin 등 한 가지 이상의 언어로 프로덕션 레벨의 데이터 시스템을 개발하고 운영해 본 경험자• Spark, Flink, Beam 등 빅데이터 분산 처리 프레임워크에 대한 깊은 이해와 활용 경험이 있는 분• dbt (Data Build Tool) 등을 활용한 Analytics Engineering 및 데이터 테스트/품질 관리 경험자• Kubernetes 등 컨테이너 및 분산 시스템 환경에 대한 이해와 운영 경험이 있는 분• GA4, AirBridge, Amplitude 등 마케팅 툴에 대한 이해와 로그 분석 기반 구축 경험[동료의 한마디]• 우리는 데이터를 통해 모빌리티 서비스를 이해하고, 기술로 문제를 해결합니다. 다양한 데이터 소스를 하나로 잇고, 더 나은 의사결정과 서비스를 만들어내기 위해 열린 토론 속에서 함께 고민합니다. 이 과정에서 Tech 리더로서 기술적 통찰과 실행력을 동시에 발휘할 수 있는 환경이 마련되어 있습니다. 쏘카의 데이터 플랫폼은 여전히 성장 중입니다. 함께 그 방향을 설계해 주세요."
바이오리서치에이아이,"• 전 세계 제약·바이오 기업 데이터를 크롤링·수집하는 시스템을 개발/운영합니다.• Daily pipeline이 안정적으로 동작하도록 모니터링하고 데이터 품질을 관리합니다.• 데이터 수집 속도 및 안정성 향상을 위한 병렬처리/캐싱/리트라이 전략 등을 설계합니다.• Airflow 기반 데이터 파이프라인을 개발하고 스케줄링/장애 대응을 담당합니다.• FastAPI 기반 백엔드 API를 개발하여 내부 서비스가 사용할 수 있도록 제공합니다.• AWS 기반(EC2/ECS/S3/RDS)의 데이터 수집/저장 인프라를 운영합니다.• Prometheus & Grafana 기반 모니터링/알람 시스템을 구축/개선합니다.• 논문·특허·정부 DB 등 다양한 데이터 소스 확대를 위한 ETL 설계를 수행합니다.[핵심기술]• Python : 데이터 처리, 크롤링, API 연동, ETL• FastAPI : 내부용 API/백엔드 서비스 개발• Airflow : 데이터 파이프라인 스케줄링/오케스트레이션• AWS : ECS/Fargate, EC2, S3 / Athena, RDS• 웹 크롤링 : requests, aiohttp, BeautifulSoup, lxml, Selenium 등• 데이터베이스 : MariaDB, MongoDB, Redis• Monitoring : Prometheus, Grafana• Container / DevOps : Docker, GitHub Actions (CI/CD)• 버전 관리 및 협업 도구 : Git / GitHub.",• 신입 포함 3년 이하의 개발 경력• Python 기반 프로젝트 경험 또는 동등 수준의 개발 역량• 웹 크롤링 / API 데이터 수집 경험• 데이터 파이프라인 또는 ETL 개발 경험• 기본적인 Linux/CLI 환경에서 개발할 수 있는 능력• SQL 기초 이해 (조인·집계·인덱스에 대한 이해).,"• Airflow를 통한 데이터 파이프라인 운영 경험• AWS에서 인프라 운영 경험 (ECS, EC2, S3, RDS 등)• Kafka, 병렬 처리 경험• 로그/모니터링/알람 시스템 구축 경험• 데이터 품질 관리·테스트 자동화 경험• 컨테이너 기반 개발 경험(Docker)."
당근마켓,"• 로그 및 이벤트 데이터의 정의, 설계, QA, 모니터링 전 과정을 관리해요• 로그 단의 데이터를 구성원들이 신뢰하고 활용도 높게 사용할 수 있는 마트 데이터로 만들어요• 데이터 모델링과 품질 관리를 통해 신뢰도 높은 데이터 환경을 구축하고, 운영 중 관측성(Observability)과 자동화된 품질 체크를 통해 문제를 조기에 발견하고 해결해요• 데이터 거버넌스 체계 운영과 문서화를 통해 조직 전체의 데이터 신뢰성을 높여요• BI 툴과 데이터 카탈로그를 활용해 구성원들이 데이터를 쉽게 탐색하고 이해할 수 있는 환경을 만들어요.","• 데이터 신뢰성, 품질, 거버넌스를 고민하고 지속 관리한 경험이 있으신 분• 조직의 비즈니스 현황과 목표에 대한 이해를 바탕으로 구성원 활용도가 높은 마트 테이블을 서빙하실 수 있는 분• 데이터 모델링/ETL/데이터 웨어하우스 구축 경험이 있으신 분• 단일 모델 수준이 아닌, 데이터 파이프라인 전반의 데이터 품질 관리, 정합성 검증 경험이 있으신 분• SQL, Python을 활용해 데이터를 분석하고 처리할 수 있으신 분• 다양한 직군(분석가, PM, 엔지니어)과 협업 및 커뮤니케이션으로 효율적인 데이터 구조를 설계해본 분.","이벤트 트래킹 설계부터 QA까지 엔드투엔드 로그 관리 경험이 있으신 분• AI를 활용해 구성원들의 데이터 활용도를 개선한 경험이 있으신 분• 대규모 데이터를 Airflow나 DBT와 같은 도구를 효율적으로 분석에 활용할 수 있는 분• A/B 테스트에 대한 통계적 이해를 가지신 분• AWS, GCP 등 클라우드 환경에서 데이터 파이프라인 및 인프라를 운영해본 경험이 있는 분• 데이터 거버넌스 및 메타데이터 관리 시스템(DataHub 등) 운영 경험이 있는 분• Superset, Tableau 등 BI 툴을 활용해 비즈니스 현황을 리포트하신 경험이 있는 분."
바이오리서치에이아이,"Python 기반 데이터 수집/가공 코드를 작성해 OpenSearch 인덱스에 동기화합니다.• 검색 엔진 스키마, 분석기(Tokenizer/Normalizer/Synonym), 랭킹 로직을 설계/최적화합니다.• FastAPI 기반 검색 API 및 집계 API를 개발하고 운영합니다.• 검색 품질 향상을 위한 실험(지표 정의, 로그 분석)을 진행합니다.• 대용량 인덱스(수천만 건)의 업데이트/재색인 전략을 설계합니다.• OpenSearch 모니터링, 쿼리 튜닝, 성능 병목 제거 작업을 수행합니다.[핵심기술]• Python: Python ETL, Batch/Streaming 기반 동기화(Kafka)• FastAPI: 검색 API 및 집계 API 개발• OpenSearch: 검색용 데이터베이스• AWS: ECS/Fargate, EC2, RDS, OpenSearch Service, MSK• Monitoring: Prometheus, Grafana, OpenSearch Dashboard• 데이터베이스: MariaDB, OpenSearch, Redis• Container / DevOps : Docker, GitHub Actions (CI/CD)• 버전 관리 및 협업 도구 : Git / GitHub.",• Python 기반 프로젝트 경험• Django/Flask/FastAPI 중 하나 이상의 Python 웹 프레임워크 사용 경험• REST API 개발 경험 또는 개인 프로젝트 수준의 구현 경험• SQL 기초 이해 (조인·집계·인덱스에 대한 이해).,"• OpenSearch/Elasticsearch 실무 운영 경험• Analyzer/Synonym/Mapping/Scoring에 대한 개념적 이해• 검색 품질/랭킹 평가 경험• 대용량 데이터 ETL 및 실시간 동기화 경험• AWS OpenSearch Service 경험• Kibana/OpenSearch Dashboards 사용 경험NLP 기반 검색(semantic search, embedding) 관심/경험."
스펙터,"• 후보자의 이력서와 누적된 평판 데이터를 실시간으로 분석해, 개인화된 '첫 질문'을 생성해야 합니다.• 후보자의 답변 의도를 파악하고, 핵심을 찌르는 '꼬리 질문'을 동적으로 생성하는 고차원적인 대화형 AI를 만듭니다.• RAG, Fine-tuning 등 최신 LLM 기술을 활용해 'Tony'의 뇌를 설계하고 구현하는 전 과정을 리드합니다.• 기존 'TEO'의 AI 기술력을 한 차원 높여, 후보자와 포지션의 적합도를 넘어 '미래 성과'를 예측하는 모델로 진화시킵니다.• 수천만 건의 텍스트 데이터를 분석해 채용 시장의 인사이트를 도출하는 모델을 만듭니다.","• AI/ML/NLP 분야에서 5년 이상(혹은 그에 준하는)의 실제 상용화 경험이 있는 분• LLM(Large Language Models)과 Generative AI에 대한 깊은 이해 및 실제 프로젝트 적용 경험 (RAG, Fine-tuning 등)• Python, PyTorch/TensorFlow 등 ML 프레임워크 및 데이터 파이프라인 구축에 능숙한 분• 비즈니스 문제를 AI 모델로 정의하고, End-to-End로 개발 및 운영해 본 경험이 있는 분• 새로운 기술과 논문 습득에 두려움이 없고, 이를 비즈니스 문제 해결에 과감하게 적용하는 것을 즐기는 분• 비즈니스 목표를 100% 이해하고, 이를 기술적 로드맵으로 번역하며, 유관 부서(PO, Biz)와 원활한 소통이 가능한 분• Text, Graph, Behavior 데이터를 유기적으로 결합해, 사람의 ‘의사결정’을 예측하는 모델을 설계·구현해 본 분• 데이터 수집부터 전처리·모델링·시각화·서빙까지, 한 사이클 전체를 스스로 설계하고 주도한 경험이 있는 분• 추천 시스템, 인사이트 리포트, 예측 모델 등 데이터를 ‘기능’이 아닌 제품으로 만들어낸 경험이 있는 분.","• 빠르게 성장하는 스타트업에서 AI/ML 리드 혹은 PO 역할을 경험해 본 분• 채용/HR 도메인에 대한 높은 관심과 이해도• SaaS 비즈니스 및 플랫폼 운영 경험• 데이터가 곧 모델'이라는 Data-centric AI 철학을 바탕으로, 데이터 수집부터 모델 배포, 모니터링, 재학습에 이르는 E2E MLOps 인프라를 0부터 1까지(from scratch) 구축하고 운영해 본 경험• MLOps 및 Evaluation Pipeline을 직접 설계·자동화하여, AI 성능을 지속적으로 개선 가능한 시스템으로 만든 경험이 있는 분• 최신 LLM을 단순 API 호출 수준을 넘어, 실제 비즈니스 가치를 창출하는 기능으로 구현하고 상용화해 본 경험• 데이터 사이언스 조직을 세팅하고, 코드 리뷰·리서치 공유·실험 문화를 주도하며 기술적 기준을 끌어올린 경험이 있는 분."
콘센트릭스서비스코리아CATALYST,"• Data Engineering 사업 개발/관리하고 소속 인력을 인사적/기술적 관리• PM 역할 수행을 통해 주요 이해관계자와의 커뮤니케이션을 통한 요구사항 분석 및 설계• Cloud 환경에서 의사결정 및 대시보드 제작에 필요한 데이터 적재• Databricks, Airflow, Python 등을 사용한 ETL/ELT 파이프라인 구축• 데이터 마이그레이션, API를 사용한 데이터 적재• AI/ML 팀과 협업 통한 데이터 프로세스 고도화"".","• SQL, Python을 사용한 데이터 적재, 마이그레이션 능력• 데이터 아키텍처 설계 경험 및 클라우드 환경(특히 AWS, GCP, Azure)에서의 운영 능력• 데이터 모델링 경험이 있으며, 타인이 개발한 코드를 분석하는 능력• 데이터에 대한 문제 해결 능력 및 협업 능력• Databricks 기반 프로젝트 수행/리딩 경험(2년 이상).","• 이커머스 데이터 및 솔루션을 다뤄본 경험이 있으신 분(GA4, 광고 관련 API, Magento, -SNS Business 관련)• 대규모 데이터 처리 및 ETL/ELT 파이프라인 구축 경험이 있으신 분• 데이터 모델링 경험이 있으며, 데이터 마트 생성 및 대시보드 구성 경험이 있으신 분• Google BigQuery, Hadoop 및 Spark 사용 경험• AI/ML 실무 연계 혹은 GenAI 관련 업무 경험• 리더 역할 수행 경험*장애인 우대 채용하고 있는 포지션입니다. 지원서에 관련 내용 기재해 주시면 적극 반영할 예정입니다.또한 관련 규정에 따라 입사시 별도의 수당이 지급되오니 이 점도 참고 부탁드립니다."
현대오토에버,"• Salesforce CRM 시스템 개발• 비즈니스 요구사항 분석, 시스템 설계/개발• 고객데이터 관리 및 분석• 인터페이스 설계 /개발.","• Salesforce기반 시스템 구축/개발 경험 3년 이상• Salesforce 기술 경험 (Sales/Service/Marketing cloud, Lightning Platform,Heroku, SOQL/SQL, API 개발)• CRM 비즈니스 이해 및 관련 시스템 개발/운영 경험• 시스템 개발/설계 가능한 IT지식 보유.",• Salesforce Solution Architect 가능자 우대• 영어(Speaking/Reading/Writing) 가능자 우대• Automotive CRM 구축/운영 경험 우대• Siebel CRM 경험 우대.
오케스트로,"• AI 워크로드를 위한 온프레미스 인프라(서버, 스토리지, 네트워크) 아키텍처 설계 및 고도화• NVIDIA GPU, 비NVIDIA GPU, NPU 등 다양한 AI 가속기 성능 분석 및 도입 전략 수립• RDMA(RoCE, InfiniBand) 기반 초저지연 네트워크 아키텍처 설계 및 검증• OpenStack, Kubernetes 등 가상화 플랫폼과의 기술 통합 및 최적화 방안 설계• 솔루션의 성능, 확장성, 안정성을 고려한 기술 로드맵 정의.","• 5년 이상의 데이터센터 인프라 설계 또는 운영 경험• 대규모 분산 시스템 아키텍처 설계 및 구축 경험• OpenStack, Kubernetes 등 클라우드 플랫폼에 대한 깊은 이해• 가상화(KVM, SR-IOV) 및 컨테이너 기술에 대한 높은 이해도.","• AI/ML 워크로드에 대한 이해 및 관련 인프라 구축 경험• RDMA, DPDK 등 고성능 네트워킹 기술 관련 프로젝트 경험• 다양한 AI 가속기(GPU, NPU 등)에 대한 기술 검증 및 운영 경험• Ansible, Terraform 등 IaC(Infrastructure as Code) 경험."
바이트사이즈,"• AI모델 기반 SW 및 System 개발 : Machine Vision 등• AI Model 성능개선을 위한 이미지 데이터 수집, 전처리 및 분석.",• Fullstack 경력 5년 이상• AI 및 System / Solution 개발 관련 프로젝트 유경험자• 리더 및 시니어 직급으로 1년 이상 프로젝트 리딩 경험자• 근무형태 : 정규직 수습기간 3개월.,"• 웹 어플리케이션 성능 최적화, 유지보수, 트러블슈팅 경험자• 처음부터 신규 서비스 개발에 참여해 런칭 및 운영까지 해보신 분 (성능과 확장 가능한 서비스 구현한 경험)• AI 모델과 연계 및 개발 경험이 있으신 분• AWS 사용 및 운영 경험."
바이트사이즈,"• AI모델 기반 SW 및 System 개발 : Machine Vision 등• AI Model 성능개선을 위한 이미지 데이터 수집, 전처리 및 분석.","• Fullstack 경력 10년 이상• AI 및 System / Solution 개발 관련 프로젝트 유경험자• 리더 및 시니어 직급으로 1년 이상 프로젝트 리딩 경험자• 근무형태 : 정규직 수습기간 3개월[주요 기술 스택]• Application & Data : Python, JavaScript, CSS, MySQL, Pytorch, Machine Vision, JavaScript• Utilities : Git• DevOps : Java• Business : MS365 Office, MS Teams, MS Loop.","• 웹 어플리케이션 성능 최적화, 유지보수, 트러블슈팅 경험자• 처음부터 신규 서비스 개발에 참여해 런칭 및 운영까지 해보신 분 (성능과 확장 가능한 서비스 구현한 경험)• AI 모델과 연계 및 개발 경험이 있으신 분• AWS 사용 및 운영 경험."
